---
title: "Djamaldbz - Méthodes d'Analyse factorielle TP02"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE)
```

```{r, echo = FALSE}
capTabNo = 1; capFigNo = 1;
capTab = function(x){
 
    x = paste0("Tableau ",capTabNo," : ",x)
    capTabNo <<- capTabNo + 1
 x
}

capFig = function(x){
 
    x = paste0("Figure ",capFigNo," : ",x)
    capFigNo <<- capFigNo + 1
    x
}

repeated_capFig = function(x){
  x = paste0(paste0(paste0("Figure ", capFigNo), ""), x)
  x
}
options(OutDec= ",")
```

```{r}
packages_ <- c("ggplot2", "dplyr","readxl","cowplot")

for (pkg in packages_) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg, dependencies = T)
  }
  library(pkg, character.only = TRUE)
}
```

# Description des données

|       Le jeu de données utilisé dans ce premier cas pratique provient du site web de ***Global Footprint Network***. Il contient les résultats d’empreinte écologique et de biocapacité pour 184 pays.

Les données sont disponibles sur <<https://marieetienne.github.io/datasets/overshootday_overview.csv>>.

## Quelques définitions

|       Le calcul de l’empreinte écologique et de la biocapacité nous aide à répondre à la question de recherche fondamentale : Quelle est la demande des êtres humains envers les surfaces biologiquement productives (empreinte écologique) par rapport à la quantité que la planète (ou la surface productive d’une région) peut régénérer sur ces surfaces (biocapacité) ?

* **Hectare global (gha)** : C’est l’unité choisie pour exprimer toutes les quantités d’intérêt concernant la consommation/émission de carbone. Une unité de surface correspondant à la productivité moyenne d’un hectare de terres mondiales. Un hectare de terres agricoles vaudra plus d’hectares globaux qu’un hectare de désert.

* **Empreinte écologique (en gha par personne)** : Le nombre de gha requis pour produire les besoins et absorber les déchets d’un pays.

* **Biocapacité (en gha)** : La capacité d’un pays à produire ce dont il a besoin et à absorber ses déchets (réserve écologique).

* **Jour de dépassement** : Jour de l’année où la demande d’un pays dépasse sa biocapacité annuelle.

# Analyse des données

## Chargement des données

```{r}
##-- Installer et Charger les packages requis
###--- vecteurs des packages
packages <- c("factoextra", "corrr", "FactoMineR", "dplyr","kableExtra","corrplot",
              "explor")

###--- Boucle pour installer et charger les packages
for (pkg in packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg, dependencies = T)
  }
  library(pkg, character.only = TRUE)
}

##-- charger la base de données via le lien web
link.to.data <- "https://marieetienne.github.io/datasets/overshootday_overview.csv"
df <- read.csv(link.to.data)
```

## Analyse exploratoire des données

```{r}
nrow(df); ncol(df) ;dim(df)
```
Les données sont composées de **182** lignes et de ***13*** colonnes.

## Résumé statitique des variables

On utilise la commande ***summary(df)*** tout simplement, mais pour une question d'exthétique on utilise ce code.

```{r}
##-- summary pour les variable numériques
summary.df.num <- sapply(df[sapply(df, is.numeric)], function(x) {
  c(
    min = min(x, na.rm = TRUE),
    Q1 = quantile(x, 0.25, na.rm = TRUE),
    Q3 = quantile(x, 0.75, na.rm = TRUE),
    med = quantile(x, 0.5, na.rm = TRUE),
    mean = mean(x, na.rm = TRUE),
    max = max(x, na.rm = TRUE),
    count = sum(!is.na(x)),
    sd = sd(x, na.rm = TRUE),
    `NA's` = round(sum(is.na(x)),0)
  )
})
summary.df.num <- as.data.frame(summary.df.num)
```

Ensuite nous affichons ce resumé dans un tableau : 

```{r, echo=FALSE}
kable(summary.df.num, caption = capTab("Résumé statistique des variables")) %>% add_footnote(label = "by Djamal Y. TOE") 
```

|   Nous constatons que ceraines variables ont des données manquantes, nous pouvons décider de soit les supprimer, soit les prédire avec des méthodes d'imputation en fonction de leurs importances. Mais pour le moment nous allons juste les supprimer.

```{r}
df <- na.omit(df)
nrow(df)
```

Ainsi nous passons de 182 à 162 lignes.

## Contruction de l'Analyse en composante principale

* **Le poids pour les pays** : Les tailles respectives des populations de chaques pays car cela garantit que l'analyse est représentative des différences globales, en tenant compte de l'impact démographique des pays.

* **Métrique** : Normalisation des données car les variables ne sont pas toutes sur la même échelle. Cela permet d'éviter que les variables avec de grosses valeurs (grandes échelles) dominent l'analyse.

* **variables sup** :
  - ***Quali sup*** : region, income_group
  - ***Quanti sup*** : pop
  
### Réalisation de l'ACP

- **Vérifions la corrélations entre les variables quantitatives**

```{r, fig.align='center', fig.cap=capFig("Matrice de corrélations"), fig.width = 12, fig.height = 7}
numeric.vars <- as.data.frame(df[sapply(df, is.numeric)])
M <- round(cor(numeric.vars),2) #- Calculer la matrice de corrélation

##-- créer un objet qui contient une palette de couleur pour le gradiant dans le plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))

##-- dessiner le graphique
corrplot(M, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", #- ajout des coefficients correlation
         tl.col="black", tl.srt=45, tl.cex = 1
         , #- couleur, rotation et police de texte des libellés 
         ##-- ne pas afficher les coefficients de corrélations sur la diagonale (ils valent tous 1)
         diag=FALSE 
         ) 

```
|     On voit qu'il y' a quand même des variables qui sont <<fortement corrélées>> (pour l'affirmer avec plus d'assurance il serait judicieux de faire un test billatéral de corrélation de **Pearson** avec la commande cor.test(method = "pearson", alternative = "two.sided")).

- **Création du modèle de l'ACP**

```{r}
data.pca <- df[,-1] #- sélectionner toute les variables sauf la variable pays
rownames(data.pca) <- df[,1] #- renommer les lignes avec les noms des pays (individus)
poids <- df$pop
pca.model <- PCA(data.pca, scale.unit = TRUE,
                 quali.sup = c("region", "income_group"),
                 graph = FALSE,
                 row.w = data.pca$pop,
                 quanti.sup = 6)

##- explor(pca.model) pour une interface interactive
```

### Recupération  des valeurs propres et des variances

```{r}
eigen.values <- pca.model$eig
knitr::kable(eigen.values[1:3,2:3], caption = capTab("Inerties expliquées par les 3 premiers axes"))
```
On remarque que les axes 1,2 et 3 représentent respectivement **69,76, 16,49 et 4,09**, donc au total **91,11**

On pourrait aussi visualiser le graphique des valeurs propres : 

```{r, fig.align='center', fig.cap=capFig("Valeurs proppres")}
plt.eig <- fviz_eig(pca.model, title = "Valeurs propres avec Singapore")
```

### Qualité de representation des plans / sur les plans

- **Qualité de representation des plans**

|   Le premier plan a un taux d'inertie supérieur à **86 %**, il capte une grande partie de l'information présente dans les données ce qui signifie qu'il à une bonne qualité de representation alors que le second (1-3) en capte environ **74,63 %** donc a une faible qualité de représenatation comparé au premier. En depit de ce fait, les deux plans ont quand même qualité de représentation si mous fions au critère du taux d'inertie.


- **Qualité de representation sur les plans**

  * ***(1-2)***
  
**LES VARIABLES**
  
```{r, fig.align='center', fig.cap=capFig("Qualités de representation des variables"), fig.width=11, fig.height=6}
graph.cos2.var <- fviz_pca_var(pca.model,col.var="cos2", gradient.cols=c("#F1C40F","#2ECC71","#8E44AD"), repel=TRUE, ggtheme = theme_light())

graph.cos2.var
```

  Concernant les variables, on constate qu'elles toutes sont bien representées avec des cosinus carrés qui ont une valeur minimale environ 0,8 à part les variables **biocapacity, life_expectancy, number_of_countries_required** qui ont un cosinus carrés qui vaut environ 0,7.
  
**LES INDIVIDUS**

```{r}
threshold <- 0.85
data.ind.cos2 <- pca.model$ind$cos2

dim1 <- data.ind.cos2[,"Dim.1"]
dim1 <- dim1[dim1 >= threshold]
countries.dim1 <- names(dim1)
names(dim1) <-  NULL

dim2 <- data.ind.cos2[,"Dim.2"]
dim2 <- dim2[dim2 >= 0.6]
countries.dim2 <- names(dim2)
names(dim2) <-  NULL

##-- crétion des dataframes 
dim1.df <- data.frame(
  Country = countries.dim1,
  `Cos carré` = dim1
) %>% arrange(desc(dim1))


dim2.df <- data.frame(
  Country = countries.dim2,
  `Cos carré` = dim2
) %>% arrange(desc(dim2))


##-- création des tableaux kableExtra
dim1.tbl <- kableExtra::kbl(dim1.df, caption = capTab("Individus ayant un cosinus carré supérieur ou égal à 0,85 sur l'axe 1")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% add_footnote(label = "Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv")

dim2.tbl <- kableExtra::kbl(dim2.df, caption = capTab("Individus ayant un cosinus carré supérieur ou égal à 0,6 sur l'axe 2")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))  %>% add_footnote(label = "Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv")
```

:::: {.columns}


::: {.column width="48%"}
```{r}
dim1.tbl
```

:::

::: {.column width="48%"}
```{r}
dim2.tbl 
```

:::


::::

* **AXE 1** : On voit que les pays (individus) comme le Togo, le Yemen, les USA, le Rwanda sont tres bien representés. **RMRQ : Il y en a d'autres**

* **AXE 2** : Il n'y a que 6 pays qui sont bien représentés sur cet axe. Il s'agit de la Namibie, le Paraguay, le Brésil, la Bolivie et Barbados. 

  
***REMARQUE : *** *Pour le plan formé des axes 1 et 3, on peut procéder la même que celle en amont*


### Caractérisation des axes

```{r, fig.align='center', fig.cap=capFig("Cercle de corrélation des variables et leur contribution à la formation des axes"), fig.width=11, fig.height=6}
graph.contrib.var <- fviz_pca_var(pca.model,col.var="contrib", gradient.cols=c("#F1C40F","#2ECC71","#8E44AD"), repel=TRUE, ggtheme = theme_light())

graph.contrib.var
```


### Comment l’ACP est-elle modifiée si on retire Singapour de l’analyse ?

```{r}
data.pca.sans.singapore <- data.pca %>% filter(rownames(data.pca) != "Singapore")
poids <- df$pop
pca.model.sans.singapore <- PCA(data.pca.sans.singapore, scale.unit = TRUE,
                 quali.sup = c("region", "income_group"),
                 graph = FALSE,
                 row.w = data.pca.sans.singapore$pop,
                 quanti.sup = 6)

##-- explor(pca.model)
```

```{r, fig.align='center', fig.cap=capFig("Comparaison des valeurs propres issues de l'ACP aevc et sans Singapore"), fig.width=11, fig.height=6}
plt.eig.sans.sing <- fviz_eig(pca.model.sans.singapore, title = "Valeurs propres sans Singapore") 
comp.eig <-  cowplot::plot_grid(
  plt.eig,
  plt.eig.sans.sing,
  ncol = 2
)+ theme_light()
comp.eig
```

|   On voit que rien ne se passe (pas de changement brusque) au niveau de la qualité des axes. Voyons de plus prêt ce qui se passe :

```{r, fig.align='center', fig.cap=capFig("Comparaison des valeurs propres issues de l'ACP aevc et sans Singapore"), fig.width=11, fig.height=6}
plot.indiv.avec.sing <- fviz_pca_ind(pca.model) + 
                        theme_light()
plot.indiv.avec.sing
```

|   On voit que **Singapore** est atypique. Cela pourrait signifier que Singapore participe fortement à la formation de l'axe 2 (point plus proche de l'axe 1).

```{r}
data <- as.data.frame(pca.model$ind$contrib)
data <-  data %>% arrange(desc(Dim.2)) %>% head(10)
kableExtra::kbl(data, caption = capTab("Contribution des individus à la formation des axes par contribution décroissante suivant l'axe 2")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))  %>% add_footnote(label = "Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv")
```
Et pourtant il contribue fortement à la formation de l'axe 2, il est même celui qui contribue les plus à la formation des axes. Le fait que **Singapore** contribue le plus à la formation des axes et que rien ne change lorsqu'il est retiré de l'analyse s'explique tout simplement par **sa taille de population**. En effet la taille de la population a été utilisée comme poids des individus qui sont ici les pays.

## Identifications des pays en fonction de leur groupe de revenu

> Il s'agit juste d'une parenthèse qui n'a rien avoir avec l'objectif de l'étude

```{r, fig.align='center', fig.cap=capFig("Affichage des 40 individus qui contribuent le plus à la formation des axes en fonction de leur groupe de revenu"), fig.width=11, fig.height=6}

##-- Définitions des groupes de revenus
income_groups_definitions <- c(
  "UM" = "Upper-Middle",
  "LM" = "Lower-Middle",
  "HI" = "High Income",
  "LI" = "Low Income"
)


##-- Ajouter une colonne avec les définitions correspondantes
data.pca$income_group_def <- as.factor(income_groups_definitions[data.pca$income_group])


graph_indiv <- fviz_pca_ind(
  pca.model,
  select.ind = list(
    contrib = 50
  ),
  invisible = c("quanti.sup","ind.sup"),
  habillage = data.pca$income_group_def,
  addEllipses = TRUE,
  repel = TRUE,
) + theme_light() 


graph_indiv

#hc.pca <- HCPC(pca.model, nb.clust=3)
```

|       On voit que les groupes ne sont pas bien séparés, raison pour laquelle les ellipses ont des partie qui coïncident. Cela pourrait signifier que les les groupes de revenus sont  trop similaires pour etre clairement séparés sur les axes sélectionnés (dans le plan des composantes principales). Cela pourrait aussi fait cas d'hétérogénéité, c'est-à-dire que les groupes ne sont pas homogènes (grande variabilité intra-groupe).
|       A bien regarder, nous aurions pu les regrouper en trois groupes de revenu, en combinant les ***Low income*** et les ***Low middle income***, les ***Upper middle income (avec certains pays du High income)*** et enfin le dernier groupe ***les high income***. Il faut noter que tout ça n'est que purement visuel même si on a quand même une grande partie de l'information contenue dans les données rien qu'avec ces deux plans **(plus de 80%)**.

### Deux ACP différentes

> Pourquoi réaliser deux ACP différentes ?

|   Pour simplement calculer la 1-ère valeur propre de chaque groupe de variables (***empreinte écologique et de developpement***) afin de les utiliser ponderer les variables afin qu'elles contribuent de manière équitable à la formation des axes. Pour plus de détails [aller à la sous-section](#afm) et sur le site de mon professeur de **Méthodes d'Analyses Factorielles** en cliquanr sur ce lien <https://marieetienne.github.io/MAF/01_afm.html#/title-slide>.

On préfère utiliser la première valeur propre ($\lambda_{k1}$) car elle capturerait l’essentiel de l’inertie d’un groupe et permet une pondération cohérente et équilibrée dans l’AFM. La seconde valeur propre reflète des structures secondaires ou résiduelles qui ne sont pas pertinentes pour normaliser les contributions des groupes dans l’analyse globale.

```{r}
variables.empreinte <- df[, c("total_prod", "total_cons", "biocapacity", "number_of_earths_required", "overshoot_day", "pop")]
rownames(variables.empreinte) <- df$country
variables.developpement <- df[, c("life_expectancy", "hdi", "per_capita_gdp","pop")]
rownames(variables.developpement) <- df$country
```


#### ACP sur les variables d'empruntes écologiques

|       Il s'agit ici de faire l'ACP que sur les variables d'empruntes écologiques et de mettre les autres variables (de developpement) en quantitatives supplémentaires.


```{r}
data.pca <- df[,-1] ## sélectionner toute les variables sauf la variable pays
rownames(data.pca) <- df[,1] ## renommer les lignes avec les noms des pays (individus)
poids <- df$pop
acp_empreinte <- PCA(data.pca, scale.unit = TRUE,
                 quali.sup = c("region", "income_group"),
                 graph = FALSE,
                 row.w = data.pca$pop,
                 quanti.sup = c(6,1,2,3))

##-- 1ere valeur propre
acp_empreinte$eig[1,1]
```

La première valeur propre est : ***4,12***


#### ACP sur les variables d'empruntes écologiques


```{r}
acp.developpement <- PCA(data.pca, scale.unit = TRUE,
                 quali.sup = c("region", "income_group"),
                 graph = FALSE,
                 row.w = data.pca$pop,
                 quanti.sup = 6:12)

##-- 1ere valeur propre
acp.developpement$eig[1,1]
```

La première valeur propre est : ***2,59***

#### Réalisons l'AFM manuellement

```{r}
variables.empreinte.pond <- variables.empreinte[,-ncol(variables.empreinte)]/sqrt(acp_empreinte$eig[1,1])

variables.developpement.pond <- variables.developpement[,-ncol(variables.developpement)]/sqrt(
  acp.developpement$eig[1,1]
)

variables.empreinte.pond$group <- "Empreinte écologique"
variables.developpement.pond$group <- "developpement"

df.afm <- cbind(variables.empreinte.pond, 
                variables.developpement.pond,
                pop = df$pop,
                region = df$region,
                income_group = df$income_group)

acp.afm <- PCA(df.afm, scale.unit = TRUE,
                 quali.sup = c("region", "income_group", "group"),
                 graph = FALSE,
                 row.w = df.afm$pop,
                 quanti.sup = 9)

variance.cum.val.prop.2acp <- acp.afm$eig[, c(1,3)]
colnames(variance.cum.val.prop.2acp) <- c("Valeur propres", "Pourcentage de variance cumulée")
```

```{r }
#| label: variance.cum.val.prop.2acp
kableExtra::kbl(variance.cum.val.prop.2acp, caption = capTab("Valeurs propres et variances cumulées de chaque axes issues d'une AFM manuelle")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% add_footnote(label = "Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv")
```



## REALISATION DE L'AFM {#afm}

> Pourquoi réaliser une AFM au lieu d'une ACP tout court?

|       L'**A**nalyse **F**actorielle **M**ultiple ***(AFM)*** permet d'aller au-delà des limites d'une **A**nalyse en **C**omposantes **P**rincipales ***(ACP)*** classique, particulièrement lorsque les variables d'un jeu de données ne sont pas à la même échelle ou lorsqu'elles sont organisées en groupes. La normalisation dans l'ACP sert à ramener toutes les variables à une même échelle, évitant ainsi que certaines variables dominent artificiellement l'analyse en raison de leur variance plus élevée. Par exemple d'autres ont une contribution élevée que d'autres alors que c'est juste l'unité de mésure qui pèse plus.

|   Cependant, cette normalisation n'est pas suffisante lorsque les variables sont regroupées par thématique ou nature. Par exemple, supposons un jeu de données contenant $n$ variables, parmi lesquelles $n - k$ $\text{avec k telque  } \forall \text{ j} \neq \text{k, }$
$\text{n - k} > \text{n - j où n - j est le nombre de variables dans tous les autres groupes ou dans un autre groupe j}$ appartiennent à un groupe $i$ .Dans ce cas, le groupe $i$ peut influencer de manière disproportionnée les résultats de l'ACP, simplement en raison de la taille du groupe. Cela signifie que, même après normalisation, le poids collectif du groupe $i$ dans la construction des composantes principales pourrait être trop important par rapport aux autres groupes.

|   L'**AFM** résout ce problème en intégrant un poids équilibré entre les groupes. Elle considère chaque groupe comme une entité, indépendamment du nombre de variables qu'il contient. Cela permet une contribution équitable des groupes aux axes factoriels. Par conséquent, l'AFM est particulièrement adaptée dans des contextes où les variables appartiennent à des thématiques distinctes (par exemple, des groupes liés à des disciplines différentes : santé, économie, environnement).
Il est crucial de préserver l'équilibre des contributions entre ces thématiques pour éviter les biais d'interprétation.
Ainsi, l'AFM fournit une perspective multidimensionnelle plus équilibrée et pertinente pour analyser des jeux de données complexes, tout en respectant la structure inhérente des variables

> Réalisons l'AFM à présent

```{r}
#-- création de la table pour l'AFM. Les vriables doivent être rangées 
#-- suivant le groupe (variables du groupe 1 ensuite celles du groupe 2 ...)
data.afm <- data.pca %>%
  select(
    life_expectancy, hdi, per_capita_gdp,  ##-- Variables de developpement
    total_prod, total_cons, biocapacity, ##------ Variables
    number_of_earths_required, overshoot_day ##-- d'empreinte écologique
)

model.afm <- MFA(
    data.afm, 
    group = c(5, 3), ##-- Spécifie le nombre de variables dans chaque groupe
    type = rep("s", 2), ##-- Indique que les variables doivent être normalisées pour chaque groupe
    name.group = c("Developpement", "Empreinte ecologique"), ##-- Nommer les groupes
    graph = F  ##-- Générer un graphique
)
variance.cum.val.prop.afm <- model.afm$eig[, c(1,3)]
colnames(variance.cum.val.prop.afm) <- c("Valeur propres", "Pourcentage de variance cumulée")
```


```{r}
kableExtra::kbl(variance.cum.val.prop.afm, caption = capTab("Valeurs propres et variances cumulées de chaque axes issues d'une AFM avec R")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% add_footnote(label = "Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv")
```

On voit qu'il n'y a pas très grande différence entre les pourcentage de variances cumulées des deux **AFM** (manuellement @variance.cum.val.prop.2acp et avec R) parcontre les valeurs propres ne sont pas les mêmes.

> On peut visualiser les variables

```{r, fig.align='center', fig.cap=capFig("Visualisation des variables dans le plan (1,2) avec les résultats de l'AFM"), fig.width=11, fig.height=6}
fviz_mfa_var(model.afm, axes = c(1,2), choice= "quanti.var", repel = T) + theme_light()
```

> On peut visualiser leur qualité de representation

```{r , fig.align='center', fig.cap=capFig("Qualité de représentation des variables dans le plan (1,2) avec les résultats de l'AFM"), fig.width=11, fig.height=6}
graph.cos.var.afm <- fviz_mfa_var(model.afm, axes = c(1,2), choice= "quanti.var", col.var="cos2", gradient.cols=c("#F1C40F","#2ECC71","#8E44AD"), repel = T, ggtheme = theme_light())

graph.cos.var.afm
```
> Leur contribution à la formation des axes

```{r, fig.align='center', fig.cap=capFig("Cercle de corrélation des variables et leur contribution à la formation des axes"), fig.width=11, fig.height=6}
graph.contrib.var.afm <- fviz_mfa_var(model.afm,col.var="contrib", gradient.cols=c("#F1C40F","#2ECC71","#8E44AD"), repel=TRUE, ggtheme = theme_light())

graph.contrib.var.afm
```
