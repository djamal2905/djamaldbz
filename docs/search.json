[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "Bienvenue sur mon site personnel.\nJe suis Djamal Y. TOE, statisticien passionné par les analyses avancées, la visualisation de données, et la résolution de problèmes complexes à travers des approches quantitatives. Ce site présente mes projets, mes recherches, et mes contributions dans le domaine des statistiques et de la science des données. Je suis titulaire d’une licence en statistique-informatique et actuellement élève ingénieur en Data Science à l’Ecole Nationale de la statistique et de l’Analyse de l’Information à Bruz Rennes, France."
  },
  {
    "objectID": "about.html#à-propos-de-moi",
    "href": "about.html#à-propos-de-moi",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "À propos de moi",
    "text": "À propos de moi\nJe combine mes compétences en statistiques, programmation et analyse de données pour transformer des ensembles de données en informations exploitables. Mon objectif est d’améliorer la prise de décision grâce à des modèles et des méthodes robustes. Ayant effectuer des stages en entreprises, j’ai appris beaucoup de choses notamment en bio-statistiques et sur les modélisations qui y sont utilisées. J’ai également des connaissance en cartographie (avec R)."
  },
  {
    "objectID": "about.html#expérience",
    "href": "about.html#expérience",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Expérience",
    "text": "Expérience\n\nStagiaire au Centre de Méthodologie et de Gestion de données au Centre MURAZ sis Bobo-Dioulasso, Burkina Faso\n\ndurée : 6 mois Août 2023 - Janvier 2024\nTravail effectué :\n\nAnalyse exploratoire de données\nTests statistiques et Modélisations\nSystème d’information géographique\nRedaction automatique de rapports\n\n\nStagiaire au Centre de Méthodologie et de Gestion de données au Centre MURAZ & l’Institut National de recherche en Science de la Santé sis Bobo-Dioulasso, Burkina Faso\n\ndurée : 5 mois Janvier 2024 - Mai 2024"
  },
  {
    "objectID": "about.html#projets-et-contributions",
    "href": "about.html#projets-et-contributions",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Projets et Contributions",
    "text": "Projets et Contributions\n\n1. Analyses Factorielles et Visualisations Avancées\n\nDéveloppement d’analyses factorielles (ACP, AFC, ACM, AFM, AFD) pour comprendre les structures complexes des données.\nVisualisation interactive des résultats pour une meilleure interprétation (Rshiny, Python Jupyter Dash).\n\n\n\n2. Modèles de Régression et Prévision\n\nRégression linéaire, logistique, et mixte\nPrévisions à l’aide de modèles de séries temporelles\n\n\n\n3. Applications Statistiques\n\nDéveloppement d’outils interactifs pour l’analyse de données (Shiny, Quarto)\nRapports automatisés (Rmarkdown, Bookdown)\n\n\n\n4. Applications Bureau et Web\n\nDévéloppement de logiciel bureau pour la gestion des caisses\nDévéloppement de sites web avec python&Django (pas trop avancé)\n\n\n\n5. Computer vision\nDébute dans la vision par ordinateur avec :\n\nLa SVM (Support Vector Machine)\nLe KNN (K- Nearest Neighbour)\nL’ACP (L’Analyse en Composante Principale)\nLes reseaux de neurones convolutionnels (à venir)\n\n\n\n6. Langages de programmtion et outils statistiques\n\nPython, Java, C++ & C\nR, Stata, SPSS\nHtml, Css\nOffice et Suites\nSystème de Gestion de données :\n\nMySql\nOracle SQL"
  },
  {
    "objectID": "about.html#dernières-publications",
    "href": "about.html#dernières-publications",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Dernières Publications",
    "text": "Dernières Publications\n\nExploration des Techniques d’Analyse Factorielle\nGuide Pratique pour les Modèles Mixtes\nVisualisation Dynamique avec R et Quarto\nFormation en python"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html",
    "href": "ANALYSES_FACTORIELLES/TP03.html",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "",
    "text": "packages_ &lt;- c(\"ggplot2\", \"dplyr\",\"readxl\",\"cowplot\")\n\nfor (pkg in packages_) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#quelques-définitions",
    "href": "ANALYSES_FACTORIELLES/TP03.html#quelques-définitions",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Quelques définitions",
    "text": "Quelques définitions\n      Le calcul de l’empreinte écologique et de la biocapacité nous aide à répondre à la question de recherche fondamentale : Quelle est la demande des êtres humains envers les surfaces biologiquement productives (empreinte écologique) par rapport à la quantité que la planète (ou la surface productive d’une région) peut régénérer sur ces surfaces (biocapacité) ?\n\nHectare global (gha) : C’est l’unité choisie pour exprimer toutes les quantités d’intérêt concernant la consommation/émission de carbone. Une unité de surface correspondant à la productivité moyenne d’un hectare de terres mondiales. Un hectare de terres agricoles vaudra plus d’hectares globaux qu’un hectare de désert.\nEmpreinte écologique (en gha par personne) : Le nombre de gha requis pour produire les besoins et absorber les déchets d’un pays.\nBiocapacité (en gha) : La capacité d’un pays à produire ce dont il a besoin et à absorber ses déchets (réserve écologique).\nJour de dépassement : Jour de l’année où la demande d’un pays dépasse sa biocapacité annuelle."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#chargement-des-données",
    "href": "ANALYSES_FACTORIELLES/TP03.html#chargement-des-données",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Chargement des données",
    "text": "Chargement des données\n\n##-- Installer et Charger les packages requis\n###--- vecteurs des packages\npackages &lt;- c(\"factoextra\", \"corrr\", \"FactoMineR\", \"dplyr\",\"kableExtra\",\"corrplot\",\n              \"explor\")\n\n###--- Boucle pour installer et charger les packages\nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}\n\n##-- charger la base de données via le lien web\nlink.to.data &lt;- \"https://marieetienne.github.io/datasets/overshootday_overview.csv\"\ndf &lt;- read.csv(link.to.data)"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#analyse-exploratoire-des-données",
    "href": "ANALYSES_FACTORIELLES/TP03.html#analyse-exploratoire-des-données",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Analyse exploratoire des données",
    "text": "Analyse exploratoire des données\n\nnrow(df); ncol(df) ;dim(df)\n\n[1] 182\n\n\n[1] 13\n\n\n[1] 182  13\n\n\nLes données sont composées de 182 lignes et de 13 colonnes."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#résumé-statitique-des-variables",
    "href": "ANALYSES_FACTORIELLES/TP03.html#résumé-statitique-des-variables",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Résumé statitique des variables",
    "text": "Résumé statitique des variables\nOn utilise la commande summary(df) tout simplement, mais pour une question d’exthétique on utilise ce code.\n\n##-- summary pour les variable numériques\nsummary.df.num &lt;- sapply(df[sapply(df, is.numeric)], function(x) {\n  c(\n    min = min(x, na.rm = TRUE),\n    Q1 = quantile(x, 0.25, na.rm = TRUE),\n    Q3 = quantile(x, 0.75, na.rm = TRUE),\n    med = quantile(x, 0.5, na.rm = TRUE),\n    mean = mean(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    count = sum(!is.na(x)),\n    sd = sd(x, na.rm = TRUE),\n    `NA's` = round(sum(is.na(x)),0)\n  )\n})\nsummary.df.num &lt;- as.data.frame(summary.df.num)\n\nEnsuite nous affichons ce resumé dans un tableau :\n\n\n\nTableau 1 : Résumé statistique des variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlife_expectancy\nhdi\nper_capita_gdp\npop\ntotal_prod\ntotal_cons\nbiocapacity\nnumber_of_countries_required\nnumber_of_earths_required\novershoot_day\n\n\n\n\nmin\n52,525000\n0,3850000\n732,836\n0,06200\n0,371747\n0,5540298\n0,1041268\n0,0180633\n0,3668548\n41,0000\n\n\nQ1.25%\n65,747000\n0,5945000\n4888,255\n2,64100\n1,156834\n1,2195240\n0,6633750\n0,8273357\n0,8075166\n143,0000\n\n\nQ3.75%\n76,400695\n0,8350000\n31670,000\n32,91550\n3,828778\n3,8418335\n2,6656718\n2,7330613\n2,5438978\n365,0000\n\n\nmed.50%\n71,900000\n0,7310000\n13548,200\n10,01950\n1,924223\n2,3197815\n1,3622344\n1,7280656\n1,5360601\n239,0000\n\n\nmean\n71,180320\n0,7177193\n21139,464\n43,47636\n2,879469\n2,9624675\n3,5569055\n2,9127705\n1,9616192\n239,7802\n\n\nmax\n84,445610\n0,9620000\n120505,000\n1480,63200\n13,394536\n13,1263342\n85,6461100\n55,1061868\n8,6916969\n365,0000\n\n\ncount\n175,000000\n171,0000000\n163,000\n182,00000\n182,000000\n181,0000000\n181,0000000\n181,0000000\n181,0000000\n182,0000\n\n\nsd\n7,615465\n0,1533110\n22330,819\n156,03751\n2,515235\n2,1957327\n10,0256869\n5,1916277\n1,4539202\n109,5507\n\n\nNA’s\n7,000000\n11,0000000\n19,000\n0,00000\n0,000000\n1,0000000\n1,0000000\n1,0000000\n1,0000000\n0,0000\n\n\n\nNote: aby Djamal Y. TOE\n\n\n  Nous constatons que ceraines variables ont des données manquantes, nous pouvons décider de soit les supprimer, soit les prédire avec des méthodes d’imputation en fonction de leurs importances. Mais pour le moment nous allons juste les supprimer.\n\ndf &lt;- na.omit(df)\nnrow(df)\n\n[1] 162\n\n\nAinsi nous passons de 182 à 162 lignes."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#contruction-de-lanalyse-en-composante-principale",
    "href": "ANALYSES_FACTORIELLES/TP03.html#contruction-de-lanalyse-en-composante-principale",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Contruction de l’Analyse en composante principale",
    "text": "Contruction de l’Analyse en composante principale\n\nLe poids pour les pays : Les tailles respectives des populations de chaques pays car cela garantit que l’analyse est représentative des différences globales, en tenant compte de l’impact démographique des pays.\nMétrique : Normalisation des données car les variables ne sont pas toutes sur la même échelle. Cela permet d’éviter que les variables avec de grosses valeurs (grandes échelles) dominent l’analyse.\nvariables sup :\n\nQuali sup : region, income_group\nQuanti sup : pop\n\n\n\nRéalisation de l’ACP\n\nVérifions la corrélations entre les variables quantitatives\n\n\nnumeric.vars &lt;- as.data.frame(df[sapply(df, is.numeric)])\nM &lt;- round(cor(numeric.vars),2) #- Calculer la matrice de corrélation\n\n##-- créer un objet qui contient une palette de couleur pour le gradiant dans le plot\ncol &lt;- colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\n##-- dessiner le graphique\ncorrplot(M, method=\"color\", col=col(200),  \n         type=\"upper\", order=\"hclust\", \n         addCoef.col = \"black\", #- ajout des coefficients correlation\n         tl.col=\"black\", tl.srt=45, tl.cex = 1\n         , #- couleur, rotation et police de texte des libellés \n         ##-- ne pas afficher les coefficients de corrélations sur la diagonale (ils valent tous 1)\n         diag=FALSE \n         ) \n\n\n\n\nFigure 1 : Matrice de corrélations\n\n\n\n\n    On voit qu’il y’ a quand même des variables qui sont &lt;&gt; (pour l’affirmer avec plus d’assurance il serait judicieux de faire un test billatéral de corrélation de Pearson avec la commande cor.test(method = “pearson”, alternative = “two.sided”)).\n\nCréation du modèle de l’ACP\n\n\ndata.pca &lt;- df[,-1] #- sélectionner toute les variables sauf la variable pays\nrownames(data.pca) &lt;- df[,1] #- renommer les lignes avec les noms des pays (individus)\npoids &lt;- df$pop\npca.model &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = 6)\n\n##- explor(pca.model) pour une interface interactive\n\n\n\nRecupération des valeurs propres et des variances\n\neigen.values &lt;- pca.model$eig\nknitr::kable(eigen.values[1:3,2:3], caption = capTab(\"Inerties expliquées par les 3 premiers axes\"))\n\n\nTableau 2 : Inerties expliquées par les 3 premiers axes\n\n\n\npercentage of variance\ncumulative percentage of variance\n\n\n\n\ncomp 1\n69,758338\n69,75834\n\n\ncomp 2\n16,485374\n86,24371\n\n\ncomp 3\n4,865912\n91,10962\n\n\n\n\n\nOn remarque que les axes 1,2 et 3 représentent respectivement 69,76, 16,49 et 4,09, donc au total 91,11\nOn pourrait aussi visualiser le graphique des valeurs propres :\n\nplt.eig &lt;- fviz_eig(pca.model, title = \"Valeurs propres avec Singapore\")\n\n\n\nQualité de representation des plans / sur les plans\n\nQualité de representation des plans\n\n  Le premier plan a un taux d’inertie supérieur à 86 %, il capte une grande partie de l’information présente dans les données ce qui signifie qu’il à une bonne qualité de representation alors que le second (1-3) en capte environ 74,63 % donc a une faible qualité de représenatation comparé au premier. En depit de ce fait, les deux plans ont quand même qualité de représentation si mous fions au critère du taux d’inertie.\n\nQualité de representation sur les plans\n\n(1-2)\n\n\nLES VARIABLES\n\ngraph.cos2.var &lt;- fviz_pca_var(pca.model,col.var=\"cos2\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.cos2.var\n\n\n\n\nFigure 3 : Qualités de representation des variables\n\n\n\n\nConcernant les variables, on constate qu’elles toutes sont bien representées avec des cosinus carrés qui ont une valeur minimale environ 0,8 à part les variables biocapacity, life_expectancy, number_of_countries_required qui ont un cosinus carrés qui vaut environ 0,7.\nLES INDIVIDUS\n\nthreshold &lt;- 0.85\ndata.ind.cos2 &lt;- pca.model$ind$cos2\n\ndim1 &lt;- data.ind.cos2[,\"Dim.1\"]\ndim1 &lt;- dim1[dim1 &gt;= threshold]\ncountries.dim1 &lt;- names(dim1)\nnames(dim1) &lt;-  NULL\n\ndim2 &lt;- data.ind.cos2[,\"Dim.2\"]\ndim2 &lt;- dim2[dim2 &gt;= 0.6]\ncountries.dim2 &lt;- names(dim2)\nnames(dim2) &lt;-  NULL\n\n##-- crétion des dataframes \ndim1.df &lt;- data.frame(\n  Country = countries.dim1,\n  `Cos carré` = dim1\n) %&gt;% arrange(desc(dim1))\n\n\ndim2.df &lt;- data.frame(\n  Country = countries.dim2,\n  `Cos carré` = dim2\n) %&gt;% arrange(desc(dim2))\n\n\n##-- création des tableaux kableExtra\ndim1.tbl &lt;- kableExtra::kbl(dim1.df, caption = capTab(\"Individus ayant un cosinus carré supérieur ou égal à 0,85 sur l'axe 1\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\ndim2.tbl &lt;- kableExtra::kbl(dim2.df, caption = capTab(\"Individus ayant un cosinus carré supérieur ou égal à 0,6 sur l'axe 2\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))  %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\n\ndim1.tbl\n\n\n\nTableau 3 : Individus ayant un cosinus carré supérieur ou égal à 0,85 sur l'axe 1\n\n\nCountry\nCos.carré\n\n\n\n\nRwanda\n0,9810454\n\n\nNepal\n0,9772128\n\n\nHaiti\n0,9763067\n\n\nPakistan\n0,9745537\n\n\nSao Tome and Principe\n0,9617076\n\n\nIndia\n0,9558559\n\n\nKenya\n0,9448689\n\n\nTogo\n0,9425662\n\n\nMalawi\n0,9425394\n\n\nTanzania, United Republic of\n0,9419010\n\n\nEthiopia\n0,9390190\n\n\nGambia\n0,9377395\n\n\nPoland\n0,9272053\n\n\nYemen\n0,9228666\n\n\nCzech Republic\n0,9218239\n\n\nAustria\n0,9047663\n\n\nGuatemala\n0,9044971\n\n\nMyanmar\n0,8964483\n\n\nBurundi\n0,8916493\n\n\nCambodia\n0,8911437\n\n\nDenmark\n0,8896874\n\n\nUnited States of America\n0,8875048\n\n\nSlovenia\n0,8840522\n\n\nMalaysia\n0,8840507\n\n\nBenin\n0,8831711\n\n\nSudan\n0,8713134\n\n\nSenegal\n0,8705626\n\n\nTimor-Leste\n0,8640862\n\n\nBelgium\n0,8604596\n\n\nAngola\n0,8591836\n\n\nGhana\n0,8579621\n\n\nSierra Leone\n0,8542504\n\n\nSlovakia\n0,8524619\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\ndim2.tbl \n\n\n\nTableau 4 : Individus ayant un cosinus carré supérieur ou égal à 0,6 sur l'axe 2\n\n\nCountry\nCos.carré\n\n\n\n\nNamibia\n0,7502317\n\n\nParaguay\n0,6807204\n\n\nBrazil\n0,6672407\n\n\nBolivia\n0,6609662\n\n\nBarbados\n0,6458843\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\nAXE 1 : On voit que les pays (individus) comme le Togo, le Yemen, les USA, le Rwanda sont tres bien representés. RMRQ : Il y en a d’autres\nAXE 2 : Il n’y a que 6 pays qui sont bien représentés sur cet axe. Il s’agit de la Namibie, le Paraguay, le Brésil, la Bolivie et Barbados.\n\nREMARQUE :  Pour le plan formé des axes 1 et 3, on peut procéder la même que celle en amont\n\n\nCaractérisation des axes\n\ngraph.contrib.var &lt;- fviz_pca_var(pca.model,col.var=\"contrib\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.contrib.var\n\n\n\n\nFigure 4 : Cercle de corrélation des variables et leur contribution à la formation des axes\n\n\n\n\n\n\nComment l’ACP est-elle modifiée si on retire Singapour de l’analyse ?\n\ndata.pca.sans.singapore &lt;- data.pca %&gt;% filter(rownames(data.pca) != \"Singapore\")\npoids &lt;- df$pop\npca.model.sans.singapore &lt;- PCA(data.pca.sans.singapore, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca.sans.singapore$pop,\n                 quanti.sup = 6)\n\n##-- explor(pca.model)\n\n\nplt.eig.sans.sing &lt;- fviz_eig(pca.model.sans.singapore, title = \"Valeurs propres sans Singapore\") \ncomp.eig &lt;-  cowplot::plot_grid(\n  plt.eig,\n  plt.eig.sans.sing,\n  ncol = 2\n)+ theme_light()\ncomp.eig\n\n\n\n\nFigure 5 : Comparaison des valeurs propres issues de l’ACP aevc et sans Singapore\n\n\n\n\n  On voit que rien ne se passe (pas de changement brusque) au niveau de la qualité des axes. Voyons de plus prêt ce qui se passe :\n\nplot.indiv.avec.sing &lt;- fviz_pca_ind(pca.model) + \n                        theme_light()\nplot.indiv.avec.sing\n\n\n\n\nFigure 6 : Comparaison des valeurs propres issues de l’ACP aevc et sans Singapore\n\n\n\n\n  On voit que Singapore est atypique. Cela pourrait signifier que Singapore participe fortement à la formation de l’axe 2 (point plus proche de l’axe 1).\n\ndata &lt;- as.data.frame(pca.model$ind$contrib)\ndata &lt;-  data %&gt;% arrange(desc(Dim.2)) %&gt;% head(10)\nkableExtra::kbl(data, caption = capTab(\"Contribution des individus à la formation des axes par contribution décroissante suivant l'axe 2\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))  %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 5 : Contribution des individus à la formation des axes par contribution décroissante suivant l'axe 2\n\n\n\nDim.1\nDim.2\nDim.3\nDim.4\nDim.5\n\n\n\n\nSingapore\n0,7259355\n15,139608\n28,5623680\n9,9266768\n5,6933884\n\n\nBrazil\n0,2363938\n11,748028\n0,2780798\n16,7474472\n0,1489935\n\n\nChina\n6,3338962\n10,346574\n0,9583694\n1,3599693\n36,9834265\n\n\nRussian Federation\n3,7284884\n10,223438\n4,1131775\n0,1010599\n3,8319553\n\n\nCanada\n3,7127169\n6,392768\n0,8335954\n3,8719645\n0,0267550\n\n\nJapan\n2,3347045\n4,109062\n0,8491595\n0,6848764\n2,2016647\n\n\nUnited States of America\n21,6581050\n3,434086\n3,0985377\n22,3391460\n5,4054986\n\n\nKorea, Republic of\n1,9711036\n2,758601\n0,8457859\n0,0962515\n0,0745840\n\n\nAustralia\n1,8672806\n2,568678\n0,0085414\n1,3778438\n0,3505079\n\n\nGuyana\n0,0605633\n2,548944\n1,0759061\n8,5175485\n0,9606747\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEt pourtant il contribue fortement à la formation de l’axe 2, il est même celui qui contribue les plus à la formation des axes. Le fait que Singapore contribue le plus à la formation des axes et que rien ne change lorsqu’il est retiré de l’analyse s’explique tout simplement par sa taille de population. En effet la taille de la population a été utilisée comme poids des individus qui sont ici les pays."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#identifications-des-pays-en-fonction-de-leur-groupe-de-revenu",
    "href": "ANALYSES_FACTORIELLES/TP03.html#identifications-des-pays-en-fonction-de-leur-groupe-de-revenu",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Identifications des pays en fonction de leur groupe de revenu",
    "text": "Identifications des pays en fonction de leur groupe de revenu\n\nIl s’agit juste d’une parenthèse qui n’a rien avoir avec l’objectif de l’étude\n\n\n##-- Définitions des groupes de revenus\nincome_groups_definitions &lt;- c(\n  \"UM\" = \"Upper-Middle\",\n  \"LM\" = \"Lower-Middle\",\n  \"HI\" = \"High Income\",\n  \"LI\" = \"Low Income\"\n)\n\n\n##-- Ajouter une colonne avec les définitions correspondantes\ndata.pca$income_group_def &lt;- as.factor(income_groups_definitions[data.pca$income_group])\n\n\ngraph_indiv &lt;- fviz_pca_ind(\n  pca.model,\n  select.ind = list(\n    contrib = 50\n  ),\n  invisible = c(\"quanti.sup\",\"ind.sup\"),\n  habillage = data.pca$income_group_def,\n  addEllipses = TRUE,\n  repel = TRUE,\n) + theme_light() \n\n\ngraph_indiv\n\n\n\n\nFigure 7 : Affichage des 40 individus qui contribuent le plus à la formation des axes en fonction de leur groupe de revenu\n\n\n\n#hc.pca &lt;- HCPC(pca.model, nb.clust=3)\n\n      On voit que les groupes ne sont pas bien séparés, raison pour laquelle les ellipses ont des partie qui coïncident. Cela pourrait signifier que les les groupes de revenus sont trop similaires pour etre clairement séparés sur les axes sélectionnés (dans le plan des composantes principales). Cela pourrait aussi fait cas d’hétérogénéité, c’est-à-dire que les groupes ne sont pas homogènes (grande variabilité intra-groupe).\n      A bien regarder, nous aurions pu les regrouper en trois groupes de revenu, en combinant les Low income et les Low middle income, les Upper middle income (avec certains pays du High income) et enfin le dernier groupe les high income. Il faut noter que tout ça n’est que purement visuel même si on a quand même une grande partie de l’information contenue dans les données rien qu’avec ces deux plans (plus de 80%).\n\nDeux ACP différentes\n\nPourquoi réaliser deux ACP différentes ?\n\n  Pour simplement calculer la 1-ère valeur propre de chaque groupe de variables (empreinte écologique et de developpement) afin de les utiliser ponderer les variables afin qu’elles contribuent de manière équitable à la formation des axes. Pour plus de détails aller à la sous-section et sur le site de mon professeur de Méthodes d’Analyses Factorielles en cliquanr sur ce lien https://marieetienne.github.io/MAF/01_afm.html#/title-slide.\nOn préfère utiliser la première valeur propre (\\(\\lambda_{k1}\\)) car elle capturerait l’essentiel de l’inertie d’un groupe et permet une pondération cohérente et équilibrée dans l’AFM. La seconde valeur propre reflète des structures secondaires ou résiduelles qui ne sont pas pertinentes pour normaliser les contributions des groupes dans l’analyse globale.\n\nvariables.empreinte &lt;- df[, c(\"total_prod\", \"total_cons\", \"biocapacity\", \"number_of_earths_required\", \"overshoot_day\", \"pop\")]\nrownames(variables.empreinte) &lt;- df$country\nvariables.developpement &lt;- df[, c(\"life_expectancy\", \"hdi\", \"per_capita_gdp\",\"pop\")]\nrownames(variables.developpement) &lt;- df$country\n\n\nACP sur les variables d’empruntes écologiques\n      Il s’agit ici de faire l’ACP que sur les variables d’empruntes écologiques et de mettre les autres variables (de developpement) en quantitatives supplémentaires.\n\ndata.pca &lt;- df[,-1] ## sélectionner toute les variables sauf la variable pays\nrownames(data.pca) &lt;- df[,1] ## renommer les lignes avec les noms des pays (individus)\npoids &lt;- df$pop\nacp_empreinte &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = c(6,1,2,3))\n\n##-- 1ere valeur propre\nacp_empreinte$eig[1,1]\n\n[1] 4,115324\n\n\nLa première valeur propre est : 4,12\n\n\nACP sur les variables d’empruntes écologiques\n\nacp.developpement &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = 6:12)\n\n##-- 1ere valeur propre\nacp.developpement$eig[1,1]\n\n[1] 2,592046\n\n\nLa première valeur propre est : 2,59\n\n\nRéalisons l’AFM manuellement\n\nvariables.empreinte.pond &lt;- variables.empreinte[,-ncol(variables.empreinte)]/sqrt(acp_empreinte$eig[1,1])\n\nvariables.developpement.pond &lt;- variables.developpement[,-ncol(variables.developpement)]/sqrt(\n  acp.developpement$eig[1,1]\n)\n\nvariables.empreinte.pond$group &lt;- \"Empreinte écologique\"\nvariables.developpement.pond$group &lt;- \"developpement\"\n\ndf.afm &lt;- cbind(variables.empreinte.pond, \n                variables.developpement.pond,\n                pop = df$pop,\n                region = df$region,\n                income_group = df$income_group)\n\nacp.afm &lt;- PCA(df.afm, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\", \"group\"),\n                 graph = FALSE,\n                 row.w = df.afm$pop,\n                 quanti.sup = 9)\n\nvariance.cum.val.prop.2acp &lt;- acp.afm$eig[, c(1,3)]\ncolnames(variance.cum.val.prop.2acp) &lt;- c(\"Valeur propres\", \"Pourcentage de variance cumulée\")\n\n\nkableExtra::kbl(variance.cum.val.prop.2acp, caption = capTab(\"Valeurs propres et variances cumulées de chaque axes issues d'une AFM manuelle\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 6 : Valeurs propres et variances cumulées de chaque axes issues d'une AFM manuelle\n\n\n\nValeur propres\nPourcentage de variance cumulée\n\n\n\n\ncomp 1\n5,4257689\n67,82211\n\n\ncomp 2\n1,3223267\n84,35120\n\n\ncomp 3\n0,6522681\n92,50455\n\n\ncomp 4\n0,3973880\n97,47190\n\n\ncomp 5\n0,1005256\n98,72847\n\n\ncomp 6\n0,0689548\n99,59040\n\n\ncomp 7\n0,0327679\n100,00000\n\n\ncomp 8\n0,0000000\n100,00000\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#afm",
    "href": "ANALYSES_FACTORIELLES/TP03.html#afm",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "REALISATION DE L’AFM",
    "text": "REALISATION DE L’AFM\n\nPourquoi réaliser une AFM au lieu d’une ACP tout court?\n\n      L’Analyse Factorielle Multiple (AFM) permet d’aller au-delà des limites d’une Analyse en Composantes Principales (ACP) classique, particulièrement lorsque les variables d’un jeu de données ne sont pas à la même échelle ou lorsqu’elles sont organisées en groupes. La normalisation dans l’ACP sert à ramener toutes les variables à une même échelle, évitant ainsi que certaines variables dominent artificiellement l’analyse en raison de leur variance plus élevée. Par exemple d’autres ont une contribution élevée que d’autres alors que c’est juste l’unité de mésure qui pèse plus.\n  Cependant, cette normalisation n’est pas suffisante lorsque les variables sont regroupées par thématique ou nature. Par exemple, supposons un jeu de données contenant \\(n\\) variables, parmi lesquelles \\(n - k\\) \\(\\text{avec k telque  } \\forall \\text{ j} \\neq \\text{k, }\\)\n\\(\\text{n - k} &gt; \\text{n - j où n - j est le nombre de variables dans tous les autres groupes ou dans un autre groupe j}\\) appartiennent à un groupe \\(i\\) .Dans ce cas, le groupe \\(i\\) peut influencer de manière disproportionnée les résultats de l’ACP, simplement en raison de la taille du groupe. Cela signifie que, même après normalisation, le poids collectif du groupe \\(i\\) dans la construction des composantes principales pourrait être trop important par rapport aux autres groupes.\n  L’AFM résout ce problème en intégrant un poids équilibré entre les groupes. Elle considère chaque groupe comme une entité, indépendamment du nombre de variables qu’il contient. Cela permet une contribution équitable des groupes aux axes factoriels. Par conséquent, l’AFM est particulièrement adaptée dans des contextes où les variables appartiennent à des thématiques distinctes (par exemple, des groupes liés à des disciplines différentes : santé, économie, environnement).\nIl est crucial de préserver l’équilibre des contributions entre ces thématiques pour éviter les biais d’interprétation. Ainsi, l’AFM fournit une perspective multidimensionnelle plus équilibrée et pertinente pour analyser des jeux de données complexes, tout en respectant la structure inhérente des variables\n\nRéalisons l’AFM à présent\n\n\n#-- création de la table pour l'AFM. Les vriables doivent être rangées \n#-- suivant le groupe (variables du groupe 1 ensuite celles du groupe 2 ...)\ndata.afm &lt;- data.pca %&gt;%\n  select(\n    life_expectancy, hdi, per_capita_gdp,  ##-- Variables de developpement\n    total_prod, total_cons, biocapacity, ##------ Variables\n    number_of_earths_required, overshoot_day ##-- d'empreinte écologique\n)\n\nmodel.afm &lt;- MFA(\n    data.afm, \n    group = c(5, 3), ##-- Spécifie le nombre de variables dans chaque groupe\n    type = rep(\"s\", 2), ##-- Indique que les variables doivent être normalisées pour chaque groupe\n    name.group = c(\"Developpement\", \"Empreinte ecologique\"), ##-- Nommer les groupes\n    graph = F  ##-- Générer un graphique\n)\nvariance.cum.val.prop.afm &lt;- model.afm$eig[, c(1,3)]\ncolnames(variance.cum.val.prop.afm) &lt;- c(\"Valeur propres\", \"Pourcentage de variance cumulée\")\n\n\nkableExtra::kbl(variance.cum.val.prop.afm, caption = capTab(\"Valeurs propres et variances cumulées de chaque axes issues d'une AFM avec R\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 7 : Valeurs propres et variances cumulées de chaque axes issues d'une AFM avec R\n\n\n\nValeur propres\nPourcentage de variance cumulée\n\n\n\n\ncomp 1\n1,9203865\n67,85068\n\n\ncomp 2\n0,5123847\n85,95414\n\n\ncomp 3\n0,2050340\n93,19836\n\n\ncomp 4\n0,0790131\n95,99003\n\n\ncomp 5\n0,0659024\n98,31848\n\n\ncomp 6\n0,0327210\n99,47457\n\n\ncomp 7\n0,0148713\n100,00000\n\n\ncomp 8\n0,0000000\n100,00000\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\nOn voit qu’il n’y a pas très grande différence entre les pourcentage de variances cumulées des deux AFM (manuellement @variance.cum.val.prop.2acp et avec R) parcontre les valeurs propres ne sont pas les mêmes.\n\nOn peut visualiser les variables\n\n\nfviz_mfa_var(model.afm, axes = c(1,2), choice= \"quanti.var\", repel = T) + theme_light()\n\n\n\n\nFigure 8 : Visualisation des variables dans le plan (1,2) avec les résultats de l’AFM\n\n\n\n\n\nOn peut visualiser leur qualité de representation\n\n\ngraph.cos.var.afm &lt;- fviz_mfa_var(model.afm, axes = c(1,2), choice= \"quanti.var\", col.var=\"cos2\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel = T, ggtheme = theme_light())\n\ngraph.cos.var.afm\n\n\n\n\nFigure 9 : Qualité de représentation des variables dans le plan (1,2) avec les résultats de l’AFM\n\n\n\n\n\nLeur contribution à la formation des axes\n\n\ngraph.contrib.var.afm &lt;- fviz_mfa_var(model.afm,col.var=\"contrib\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.contrib.var.afm\n\n\n\n\nFigure 10 : Cercle de corrélation des variables et leur contribution à la formation des axes"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#contexte",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#contexte",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Contexte",
    "text": "Contexte\n\nLe jeu de données mtcars est l’un des ensembles de données les plus connus en statistiques et science des données. Il contient des informations sur les spécifications techniques et les performances de 32 modèles de voitures des années 1970. Ce dataset offre une opportunité unique d’explorer des relations entre des variables mécaniques, comme la consommation en carburant, la puissance ou encore le poids des véhicules."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#problématique",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#problématique",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Problématique",
    "text": "Problématique\n\nComment exploiter les relations entre les caractéristiques des voitures pour identifier des groupes ou des tendances qui pourraient aider à la prise de décision dans le secteur automobile ?"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectif-général",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectif-général",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Objectif général",
    "text": "Objectif général\n\nÉtudier les relations entre les caractéristiques techniques des voitures afin de dégager des tendances et des informations utiles pour la conception ou la sélection des véhicules."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectifs-spécifiques",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectifs-spécifiques",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Objectifs spécifiques",
    "text": "Objectifs spécifiques\n\n\nExplorer les relations entre la consommation en carburant (mpg) et les caractéristiques mécaniques\n\n\n\n\nIdentifier des groupes de voitures ayant des caractéristiques similaires à l’aide d’analyses descriptives et graphiques."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#matériels",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#matériels",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Matériels",
    "text": "Matériels\n\nLogiciel utilisé : RStudio avec les packages nécessaires (ggplot2, dplyr, cowplot, etc.)\nSource des données : Jeu de données intégré mtcars."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\n\nNettoyage des données : Vérification des valeurs manquantes ou aberrantes.\nAnalyse descriptive : Moyennes, médianes, écart-types pour chaque variable."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nModélisation multivariée : Variables utilisées\n\nmpg : Consommation de carburant en miles par gallon (variable dépendante).\nwt : Poids du véhicule (en milliers de livres).\ncyl : Nombre de cylindres du moteur.\nam: Type de transmission (0 = automatique, 1 = manuelle).\ncarb : Nombre de carburateurs.\nhp : Puissance brute du moteur (en chevaux-vapeur)."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-2",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nModélisation multivariée :\n\\[\n\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\noù :\n\n\\(Y\\): Vecteur des valeurs observées (dépendantes ici mpg)\n\\(X\\) : Matrice des variables explicatives (indépendantes), incluant une colonne de 1 pour l’intercept.\n\\(\\beta\\) : Vecteur des coefficients estimés du modèle.\n\\(\\epsilon\\) : Vecteur des erreurs résiduelles."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-3",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-3",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nTests de significativité des coefficients\nTest t de Student\n\nHypothèse nulle  \\(H_0\\) : le coefficient est égal à zéro (c’est-à-dire, la variable n’a pas d’effet significatif).\nHypothèse alternative \\(H_a\\) : Le coefficient est différent de zéro.\n\nSi la p-valeur est inférieure à un seuil significatif \\(p &lt; 0.05\\), nous rejetons l’hypothèse nulle et concluons que la variable a un effet significatif sur la variable dépendante."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-4",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-4",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nSignificativité globale du modèle : Test F\n\nHypothèse nulle \\(H_0\\): Tous les coefficients sont égaux à zéro (pas de pouvoir explicatif).\nHypothèse alternative \\(H_a\\) : Au moins un coefficient est différent de zéro (le modèle est significatif).\n\nSi la p-valeur du test \\(F\\) est inférieure à \\(0.05\\), nous rejetons l’hypothèse nulle et concluons que le modèle est significatif."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-5",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-5",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nR-carré : qualité d’ajustement\n\n\\(R^2\\) varie entre 0 et 1 :\n\nUn \\(R^2\\) proche de 1 signifie que le modèle explique bien les variations de la variable dépendante.\nUn \\(R^2\\) proche de 0 indique que le modèle n’explique que peu ou pas les variations de la variable dépendante."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-6",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-6",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\n\nVisualisations :\n\nGraphiques de dispersion (scatterplots) pour étudier les corrélations\nHistogrammes pour analyser la distribution des variables"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#présentation-de-léchantillon",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#présentation-de-léchantillon",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Présentation de l’échantillon",
    "text": "Présentation de l’échantillon\n\n\n\n\n\nTable 1 : Description des variables du jeu de données\n\n\nColonne\nNom\nDescription\n\n\n\n\n[,1]\nmpg\nMiles par gallon (US)\n\n\n[,2]\ncyl\nNombre de cylindres\n\n\n[,3]\ndisp\nCylindrée (en pouces cubes)\n\n\n[,4]\nhp\nPuissance brute (chevaux)\n\n\n[,5]\ndrat\nRapport du pont arrière\n\n\n[,6]\nwt\nPoids (en milliers de livres)\n\n\n[,7]\nqsec\nTemps pour parcourir 1/4 de mile\n\n\n[,8]\nvs\nType de moteur (0 = V, 1 = ligne droite)\n\n\n[,9]\nam\nType de transmission (0 = automatique, 1 = manuelle)\n\n\n[,10]\ngear\nNombre de vitesses avant\n\n\n[,11]\ncarb\nNombre de carburateurs\n\n\n\na R : mtcars"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#présentation-de-léchantillon-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#présentation-de-léchantillon-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Présentation de l’échantillon",
    "text": "Présentation de l’échantillon\nRésumé statistiques\n\n\n\n\nTable 2 : Résumé statistique des variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nmin\n10.400000\n4.000000\n71.1000\n52.00000\n2.7600000\n1.5130000\n14.500000\n0.0000000\n0.0000000\n3.0000000\n1.0000\n\n\nQ1.25%\n15.425000\n4.000000\n120.8250\n96.50000\n3.0800000\n2.5812500\n16.892500\n0.0000000\n0.0000000\n3.0000000\n2.0000\n\n\nQ3.75%\n22.800000\n8.000000\n326.0000\n180.00000\n3.9200000\n3.6100000\n18.900000\n1.0000000\n1.0000000\n4.0000000\n4.0000\n\n\nmed.50%\n19.200000\n6.000000\n196.3000\n123.00000\n3.6950000\n3.3250000\n17.710000\n0.0000000\n0.0000000\n4.0000000\n2.0000\n\n\nmean\n20.090625\n6.187500\n230.7219\n146.68750\n3.5965625\n3.2172500\n17.848750\n0.4375000\n0.4062500\n3.6875000\n2.8125\n\n\nmax\n33.900000\n8.000000\n472.0000\n335.00000\n4.9300000\n5.4240000\n22.900000\n1.0000000\n1.0000000\n5.0000000\n8.0000\n\n\ncount\n32.000000\n32.000000\n32.0000\n32.00000\n32.0000000\n32.0000000\n32.000000\n32.0000000\n32.0000000\n32.0000000\n32.0000\n\n\nsd\n6.026948\n1.785922\n123.9387\n68.56287\n0.5346787\n0.9784574\n1.786943\n0.5040161\n0.4989909\n0.7378041\n1.6152\n\n\nNA’s\n0.000000\n0.000000\n0.0000\n0.00000\n0.0000000\n0.0000000\n0.000000\n0.0000000\n0.0000000\n0.0000000\n0.0000\n\n\n\nNote: aR : mtcars"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats principaux : Modélisation",
    "text": "Résultats principaux : Modélisation\nSélection de modèle en ajoutant ou en supprimant des variables pour minimiser l’AIC\n\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    wt\n-3.9\n-5.4, -2.5\n&lt;0.001\n    am\n2.9\n0.05, 5.8\n0.047\n    qsec\n1.2\n0.63, 1.8\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats principaux : Modélisation",
    "text": "Résultats principaux : Modélisation\n\nPoids (wt) : L’augmentation du poids réduit la consommation de carburant, avec un coefficient négatif significatif (p-value = 0.000199)\nNombre de cylindres (cyl) : L’effet des cylindres est légèrement négatif, mais le lien reste faible. p-value = 0.098480 (juste au seuil de signification à 0.1)."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation-2",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats principaux : Modélisation",
    "text": "Résultats principaux : Modélisation\n\nPuissance (hp) : Pas de relation directe significative entre la puissance et la consommation. p-value = 0.140015.\nOptimisation : Le modèle suggère que la réduction du poids des voitures pourrait améliorer leur efficacité énergétique."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats sécondaires",
    "text": "Résultats sécondaires\nRépartition des voitures par cylindres\n\nLa majorité des voitures ont 4 ou 8 cylindres."
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats sécondaires",
    "text": "Résultats sécondaires\nRépartition des voitures par transmission"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires-2",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats sécondaires",
    "text": "Résultats sécondaires"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-1",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Discussions",
    "text": "Discussions\n\nPoids (wt) : Impact significatif sur la consommation en carburant (mpg) avec une p-valeur très faible\nNombre de cylindres (cyl) : Effet marginalement significatif (p = 0,098)\nPuissance (hp) : Pas d’impact significatif sur la consommation (p = 0,14)"
  },
  {
    "objectID": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-2",
    "href": "FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Discussions",
    "text": "Discussions\n\nR² ajusté : 82,6 %, ce qui indique un bon ajustement du modèle\nTest F : Le modèle est globalement significatif (p &lt; 0,05).\nPuissance (hp) : Pas de relation directe significative entre la puissance et la consommation. p-value = 0.140015."
  },
  {
    "objectID": "FORMATIONS/presentations.html",
    "href": "FORMATIONS/presentations.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "packages &lt;- c(\"ggplot2\",\"haven\", \"gtsummary\", \"corrr\", \"MASS\",\n              \"dplyr\",\"haven\", \"rstatix\", \"tidyverse\", \"ggpubr\",\n              \"glue\", \"dplyr\",\"ggspatial\", \"ggrepel\",\n              \"readxl\", \"stringr\", \"colorspace\") \n            \nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "FORMATIONS/presentations.html#faire-ses-présentations-directement-avec-r-et-rstudio",
    "href": "FORMATIONS/presentations.html#faire-ses-présentations-directement-avec-r-et-rstudio",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Faire ses présentations directement avec R et Rstudio",
    "text": "Faire ses présentations directement avec R et Rstudio\n\nPourquoi utiliser R et Rstudio pour ses présentations ?\n\n      R et RStudio offrent des outils puissants pour créer des présentations dynamiques, reproductibles et intégrées à vos analyses de données. Voici quelques raisons :\n\nIntégration parfaite des analyses et des présentations :\n\nNous pouvons combiner code, graphiques, tableaux et explications textuelles dans un seul document. Cela garantit une reproductibilité totale : les résultats sont automatiquement mis à jour si vos données changent.\n\nFlexibilité avec RMarkdown :\n\nCréez des présentations dans divers formats : HTML (slidy, reveal.js), PDF (Beamer), ou powerpoint ppt. Les formats sont hautement personnalisables pour répondre à vos besoins esthétiques et fonctionnels.\n\nSimplification du travail collaboratif :\n\nIl y’a une possibilité de garder un fichier .tex pour ceux qui sont à l’aise avec latex.\n\n\nMaintenant allons-y !!!\n\n\n\n\n\nCommençons par une présentation revaljs\n\n\n\n\nInstaller les packages nécessaires\n\nAssurez-vous d’avoir le package revealjs installé. Si ce n’est pas le cas, installez-le avec :\ninstall.packages(\"revealjs\")\n\nCréer un fichier RMarkdown pour une présentation\n\nCréer un nouveau fichier RMarkdown :\n\nAllez dans : File &gt; New File &gt; Quarto presentation\nDans la fenêtre qui s’ouvre : Entrez un titre et un auteur. Dans l’option Default Output Format, choisissez From Template &gt; Revealjs Presentation.\n\n\nChanger l’en-tête YAML\n\nEn image voici, un descriptif visuel des 04 petites étapes pour la création du fichier avec des images :\n\n\n\n\n\n\nEtape 1\n\n\n\n\n\n\n\nEtape 2\n\n\n\n\n\n\n\n\n\nEtape 3\n\n\n\n\n\n\n\nEtape 4\n\n\n\n\n\n\n\n\n\nExplication de l’en-tête YAML"
  },
  {
    "objectID": "FORMATIONS/presentations.html#informations-générales",
    "href": "FORMATIONS/presentations.html#informations-générales",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Informations générales",
    "text": "Informations générales\n\ntitle : Titre principal de la présentation\n\nIci : “ANALYSE EXPLORATOIRE DES DONNEES MTCARS”. C’est ce qui s’affiche en haut de la première diapositive.\n\nauthor : Nom(s) des présentateur(s)\n\nIci : “Presented by Djamal Toe”.\n\ninstitute : Institution ou organisation associée\n\nIci : “National School for Statistic and Data Analysis”.\n-date : Date de la présentation\nIci, elle est générée dynamiquement avec : 2024-12-16. Cela affichera automatiquement la date du jour où le fichier est tricoté."
  },
  {
    "objectID": "FORMATIONS/presentations.html#format-et-personnalisation-reveal.js",
    "href": "FORMATIONS/presentations.html#format-et-personnalisation-reveal.js",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Format et personnalisation (reveal.js)",
    "text": "Format et personnalisation (reveal.js)\nLa section format: revealjs: contient des options spécifiques à la bibliothèque reveal.js, permettant de personnaliser la présentation.\n\nVitesse de transition:  transition-speed: fast définit la vitesse des transitions entre les diapositives. Options possibles : slow, normal, fast.\nAspect ratio :  aspect_ratio: \"16:9\" spécifie le ratio largeur/hauteur des diapositives. Le ratio “16:9” est idéal pour les écrans modernes (écran large). Autres options possibles : “4:3”, “3:2”, etc.\nMarges : margin: 0.02 définit l’espace vide autour du contenu de chaque diapositive. Une valeur faible (comme 0.02) maximise l’espace utilisé sur chaque diapositive.\nCentrage : center: true permet de Centrer le contenu verticalement et horizontalement sur chaque diapositive.\nPied de page : footer: “English classes with Milonnet” : Ajoute un texte en bas de chaque diapositive, comme une signature ou une note de contexte.\nLogo : logo: \"logo_ensai.png\" affiche un logo en haut à droite de chaque diapositive. L’image doit être placée dans le répertoire spécifié ou un chemin relatif correct doit être utilisé.\nCSS personnalisé : css: style.css permet d’utiliser un fichier CSS externe pour personnaliser les styles. Exemple : changer les polices, couleurs, tailles, etc. Le fichier style.css doit être dans le même répertoire ou le chemin approprié doit être indiqué.\nGestion des figure : fig_caption: yes active l’affichage des légendes sous les graphiques insérés.\nTable des matières (ToC) : toc: true active l’affichage d’une table des matières, toc-expand: false exige que les sections de la table des matières ne soient pas développées par défaut, toc-depth: 1 définit la profondeur de la hiérarchie affichée dans la table des matières (seulement les titres principaux #)."
  },
  {
    "objectID": "FORMATIONS/presentations.html#prévisualition",
    "href": "FORMATIONS/presentations.html#prévisualition",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Prévisualition",
    "text": "Prévisualition\n      Pendant que vous faites la présentations sur Rstudio, vous pouvez la présualiser. Regardez les images ci-après :\n\n\n\n\n\n\nPrevisualisation : etape 1\n\n\n\n\n\n\n\nPrevisualisation : etape 2\n\n\n\n\n\n\n\n\n\nCompilation et Previsualisation : etape 3\n\n\n\n\n\n\n\n\n\n\n\nViewer ou Presenation ?\n\n\n\nA l’étape 2 de la prévisualisation, il se peut que la prévisualisation apparaisse dans la partie Presentation juste à droite de l’onglet Viewer encerclé en rouge sur l’image."
  },
  {
    "objectID": "FORMATIONS/presentations.html#mise-en-forme-avec-le-fichier-css",
    "href": "FORMATIONS/presentations.html#mise-en-forme-avec-le-fichier-css",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Mise en forme avec le fichier CSS",
    "text": "Mise en forme avec le fichier CSS\n      Pour cette section ne vous inquietez pas si vous n’avez pas de connaissance en html ou en css, nous utiliserons juste un code css pour la mise en forme du titre."
  },
  {
    "objectID": "FORMATIONS/presentations.html#télécharger-le-fichier-de-la-présentation",
    "href": "FORMATIONS/presentations.html#télécharger-le-fichier-de-la-présentation",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Télécharger le fichier de la présentation",
    "text": "Télécharger le fichier de la présentation\nAvant de télécharger le fichier, vous pouvez voir ce qu’il donne en cliquant sur ce lien\nVous pouvez télécharger le fichier d’analyse exploratoire des données mtcars au format .qmd ci-dessous.\nTélécharger le fichier .qmd\nSi vous avez des questions, vous pouvez me contacter !!!\nRetour à la page d’accueuil"
  },
  {
    "objectID": "FORMATIONS/SIG.html",
    "href": "FORMATIONS/SIG.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "packages &lt;- c(\"ggplot2\",\"haven\", \"gtsummary\", \"corrr\", \"MASS\",\n              \"dplyr\",\"haven\", \"rstatix\", \"tidyverse\", \"ggpubr\",\n              \"glue\", \"dplyr\",\"ggspatial\", \"ggrepel\",\"marmap\", \n              \"readxl\", \"stringr\", \"colorspace\", \"sf\", \"viridis\",\n              \"tools\",\"ggspatial\",\"readxl\",\"openxlsx\",\"grid\",\n              \"outliers\",\"car\",\"ftExtra\",\"tibble\",\n              \"gtsummary\", \"wesanderson\", \"viridis\",\n              \"RColorBrewer\", \"knitr\", \"kableExtra\") \n            \nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "FORMATIONS/SIG.html#comment-faire-des-cartes-choroplèthes-et-des-cartes-de-proportions-avec-r",
    "href": "FORMATIONS/SIG.html#comment-faire-des-cartes-choroplèthes-et-des-cartes-de-proportions-avec-r",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Comment faire des cartes Choroplèthes et des cartes de proportions avec R ?",
    "text": "Comment faire des cartes Choroplèthes et des cartes de proportions avec R ?\n      Les cartes choroplèthes et les cartes de proportions sont des outils puissants pour visualiser des données géospatiales dans R. Ces cartes permettent de représenter des valeurs quantitatives (par exemple, des taux de population, des moyennes) sur des zones géographiques, souvent des régions administratives comme des départements, des communes, ou des zones géographiques personnalisées.\n\nIntroduction aux Cartes Choroplèthes et Cartes de Proportions\n\nLes cartes choroplèthes colorient les régions géographiques en fonction de valeurs numériques ou de proportions, facilitant l’analyse spatiale et la compréhension des variations géographiques. Elles sont couramment utilisées pour des données socio-économiques, de santé publique, ou des analyses environnementales.\nLes cartes de proportions sont similaires mais mettent davantage l’accent sur les ratios ou proportions par rapport à une valeur totale, comme des pourcentages ou des fractions de populations.\n\nNotions de Base : Polygones, Shapefiles et Coordonnées Avant de créer ces cartes, il est important de comprendre quelques notions de base, comme les polygones et les shapefiles :\n\n\n\n\n\n\n\nPolygones\n\n\n\nUne zone géographique est souvent représentée par un polygone, une forme géométrique fermée qui peut avoir plusieurs côtés. Par exemple, une commune ou un département sur une carte peut être représentée comme un polygone.\n\n\n\n\n\n\n\n\nShapefiles\n\n\n\nCe sont un format de fichier standard pour stocker des informations géospatiales, y compris les coordonnées de points, de lignes et de polygones. Ils peuvent contenir les géométries des entités géographiques ainsi que leurs attributs (valeurs associées à chaque région, comme le revenu moyen ou le taux de chômage).\n\n\n\n\n\n\n\n\nCoordonnées géographiques\n\n\n\nLes coordonnées (latitude et longitude) permettent de positionner ces polygones sur une carte. En R, on utilise des systèmes de coordonnées géographiques et projetées pour gérer et visualiser ces données.\n\n\nPlusieurs pakages permettent de visualiser les données avec les cartes, ici nous interessons aux packages glue et sf.\n\nZone d’étude\n\nSupposons que nous menions une étude au Burkina-Faso. Par exemple, nous mésurer des indicateurs tels que le taux de mortalité, la couverture sanitaire etc … Le Burkina Faso est un pays qui compte 13 regions, mais notre etude s’étend seulement sur 8 regions. Il convient de montrer toutes les regions, puis de mettre en exègue celles qui nous concernent.\n\nPlace au code\n\n\n\nvoir/cacher le code\n\n\n###---- Chargement des shapefiles src = GADM\nroot &lt;- getwd() ##-- la racine du repertoire\n\n##- La carte du pays sans les polygones des regions, communes et/ou departements\npath0 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_0.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath1 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_1.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath2 &lt;- paste0(\"/DATA_SIG/BFA2/gadm41_BFA_2.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath3 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_3.shp\")\n\n\n##-- selection des regions concernées\n\nstudy.area &lt;-  c(\"Boucle du Mouhoun\", \"Centre-Est\", \"Centre-Nord\",\n             \"Centre-Ouest\", \"Nord\", \"Sud-Ouest\",\n             \"Haut-Bassins\", \"Cascades\")\n\n##-- lecture des shapefiles\npays_shp &lt;- read_sf(glue(path0), quiet = T)\nregion_shp &lt;- read_sf(glue(path1), quiet = T)\n#commune_shp &lt;- read_sf(glue(path2), quiet = T)\n#province_shp &lt;- read_sf(glue(path3), quiet = T)\n\n##-- création d'une sous base avec les polygones des regions sélectionnés\n\ndata_region &lt;- region_shp %&gt;% filter(NAME_1 %in% study.area)\n\n\n##-- Study area colors\nstudy_zone_colors &lt;- c(\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\",\n                       \"#3FE1B8\", \"#9467bd\", \"#8c564b\",\n                       \"#00008B\", \"#4B0082\")\n\nstudy_zone_map &lt;- ggplot() +\n  geom_sf(data = pays_shp, aes(linewidth = \"Burkina Faso\"),fill = \"white\", color = \"black\") +\n  geom_sf(data = region_shp, aes(fill = ifelse(\n    NAME_1 %in% study.area,\n    \"Regions d'études\",\n    \"Autres regions\"\n  ) )) +\n  geom_sf_text(data = region_shp, aes(label = ifelse(\n    NAME_1 %in% study.area,\n    study.area,\n    \"\"\n  )), size = 4)+\n  ggspatial::annotation_scale(\n    location = \"br\",\n    bar_cols = c(\"black\", \"white\")\n  )  +\n  theme_light()+\n  ggspatial::annotation_north_arrow(\n    location = \"tr\", which_north = \"true\",\n    pad_x = unit(0.05, \"in\"), pad_y = unit(0.05, \"in\"),\n    style = ggspatial::north_arrow_nautical(\n      fill = c(\"black\", \"white\"),\n      line_col = \"black\"\n    )\n  )+\n  xlab(\"\")+\n  ylab(\"\")+\n  scale_linewidth_manual(values = c(1.2), name = \"\")+\n  scale_fill_manual(values = c(\"white\",\"#1f77b4\"), name=\"Zone d'étude\")+\n  theme_light() + \n  guides(\n    linewidth = guide_legend(order = 1),\n    fill = guide_legend(order = 2),\n    color = guide_legend(order = 3)\n  )\n\n\n\nstudy_zone_map\n\n\n\n\nCartographie de la zone d’étude\n\n\n\n\n\nExpliquons le code à présent\n\n\nCharger les fichier shapefiles :\n\nglue : pour preparer la structure du format (optionnel)\nreadsf : pour lire les fichiers shapefiles\n\nDefinir la zone d’étude : les fichier shapefile devient comme un dataframe, donc est manipulable au même titre que les fichiers excel, csv etc …\nOn trace d’abord la carte du pays, ensuite on ajoute la couche des regions (c’est-à-dire le shapefile des regions). On pourrait le faire simplement avec le shapefile des regions sans celui du pays.\nEnsuite on ajoute la couleur pour la zone concernée et les noms des regions sélectionnées avec geom_sf_text\nannotation_scale permet d’ajouter une barre d’échelle (scale bar) à une carte avec la position br pour dire bottom rigth (en bas à droite)\nannotation_north_arrow est utilisée pour ajouter une flèche du nord sur une carte créée avec ggplot2\nPour le reste il s’agit des fonctions qu’on utilise couramment avec ggplot2\n\n\n\nAfficher/Masquer le tableau\n\n\n\n\n\nTableau 1 : Les 10 premières lignes du shapefile\n\n\nGID_1\nGID_0\nCOUNTRY\nNAME_1\nVARNAME_1\nNL_NAME_1\nTYPE_1\nENGTYPE_1\nCC_1\nHASC_1\nISO_1\ngeometry\n\n\n\n\nBFA.1_1\nBFA\nBurkina Faso\nBoucle du Mouhoun\nNA\nNA\nRégion\nRegion\nNA\nBF.BO\nNA\nPOLYGON ((-2,73901 11,71249...\n\n\nBFA.2_1\nBFA\nBurkina Faso\nCascades\nNA\nNA\nRégion\nRegion\nNA\nBF.CD\nNA\nPOLYGON ((-4,591742 9,70225...\n\n\nBFA.7_1\nBFA\nBurkina Faso\nCentre\nNA\nNA\nRégion\nRegion\nNA\nBF.CT\nNA\nPOLYGON ((-1,2786 12,13921,...\n\n\nBFA.3_1\nBFA\nBurkina Faso\nCentre-Est\nNA\nNA\nRégion\nRegion\nNA\nBF.CE\nNA\nPOLYGON ((0,4371 11,67655, ...\n\n\nBFA.4_1\nBFA\nBurkina Faso\nCentre-Nord\nNA\nNA\nRégion\nRegion\nNA\nBF.CN\nNA\nPOLYGON ((-0,7773 12,66989,...\n\n\nBFA.5_1\nBFA\nBurkina Faso\nCentre-Ouest\nNA\nNA\nRégion\nRegion\nNA\nBF.CO\nNA\nPOLYGON ((-2,360162 11,0081...\n\n\nBFA.6_1\nBFA\nBurkina Faso\nCentre-Sud\nNA\nNA\nRégion\nRegion\nNA\nBF.CS\nNA\nPOLYGON ((-0,8624911 10,985...\n\n\nBFA.8_1\nBFA\nBurkina Faso\nEst\nNA\nNA\nRégion\nRegion\nNA\nBF.ES\nNA\nPOLYGON ((1,384436 11,44223...\n\n\nBFA.9_1\nBFA\nBurkina Faso\nHaut-Bassins\nNA\nNA\nRégion\nRegion\nNA\nBF.HB\nNA\nPOLYGON ((-4,08994 10,79044...\n\n\nBFA.10_1\nBFA\nBurkina Faso\nNord\nNA\nNA\nRégion\nRegion\nNA\nBF.NO\nNA\nPOLYGON ((-1,96586 12,67774...\n\n\n\na Source des données : GADM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCartes choroplèthes\n\n      Les cartes choroplèthes sont des représentations graphiques qui utilisent des nuances de couleurs pour illustrer des données quantitatives ou qualitatives sur des zones géographiques. Chaque zone est remplie d’une couleur qui correspond à une valeur spécifique ou à une plage de valeurs, facilitant ainsi l’analyse des variations spatiales des données.\nLes cartes choroplèthes sont idéales pour représenter des indicateurs comme le taux de mortalité, le revenu moyen, l’accès à l’eau potable, ou encore la couverture sanitaire par région.\n\nExemple de carte choroplèthe\nDans cet exemple, nous allons créer une carte choroplèthe montrant la couverture sanitaire par région au Burkina Faso, en utilisant les données fictives créées plus haut. pour les données, vous pouvez me contacter par email.\n\nEtape 1 : Charger les shapefiles et les données\n\nIci nous nous assurons que les shapefiles des régions et les données sont correctement chargés et liés entre eux. Pour cela on fait une jointure externe.\n\n##-- Joindre les données au shapefile\nregion_data &lt;- region_shp %&gt;% \n  left_join(data, by = c(\"NAME_1\" = \"Region\"))\n\nAvant de passer à l’étape 2, affichons les données générées avant jointure et ceux aprés jointures.\n\n\nAfficher/cacher le code\n\n\ntbl.avant.jointure &lt;- kbl(head(data,10)) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\ntbl.apres.jointure &lt;- kbl(head(data,10)) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  GADM\")\n\n\n\n\nAfficher/Masquer le tableau\n\n\ntbl.avant.jointure\ntbl.apres.jointure\n\n\nLes 10 premières lignes des tables\n\n\n\n\n\nAvant jointure\n\n\nRegion\nPopulation\nTaux_Mortalite\nCouverture_Sanitaire\nAcces_Eau_Potable\n\n\n\n\nBoucle du Mouhoun\n2365556\n8,74\n88,16\n60,73\n\n\nCascades\n2140778\n5,36\n81,77\n84,84\n\n\nCentre\n1533260\n8,69\n65,11\n72,53\n\n\nCentre-Est\n1880368\n6,37\n69,47\n84,61\n\n\nCentre-Nord\n1415029\n13,25\n67,23\n75,65\n\n\nCentre-Ouest\n1993028\n14,62\n67,68\n89,72\n\n\nCentre-Sud\n1090692\n9,86\n90,90\n62,17\n\n\nEst\n779143\n8,28\n63,79\n72,78\n\n\nHauts-Bassins\n1517049\n7,26\n92,69\n65,24\n\n\nNord\n1242644\n10,38\n79,21\n67,29\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAprès jointure\n\n\nRegion\nPopulation\nTaux_Mortalite\nCouverture_Sanitaire\nAcces_Eau_Potable\n\n\n\n\nBoucle du Mouhoun\n2365556\n8,74\n88,16\n60,73\n\n\nCascades\n2140778\n5,36\n81,77\n84,84\n\n\nCentre\n1533260\n8,69\n65,11\n72,53\n\n\nCentre-Est\n1880368\n6,37\n69,47\n84,61\n\n\nCentre-Nord\n1415029\n13,25\n67,23\n75,65\n\n\nCentre-Ouest\n1993028\n14,62\n67,68\n89,72\n\n\nCentre-Sud\n1090692\n9,86\n90,90\n62,17\n\n\nEst\n779143\n8,28\n63,79\n72,78\n\n\nHauts-Bassins\n1517049\n7,26\n92,69\n65,24\n\n\nNord\n1242644\n10,38\n79,21\n67,29\n\n\n\na Source des données : GADM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEtape 2 : Créer la carte choroplèthe\n\nUtilisez ggplot2 et geom_sf() pour afficher les régions et les colorer en fonction de la couverture sanitaire.\n\n##-  Carte choroplèthe\nchoropleth_map &lt;- ggplot(region_data) +\n  geom_sf(aes(fill = Couverture_Sanitaire), color = \"black\") +\n  scale_fill_viridis_c(\n    option = \"C\",\n    name = \"Couverture Sanitaire (%)\"\n  ) +\n  ggtitle(\"Carte choroplèthe : Couverture sanitaire par région\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\")\n  )\n\nchoropleth_map\n\n\n\n\nCouverture sanitaire par région\n\n\n\n\n\nEtape 3 :  Ajouter des éléments décoratifs\n\nAjoutons une barre d’échelle et une flèche du nord pour rendre la carte plus informative.\n\n##- Ajout des éléments décoratifs\nchoropleth_map &lt;- choropleth_map +\n  ggspatial::annotation_scale(location = \"br\") +\n  ggspatial::annotation_north_arrow(\n    location = \"tl\", style = north_arrow_nautical()\n  ) ###-- tl pour top-left (en haut à gauche)\n\nchoropleth_map\n\n\n\n\n\nInterpréter les résultats\n\nExaminez la carte générée et répondez aux questions suivantes : - Quelles régions ont la meilleure couverture sanitaire ? - Quelles régions doivent faire l’objet d’une attention particulière pour améliorer les conditions de vie ?\n\nExtensions possibles\n\nRéalisez une carte choroplèthe pour le taux de mortalité.\nAjoutez des annotations pour les régions ayant les valeurs extrêmes.\nExpérimentez avec d’autres palettes de couleurs en utilisant scale_fill_brewer() ou scale_fill_manual() etc ….\n\n\n\n\n\n\n\nDonnées discrètes ?\n\n\n\nIl se peut qu’il n’y ait pas une variabilité importante dans les données dans ce cas, au lieu d’avoir une palette, nous aurons juste des cases de couleurs comme s’agissait d’un indicateur discrèt. Dans ce cas, recoder juste cet indicateur en un indicateur qualitatif (regrouper par classe) et ensuite utiliser scale_fill_manual() pour definir vos couleurs manuellement ou laisser R le faire tout seul. Le graphique ci-dessous en est un exemple.\n\n\n\n\n\nExemple de carte avec un indicateur recodé\n\n\n\nCartes de proportions\n\n\n\n\nA suivre\n\n\n\n\nCartes de proportions avancées\n\n\n\n\n\n\nRetour à la page d’accueuil"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "",
    "text": "Bienvenue sur le site Djamaldbz, dédié à mes travaux en statistiques et informatique. Explorez mes projets, mes recherches, et mes publications."
  },
  {
    "objectID": "index.html#qui-suis-je",
    "href": "index.html#qui-suis-je",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Qui suis-je ?",
    "text": "Qui suis-je ?\nJe m’appelle Djamal Y. TOE, et je suis passionné par les statistiques et l’informatique. Mon parcours m’a amené à me concentrer sur l’analyse avancée et la résolution de problèmes à l’aide de méthodes quantitatives. Mon apprentissage est un voyage continu. Mon objectif est d’explorer de nouvelles approches et d’apporter des solutions pratiques, tout en restant ouvert à l’apprentissage et à l’amélioration constante dans le domaine des statistiques et de la science des données.\n\nEn savoir plus sur moi ici"
  },
  {
    "objectID": "index.html#mon-expertise",
    "href": "index.html#mon-expertise",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Mon expertise",
    "text": "Mon expertise\nJe combine mes compétences en statistiques, programmation et analyse de données pour résoudre des problèmes complexes et fournir des solutions pratiques.\nVoici un aperçu de mes domaines d’expertise :\n\nAnalyses Factorielles et Visualisation\nModèles de Régression et Prévisions\nApplications Statistiques Interactives\nDéveloppement d’Applications Bureau et Web\nVision par Ordinateur (Computer Vision en apprentissage)"
  },
  {
    "objectID": "index.html#mes-projets-récents",
    "href": "index.html#mes-projets-récents",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Mes projets récents",
    "text": "Mes projets récents\nVoici quelques-uns de mes projets récents dans le domaine des statistiques et de l’analyse de données :\n\nAnalyse Factorielle et Visualisation Avancée (available soon)\nModélisation de Régressions Mixtes pour des données complexes (available soon)\nDéveloppement d’outils interactifs pour la visualisation de données (available soon)\n\n\nVoir tous mes projets [Bientôt disponible]"
  },
  {
    "objectID": "index.html#dernières-publications",
    "href": "index.html#dernières-publications",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Dernières publications",
    "text": "Dernières publications\nVoici les dernières publications sur des sujets de statistiques et d’informatique que j’ai partagées :\n\nExploration des Techniques d’Analyse Factorielle\nComment faire des présentations avec R et Rstudio ?\nComment faire des cartes de proportions et des cartes choroplèthes avec R ?\n\n\nVoir toutes les publications [Bientôt disponible]"
  },
  {
    "objectID": "index.html#contactez-moi",
    "href": "index.html#contactez-moi",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Contactez-moi",
    "text": "Contactez-moi\nSi vous avez des questions ou souhaitez collaborer sur un projet, n’hésitez pas à me contacter !\n\nEnvoyer un message\n\n\n\n\nA propos de nous\nElève en Science de données à l’Ecole Nationale de la Statistique et de l’Analyse de l’Information en France, titulaire d’une licence en Statistiques-informatique.\nRéseaux sociaux\n\nFacebook\nTwitter\nLinkedIn\n\n\nCoordonnées\n\nAdresse : Rennes, 35000, France\nEmail : djamaltoe2905@gmail.com\nTéléphone : +33 ** ** ** ** **\n\nHeures de services\n\n\n\nJour\nHoraire\n\n\n\n\nLundi\n8h30pm - 9:30pm\n\n\nMardi - Vendredi\n7pm - 8pm\n\n\nSamedi\n9:30am - 10:30am\n\n\n\n\n\n\n\nInformations supplémentaires\n© 2024 DJAMAL DEV\nContact: djamaltoe2905@gmail.com\nLocalisation: Rennes, France\nTéléphone: +33 ** ** ** ** **"
  },
  {
    "objectID": "FORMATIONS/PAYANTES/R/Formation-en-R.html",
    "href": "FORMATIONS/PAYANTES/R/Formation-en-R.html",
    "title": "Djamaldbz - Formations en R en présentiel et en ligne",
    "section": "",
    "text": "Ces formations sont conçues pour différents publics cibles : étudiants en pharmacie, médecine, biologie, statistiques et ceux aui sont dans des domaines nécessitant les stats ou pas. Chaque session dure 2 heures, avec une fréquence de 2 sessions par semaine. Les formations débutent le 22 février 2025.\n\n\n\n\n5 000 FCFA par session de 2 heures.\nChaque formation complète comprend 4 sessions, soit 20 000 FCFA par participant.\n\n\n\n\n\n\n\nCalendrier des Formations\n\n\nDate\nPublic.cible\nSujet\n\n\n\n\n22 février\nPharmacie\nIntroduction à R\n\n\n22 février\nMédecine\nIntroduction à R\n\n\n22 février\nBiologie\nIntroduction à R\n\n\n26 février\nStatistiques\nR pour les statisticiens\n\n\n\n\n\n\n\n\n\n\n\nObjectif : Apprendre à gérer, analyser et visualiser des données pharmacologiques.\nSessions :\n\nIntroduction à R.\nGestion des données pharmacologiques.\nVisualisation des données.\nAnalyse statistique (tests t, ANOVA).\n\n\n\n\n\n\nObjectif : Explorer des données cliniques et épidémiologiques.\nSessions :\n\nIntroduction à R.\nStatistiques descriptives.\nVisualisation des données médicales.\n\n\n\n\n\n\nObjectif : Analyser des données biologiques\nSessions :\n\nIntroduction à R.\nVisualisation des données biologiques.\nAnalyse statistique.\n\n\n\n\n\n\nObjectif : Approfondir les outils statistiques et analytiques.\nSessions :\n\nR pour les statisticiens.\nVisualisations avancées avec ggplot2.\nModélisation statistique (modèles linéaires, généralisés).\nProgrammation avancée (création de fonctions, etc …).\n\n\n\n\n\n\n\n\nRappel\n\n\n\nPour celles et ceux qui ne font pas partie des domaines mentionnés, ne vous inquiétez pas : cette formation est conçue pour être accessible et adaptée à tous les profils. Vous en tirerez pleinement profit !\n\n\n\n\n\n\nLes participants bénéficieront de formations pratiques, avec des cas d’utilisation adaptés à leur domaine. Inscrivez-vous dès maintenant pour réserver votre place! 😊\n\nPOUR PLUS D’INFORMATIONS !!!\n\n      Veuillez contacter le numéro whatsapp suivant : +226 57036356"
  },
  {
    "objectID": "FORMATIONS/PAYANTES/R/Formation-en-R.html#plan-des-formations-en-r---niveau-1",
    "href": "FORMATIONS/PAYANTES/R/Formation-en-R.html#plan-des-formations-en-r---niveau-1",
    "title": "Djamaldbz - Formations en R en présentiel et en ligne",
    "section": "",
    "text": "Ces formations sont conçues pour différents publics cibles : étudiants en pharmacie, médecine, biologie, statistiques et ceux aui sont dans des domaines nécessitant les stats ou pas. Chaque session dure 2 heures, avec une fréquence de 2 sessions par semaine. Les formations débutent le 22 février 2025.\n\n\n\n\n5 000 FCFA par session de 2 heures.\nChaque formation complète comprend 4 sessions, soit 20 000 FCFA par participant.\n\n\n\n\n\n\n\nCalendrier des Formations\n\n\nDate\nPublic.cible\nSujet\n\n\n\n\n22 février\nPharmacie\nIntroduction à R\n\n\n22 février\nMédecine\nIntroduction à R\n\n\n22 février\nBiologie\nIntroduction à R\n\n\n26 février\nStatistiques\nR pour les statisticiens\n\n\n\n\n\n\n\n\n\n\n\nObjectif : Apprendre à gérer, analyser et visualiser des données pharmacologiques.\nSessions :\n\nIntroduction à R.\nGestion des données pharmacologiques.\nVisualisation des données.\nAnalyse statistique (tests t, ANOVA).\n\n\n\n\n\n\nObjectif : Explorer des données cliniques et épidémiologiques.\nSessions :\n\nIntroduction à R.\nStatistiques descriptives.\nVisualisation des données médicales.\n\n\n\n\n\n\nObjectif : Analyser des données biologiques\nSessions :\n\nIntroduction à R.\nVisualisation des données biologiques.\nAnalyse statistique.\n\n\n\n\n\n\nObjectif : Approfondir les outils statistiques et analytiques.\nSessions :\n\nR pour les statisticiens.\nVisualisations avancées avec ggplot2.\nModélisation statistique (modèles linéaires, généralisés).\nProgrammation avancée (création de fonctions, etc …).\n\n\n\n\n\n\n\n\nRappel\n\n\n\nPour celles et ceux qui ne font pas partie des domaines mentionnés, ne vous inquiétez pas : cette formation est conçue pour être accessible et adaptée à tous les profils. Vous en tirerez pleinement profit !\n\n\n\n\n\n\nLes participants bénéficieront de formations pratiques, avec des cas d’utilisation adaptés à leur domaine. Inscrivez-vous dès maintenant pour réserver votre place! 😊\n\nPOUR PLUS D’INFORMATIONS !!!\n\n      Veuillez contacter le numéro whatsapp suivant : +226 57036356"
  },
  {
    "objectID": "docs/ANALYSES_FACTORIELLES/TP03.html",
    "href": "docs/ANALYSES_FACTORIELLES/TP03.html",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "",
    "text": "packages_ &lt;- c(\"ggplot2\", \"dplyr\",\"readxl\",\"cowplot\")\n\nfor (pkg in packages_) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "docs/ANALYSES_FACTORIELLES/TP03.html#quelques-définitions",
    "href": "docs/ANALYSES_FACTORIELLES/TP03.html#quelques-définitions",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Quelques définitions",
    "text": "Quelques définitions\n      Le calcul de l’empreinte écologique et de la biocapacité nous aide à répondre à la question de recherche fondamentale : Quelle est la demande des êtres humains envers les surfaces biologiquement productives (empreinte écologique) par rapport à la quantité que la planète (ou la surface productive d’une région) peut régénérer sur ces surfaces (biocapacité) ?\n\nHectare global (gha) : C’est l’unité choisie pour exprimer toutes les quantités d’intérêt concernant la consommation/émission de carbone. Une unité de surface correspondant à la productivité moyenne d’un hectare de terres mondiales. Un hectare de terres agricoles vaudra plus d’hectares globaux qu’un hectare de désert.\nEmpreinte écologique (en gha par personne) : Le nombre de gha requis pour produire les besoins et absorber les déchets d’un pays.\nBiocapacité (en gha) : La capacité d’un pays à produire ce dont il a besoin et à absorber ses déchets (réserve écologique).\nJour de dépassement : Jour de l’année où la demande d’un pays dépasse sa biocapacité annuelle."
  },
  {
    "objectID": "docs/ANALYSES_FACTORIELLES/TP03.html#chargement-des-données",
    "href": "docs/ANALYSES_FACTORIELLES/TP03.html#chargement-des-données",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Chargement des données",
    "text": "Chargement des données\n\n##-- Installer et Charger les packages requis\n###--- vecteurs des packages\npackages &lt;- c(\"factoextra\", \"corrr\", \"FactoMineR\", \"dplyr\",\"kableExtra\",\"corrplot\",\n              \"explor\")\n\n###--- Boucle pour installer et charger les packages\nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}\n\n##-- charger la base de données via le lien web\nlink.to.data &lt;- \"https://marieetienne.github.io/datasets/overshootday_overview.csv\"\ndf &lt;- read.csv(link.to.data)"
  },
  {
    "objectID": "docs/ANALYSES_FACTORIELLES/TP03.html#analyse-exploratoire-des-données",
    "href": "docs/ANALYSES_FACTORIELLES/TP03.html#analyse-exploratoire-des-données",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Analyse exploratoire des données",
    "text": "Analyse exploratoire des données\n\nnrow(df); ncol(df) ;dim(df)\n\n[1] 182\n\n\n[1] 13\n\n\n[1] 182  13\n\n\nLes données sont composées de 182 lignes et de 13 colonnes."
  },
  {
    "objectID": "docs/ANALYSES_FACTORIELLES/TP03.html#résumé-statitique-des-variables",
    "href": "docs/ANALYSES_FACTORIELLES/TP03.html#résumé-statitique-des-variables",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Résumé statitique des variables",
    "text": "Résumé statitique des variables\nOn utilise la commande summary(df) tout simplement, mais pour une question d’exthétique on utilise ce code.\n\n##-- summary pour les variable numériques\nsummary.df.num &lt;- sapply(df[sapply(df, is.numeric)], function(x) {\n  c(\n    min = min(x, na.rm = TRUE),\n    Q1 = quantile(x, 0.25, na.rm = TRUE),\n    Q3 = quantile(x, 0.75, na.rm = TRUE),\n    med = quantile(x, 0.5, na.rm = TRUE),\n    mean = mean(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    count = sum(!is.na(x)),\n    sd = sd(x, na.rm = TRUE),\n    `NA's` = round(sum(is.na(x)),0)\n  )\n})\nsummary.df.num &lt;- as.data.frame(summary.df.num)\n\nEnsuite nous affichons ce resumé dans un tableau :\n\n\n\nTableau 1 : Résumé statistique des variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlife_expectancy\nhdi\nper_capita_gdp\npop\ntotal_prod\ntotal_cons\nbiocapacity\nnumber_of_countries_required\nnumber_of_earths_required\novershoot_day\n\n\n\n\nmin\n52,525000\n0,3850000\n732,836\n0,06200\n0,371747\n0,5540298\n0,1041268\n0,0180633\n0,3668548\n41,0000\n\n\nQ1.25%\n65,747000\n0,5945000\n4888,255\n2,64100\n1,156834\n1,2195240\n0,6633750\n0,8273357\n0,8075166\n143,0000\n\n\nQ3.75%\n76,400695\n0,8350000\n31670,000\n32,91550\n3,828778\n3,8418335\n2,6656718\n2,7330613\n2,5438978\n365,0000\n\n\nmed.50%\n71,900000\n0,7310000\n13548,200\n10,01950\n1,924223\n2,3197815\n1,3622344\n1,7280656\n1,5360601\n239,0000\n\n\nmean\n71,180320\n0,7177193\n21139,464\n43,47636\n2,879469\n2,9624675\n3,5569055\n2,9127705\n1,9616192\n239,7802\n\n\nmax\n84,445610\n0,9620000\n120505,000\n1480,63200\n13,394536\n13,1263342\n85,6461100\n55,1061868\n8,6916969\n365,0000\n\n\ncount\n175,000000\n171,0000000\n163,000\n182,00000\n182,000000\n181,0000000\n181,0000000\n181,0000000\n181,0000000\n182,0000\n\n\nsd\n7,615465\n0,1533110\n22330,819\n156,03751\n2,515235\n2,1957327\n10,0256869\n5,1916277\n1,4539202\n109,5507\n\n\nNA’s\n7,000000\n11,0000000\n19,000\n0,00000\n0,000000\n1,0000000\n1,0000000\n1,0000000\n1,0000000\n0,0000\n\n\n\nNote: aby Djamal Y. TOE\n\n\n  Nous constatons que ceraines variables ont des données manquantes, nous pouvons décider de soit les supprimer, soit les prédire avec des méthodes d’imputation en fonction de leurs importances. Mais pour le moment nous allons juste les supprimer.\n\ndf &lt;- na.omit(df)\nnrow(df)\n\n[1] 162\n\n\nAinsi nous passons de 182 à 162 lignes."
  },
  {
    "objectID": "docs/ANALYSES_FACTORIELLES/TP03.html#contruction-de-lanalyse-en-composante-principale",
    "href": "docs/ANALYSES_FACTORIELLES/TP03.html#contruction-de-lanalyse-en-composante-principale",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Contruction de l’Analyse en composante principale",
    "text": "Contruction de l’Analyse en composante principale\n\nLe poids pour les pays : Les tailles respectives des populations de chaques pays car cela garantit que l’analyse est représentative des différences globales, en tenant compte de l’impact démographique des pays.\nMétrique : Normalisation des données car les variables ne sont pas toutes sur la même échelle. Cela permet d’éviter que les variables avec de grosses valeurs (grandes échelles) dominent l’analyse.\nvariables sup :\n\nQuali sup : region, income_group\nQuanti sup : pop\n\n\n\nRéalisation de l’ACP\n\nVérifions la corrélations entre les variables quantitatives\n\n\nnumeric.vars &lt;- as.data.frame(df[sapply(df, is.numeric)])\nM &lt;- round(cor(numeric.vars),2) #- Calculer la matrice de corrélation\n\n##-- créer un objet qui contient une palette de couleur pour le gradiant dans le plot\ncol &lt;- colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\n##-- dessiner le graphique\ncorrplot(M, method=\"color\", col=col(200),  \n         type=\"upper\", order=\"hclust\", \n         addCoef.col = \"black\", #- ajout des coefficients correlation\n         tl.col=\"black\", tl.srt=45, tl.cex = 1\n         , #- couleur, rotation et police de texte des libellés \n         ##-- ne pas afficher les coefficients de corrélations sur la diagonale (ils valent tous 1)\n         diag=FALSE \n         ) \n\n\n\n\nFigure 1 : Matrice de corrélations\n\n\n\n\n    On voit qu’il y’ a quand même des variables qui sont &lt;&gt; (pour l’affirmer avec plus d’assurance il serait judicieux de faire un test billatéral de corrélation de Pearson avec la commande cor.test(method = “pearson”, alternative = “two.sided”)).\n\nCréation du modèle de l’ACP\n\n\ndata.pca &lt;- df[,-1] #- sélectionner toute les variables sauf la variable pays\nrownames(data.pca) &lt;- df[,1] #- renommer les lignes avec les noms des pays (individus)\npoids &lt;- df$pop\npca.model &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = 6)\n\n##- explor(pca.model) pour une interface interactive\n\n\n\nRecupération des valeurs propres et des variances\n\neigen.values &lt;- pca.model$eig\nknitr::kable(eigen.values[1:3,2:3], caption = capTab(\"Inerties expliquées par les 3 premiers axes\"))\n\n\nTableau 2 : Inerties expliquées par les 3 premiers axes\n\n\n\npercentage of variance\ncumulative percentage of variance\n\n\n\n\ncomp 1\n69,758338\n69,75834\n\n\ncomp 2\n16,485374\n86,24371\n\n\ncomp 3\n4,865912\n91,10962\n\n\n\n\n\nOn remarque que les axes 1,2 et 3 représentent respectivement 69,76, 16,49 et 4,09, donc au total 91,11\nOn pourrait aussi visualiser le graphique des valeurs propres :\n\nplt.eig &lt;- fviz_eig(pca.model, title = \"Valeurs propres avec Singapore\")\n\n\n\nQualité de representation des plans / sur les plans\n\nQualité de representation des plans\n\n  Le premier plan a un taux d’inertie supérieur à 86 %, il capte une grande partie de l’information présente dans les données ce qui signifie qu’il à une bonne qualité de representation alors que le second (1-3) en capte environ 74,63 % donc a une faible qualité de représenatation comparé au premier. En depit de ce fait, les deux plans ont quand même qualité de représentation si mous fions au critère du taux d’inertie.\n\nQualité de representation sur les plans\n\n(1-2)\n\n\nLES VARIABLES\n\ngraph.cos2.var &lt;- fviz_pca_var(pca.model,col.var=\"cos2\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.cos2.var\n\n\n\n\nFigure 3 : Qualités de representation des variables\n\n\n\n\nConcernant les variables, on constate qu’elles toutes sont bien representées avec des cosinus carrés qui ont une valeur minimale environ 0,8 à part les variables biocapacity, life_expectancy, number_of_countries_required qui ont un cosinus carrés qui vaut environ 0,7.\nLES INDIVIDUS\n\nthreshold &lt;- 0.85\ndata.ind.cos2 &lt;- pca.model$ind$cos2\n\ndim1 &lt;- data.ind.cos2[,\"Dim.1\"]\ndim1 &lt;- dim1[dim1 &gt;= threshold]\ncountries.dim1 &lt;- names(dim1)\nnames(dim1) &lt;-  NULL\n\ndim2 &lt;- data.ind.cos2[,\"Dim.2\"]\ndim2 &lt;- dim2[dim2 &gt;= 0.6]\ncountries.dim2 &lt;- names(dim2)\nnames(dim2) &lt;-  NULL\n\n##-- crétion des dataframes \ndim1.df &lt;- data.frame(\n  Country = countries.dim1,\n  `Cos carré` = dim1\n) %&gt;% arrange(desc(dim1))\n\n\ndim2.df &lt;- data.frame(\n  Country = countries.dim2,\n  `Cos carré` = dim2\n) %&gt;% arrange(desc(dim2))\n\n\n##-- création des tableaux kableExtra\ndim1.tbl &lt;- kableExtra::kbl(dim1.df, caption = capTab(\"Individus ayant un cosinus carré supérieur ou égal à 0,85 sur l'axe 1\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\ndim2.tbl &lt;- kableExtra::kbl(dim2.df, caption = capTab(\"Individus ayant un cosinus carré supérieur ou égal à 0,6 sur l'axe 2\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))  %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\n\ndim1.tbl\n\n\n\nTableau 3 : Individus ayant un cosinus carré supérieur ou égal à 0,85 sur l'axe 1\n\n\nCountry\nCos.carré\n\n\n\n\nRwanda\n0,9810454\n\n\nNepal\n0,9772128\n\n\nHaiti\n0,9763067\n\n\nPakistan\n0,9745537\n\n\nSao Tome and Principe\n0,9617076\n\n\nIndia\n0,9558559\n\n\nKenya\n0,9448689\n\n\nTogo\n0,9425662\n\n\nMalawi\n0,9425394\n\n\nTanzania, United Republic of\n0,9419010\n\n\nEthiopia\n0,9390190\n\n\nGambia\n0,9377395\n\n\nPoland\n0,9272053\n\n\nYemen\n0,9228666\n\n\nCzech Republic\n0,9218239\n\n\nAustria\n0,9047663\n\n\nGuatemala\n0,9044971\n\n\nMyanmar\n0,8964483\n\n\nBurundi\n0,8916493\n\n\nCambodia\n0,8911437\n\n\nDenmark\n0,8896874\n\n\nUnited States of America\n0,8875048\n\n\nSlovenia\n0,8840522\n\n\nMalaysia\n0,8840507\n\n\nBenin\n0,8831711\n\n\nSudan\n0,8713134\n\n\nSenegal\n0,8705626\n\n\nTimor-Leste\n0,8640862\n\n\nBelgium\n0,8604596\n\n\nAngola\n0,8591836\n\n\nGhana\n0,8579621\n\n\nSierra Leone\n0,8542504\n\n\nSlovakia\n0,8524619\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\ndim2.tbl \n\n\n\nTableau 4 : Individus ayant un cosinus carré supérieur ou égal à 0,6 sur l'axe 2\n\n\nCountry\nCos.carré\n\n\n\n\nNamibia\n0,7502317\n\n\nParaguay\n0,6807204\n\n\nBrazil\n0,6672407\n\n\nBolivia\n0,6609662\n\n\nBarbados\n0,6458843\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\nAXE 1 : On voit que les pays (individus) comme le Togo, le Yemen, les USA, le Rwanda sont tres bien representés. RMRQ : Il y en a d’autres\nAXE 2 : Il n’y a que 6 pays qui sont bien représentés sur cet axe. Il s’agit de la Namibie, le Paraguay, le Brésil, la Bolivie et Barbados.\n\nREMARQUE :  Pour le plan formé des axes 1 et 3, on peut procéder la même que celle en amont\n\n\nCaractérisation des axes\n\ngraph.contrib.var &lt;- fviz_pca_var(pca.model,col.var=\"contrib\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.contrib.var\n\n\n\n\nFigure 4 : Cercle de corrélation des variables et leur contribution à la formation des axes\n\n\n\n\n\n\nComment l’ACP est-elle modifiée si on retire Singapour de l’analyse ?\n\ndata.pca.sans.singapore &lt;- data.pca %&gt;% filter(rownames(data.pca) != \"Singapore\")\npoids &lt;- df$pop\npca.model.sans.singapore &lt;- PCA(data.pca.sans.singapore, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca.sans.singapore$pop,\n                 quanti.sup = 6)\n\n##-- explor(pca.model)\n\n\nplt.eig.sans.sing &lt;- fviz_eig(pca.model.sans.singapore, title = \"Valeurs propres sans Singapore\") \ncomp.eig &lt;-  cowplot::plot_grid(\n  plt.eig,\n  plt.eig.sans.sing,\n  ncol = 2\n)+ theme_light()\ncomp.eig\n\n\n\n\nFigure 5 : Comparaison des valeurs propres issues de l’ACP aevc et sans Singapore\n\n\n\n\n  On voit que rien ne se passe (pas de changement brusque) au niveau de la qualité des axes. Voyons de plus prêt ce qui se passe :\n\nplot.indiv.avec.sing &lt;- fviz_pca_ind(pca.model) + \n                        theme_light()\nplot.indiv.avec.sing\n\n\n\n\nFigure 6 : Comparaison des valeurs propres issues de l’ACP aevc et sans Singapore\n\n\n\n\n  On voit que Singapore est atypique. Cela pourrait signifier que Singapore participe fortement à la formation de l’axe 2 (point plus proche de l’axe 1).\n\ndata &lt;- as.data.frame(pca.model$ind$contrib)\ndata &lt;-  data %&gt;% arrange(desc(Dim.2)) %&gt;% head(10)\nkableExtra::kbl(data, caption = capTab(\"Contribution des individus à la formation des axes par contribution décroissante suivant l'axe 2\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))  %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 5 : Contribution des individus à la formation des axes par contribution décroissante suivant l'axe 2\n\n\n\nDim.1\nDim.2\nDim.3\nDim.4\nDim.5\n\n\n\n\nSingapore\n0,7259355\n15,139608\n28,5623680\n9,9266768\n5,6933884\n\n\nBrazil\n0,2363938\n11,748028\n0,2780798\n16,7474472\n0,1489935\n\n\nChina\n6,3338962\n10,346574\n0,9583694\n1,3599693\n36,9834265\n\n\nRussian Federation\n3,7284884\n10,223438\n4,1131775\n0,1010599\n3,8319553\n\n\nCanada\n3,7127169\n6,392768\n0,8335954\n3,8719645\n0,0267550\n\n\nJapan\n2,3347045\n4,109062\n0,8491595\n0,6848764\n2,2016647\n\n\nUnited States of America\n21,6581050\n3,434086\n3,0985377\n22,3391460\n5,4054986\n\n\nKorea, Republic of\n1,9711036\n2,758601\n0,8457859\n0,0962515\n0,0745840\n\n\nAustralia\n1,8672806\n2,568678\n0,0085414\n1,3778438\n0,3505079\n\n\nGuyana\n0,0605633\n2,548944\n1,0759061\n8,5175485\n0,9606747\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEt pourtant il contribue fortement à la formation de l’axe 2, il est même celui qui contribue les plus à la formation des axes. Le fait que Singapore contribue le plus à la formation des axes et que rien ne change lorsqu’il est retiré de l’analyse s’explique tout simplement par sa taille de population. En effet la taille de la population a été utilisée comme poids des individus qui sont ici les pays."
  },
  {
    "objectID": "docs/ANALYSES_FACTORIELLES/TP03.html#identifications-des-pays-en-fonction-de-leur-groupe-de-revenu",
    "href": "docs/ANALYSES_FACTORIELLES/TP03.html#identifications-des-pays-en-fonction-de-leur-groupe-de-revenu",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Identifications des pays en fonction de leur groupe de revenu",
    "text": "Identifications des pays en fonction de leur groupe de revenu\n\nIl s’agit juste d’une parenthèse qui n’a rien avoir avec l’objectif de l’étude\n\n\n##-- Définitions des groupes de revenus\nincome_groups_definitions &lt;- c(\n  \"UM\" = \"Upper-Middle\",\n  \"LM\" = \"Lower-Middle\",\n  \"HI\" = \"High Income\",\n  \"LI\" = \"Low Income\"\n)\n\n\n##-- Ajouter une colonne avec les définitions correspondantes\ndata.pca$income_group_def &lt;- as.factor(income_groups_definitions[data.pca$income_group])\n\n\ngraph_indiv &lt;- fviz_pca_ind(\n  pca.model,\n  select.ind = list(\n    contrib = 50\n  ),\n  invisible = c(\"quanti.sup\",\"ind.sup\"),\n  habillage = data.pca$income_group_def,\n  addEllipses = TRUE,\n  repel = TRUE,\n) + theme_light() \n\n\ngraph_indiv\n\n\n\n\nFigure 7 : Affichage des 40 individus qui contribuent le plus à la formation des axes en fonction de leur groupe de revenu\n\n\n\n#hc.pca &lt;- HCPC(pca.model, nb.clust=3)\n\n      On voit que les groupes ne sont pas bien séparés, raison pour laquelle les ellipses ont des partie qui coïncident. Cela pourrait signifier que les les groupes de revenus sont trop similaires pour etre clairement séparés sur les axes sélectionnés (dans le plan des composantes principales). Cela pourrait aussi fait cas d’hétérogénéité, c’est-à-dire que les groupes ne sont pas homogènes (grande variabilité intra-groupe).\n      A bien regarder, nous aurions pu les regrouper en trois groupes de revenu, en combinant les Low income et les Low middle income, les Upper middle income (avec certains pays du High income) et enfin le dernier groupe les high income. Il faut noter que tout ça n’est que purement visuel même si on a quand même une grande partie de l’information contenue dans les données rien qu’avec ces deux plans (plus de 80%).\n\nDeux ACP différentes\n\nPourquoi réaliser deux ACP différentes ?\n\n  Pour simplement calculer la 1-ère valeur propre de chaque groupe de variables (empreinte écologique et de developpement) afin de les utiliser ponderer les variables afin qu’elles contribuent de manière équitable à la formation des axes. Pour plus de détails aller à la sous-section et sur le site de mon professeur de Méthodes d’Analyses Factorielles en cliquanr sur ce lien https://marieetienne.github.io/MAF/01_afm.html#/title-slide.\nOn préfère utiliser la première valeur propre (\\(\\lambda_{k1}\\)) car elle capturerait l’essentiel de l’inertie d’un groupe et permet une pondération cohérente et équilibrée dans l’AFM. La seconde valeur propre reflète des structures secondaires ou résiduelles qui ne sont pas pertinentes pour normaliser les contributions des groupes dans l’analyse globale.\n\nvariables.empreinte &lt;- df[, c(\"total_prod\", \"total_cons\", \"biocapacity\", \"number_of_earths_required\", \"overshoot_day\", \"pop\")]\nrownames(variables.empreinte) &lt;- df$country\nvariables.developpement &lt;- df[, c(\"life_expectancy\", \"hdi\", \"per_capita_gdp\",\"pop\")]\nrownames(variables.developpement) &lt;- df$country\n\n\nACP sur les variables d’empruntes écologiques\n      Il s’agit ici de faire l’ACP que sur les variables d’empruntes écologiques et de mettre les autres variables (de developpement) en quantitatives supplémentaires.\n\ndata.pca &lt;- df[,-1] ## sélectionner toute les variables sauf la variable pays\nrownames(data.pca) &lt;- df[,1] ## renommer les lignes avec les noms des pays (individus)\npoids &lt;- df$pop\nacp_empreinte &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = c(6,1,2,3))\n\n##-- 1ere valeur propre\nacp_empreinte$eig[1,1]\n\n[1] 4,115324\n\n\nLa première valeur propre est : 4,12\n\n\nACP sur les variables d’empruntes écologiques\n\nacp.developpement &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = 6:12)\n\n##-- 1ere valeur propre\nacp.developpement$eig[1,1]\n\n[1] 2,592046\n\n\nLa première valeur propre est : 2,59\n\n\nRéalisons l’AFM manuellement\n\nvariables.empreinte.pond &lt;- variables.empreinte[,-ncol(variables.empreinte)]/sqrt(acp_empreinte$eig[1,1])\n\nvariables.developpement.pond &lt;- variables.developpement[,-ncol(variables.developpement)]/sqrt(\n  acp.developpement$eig[1,1]\n)\n\nvariables.empreinte.pond$group &lt;- \"Empreinte écologique\"\nvariables.developpement.pond$group &lt;- \"developpement\"\n\ndf.afm &lt;- cbind(variables.empreinte.pond, \n                variables.developpement.pond,\n                pop = df$pop,\n                region = df$region,\n                income_group = df$income_group)\n\nacp.afm &lt;- PCA(df.afm, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\", \"group\"),\n                 graph = FALSE,\n                 row.w = df.afm$pop,\n                 quanti.sup = 9)\n\nvariance.cum.val.prop.2acp &lt;- acp.afm$eig[, c(1,3)]\ncolnames(variance.cum.val.prop.2acp) &lt;- c(\"Valeur propres\", \"Pourcentage de variance cumulée\")\n\n\nkableExtra::kbl(variance.cum.val.prop.2acp, caption = capTab(\"Valeurs propres et variances cumulées de chaque axes issues d'une AFM manuelle\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 6 : Valeurs propres et variances cumulées de chaque axes issues d'une AFM manuelle\n\n\n\nValeur propres\nPourcentage de variance cumulée\n\n\n\n\ncomp 1\n5,4257689\n67,82211\n\n\ncomp 2\n1,3223267\n84,35120\n\n\ncomp 3\n0,6522681\n92,50455\n\n\ncomp 4\n0,3973880\n97,47190\n\n\ncomp 5\n0,1005256\n98,72847\n\n\ncomp 6\n0,0689548\n99,59040\n\n\ncomp 7\n0,0327679\n100,00000\n\n\ncomp 8\n0,0000000\n100,00000\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv"
  },
  {
    "objectID": "docs/ANALYSES_FACTORIELLES/TP03.html#afm",
    "href": "docs/ANALYSES_FACTORIELLES/TP03.html#afm",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "REALISATION DE L’AFM",
    "text": "REALISATION DE L’AFM\n\nPourquoi réaliser une AFM au lieu d’une ACP tout court?\n\n      L’Analyse Factorielle Multiple (AFM) permet d’aller au-delà des limites d’une Analyse en Composantes Principales (ACP) classique, particulièrement lorsque les variables d’un jeu de données ne sont pas à la même échelle ou lorsqu’elles sont organisées en groupes. La normalisation dans l’ACP sert à ramener toutes les variables à une même échelle, évitant ainsi que certaines variables dominent artificiellement l’analyse en raison de leur variance plus élevée. Par exemple d’autres ont une contribution élevée que d’autres alors que c’est juste l’unité de mésure qui pèse plus.\n  Cependant, cette normalisation n’est pas suffisante lorsque les variables sont regroupées par thématique ou nature. Par exemple, supposons un jeu de données contenant \\(n\\) variables, parmi lesquelles \\(n - k\\) \\(\\text{avec k telque  } \\forall \\text{ j} \\neq \\text{k, }\\)\n\\(\\text{n - k} &gt; \\text{n - j où n - j est le nombre de variables dans tous les autres groupes ou dans un autre groupe j}\\) appartiennent à un groupe \\(i\\) .Dans ce cas, le groupe \\(i\\) peut influencer de manière disproportionnée les résultats de l’ACP, simplement en raison de la taille du groupe. Cela signifie que, même après normalisation, le poids collectif du groupe \\(i\\) dans la construction des composantes principales pourrait être trop important par rapport aux autres groupes.\n  L’AFM résout ce problème en intégrant un poids équilibré entre les groupes. Elle considère chaque groupe comme une entité, indépendamment du nombre de variables qu’il contient. Cela permet une contribution équitable des groupes aux axes factoriels. Par conséquent, l’AFM est particulièrement adaptée dans des contextes où les variables appartiennent à des thématiques distinctes (par exemple, des groupes liés à des disciplines différentes : santé, économie, environnement).\nIl est crucial de préserver l’équilibre des contributions entre ces thématiques pour éviter les biais d’interprétation. Ainsi, l’AFM fournit une perspective multidimensionnelle plus équilibrée et pertinente pour analyser des jeux de données complexes, tout en respectant la structure inhérente des variables\n\nRéalisons l’AFM à présent\n\n\n#-- création de la table pour l'AFM. Les vriables doivent être rangées \n#-- suivant le groupe (variables du groupe 1 ensuite celles du groupe 2 ...)\ndata.afm &lt;- data.pca %&gt;%\n  select(\n    life_expectancy, hdi, per_capita_gdp,  ##-- Variables de developpement\n    total_prod, total_cons, biocapacity, ##------ Variables\n    number_of_earths_required, overshoot_day ##-- d'empreinte écologique\n)\n\nmodel.afm &lt;- MFA(\n    data.afm, \n    group = c(5, 3), ##-- Spécifie le nombre de variables dans chaque groupe\n    type = rep(\"s\", 2), ##-- Indique que les variables doivent être normalisées pour chaque groupe\n    name.group = c(\"Developpement\", \"Empreinte ecologique\"), ##-- Nommer les groupes\n    graph = F  ##-- Générer un graphique\n)\nvariance.cum.val.prop.afm &lt;- model.afm$eig[, c(1,3)]\ncolnames(variance.cum.val.prop.afm) &lt;- c(\"Valeur propres\", \"Pourcentage de variance cumulée\")\n\n\nkableExtra::kbl(variance.cum.val.prop.afm, caption = capTab(\"Valeurs propres et variances cumulées de chaque axes issues d'une AFM avec R\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 7 : Valeurs propres et variances cumulées de chaque axes issues d'une AFM avec R\n\n\n\nValeur propres\nPourcentage de variance cumulée\n\n\n\n\ncomp 1\n1,9203865\n67,85068\n\n\ncomp 2\n0,5123847\n85,95414\n\n\ncomp 3\n0,2050340\n93,19836\n\n\ncomp 4\n0,0790131\n95,99003\n\n\ncomp 5\n0,0659024\n98,31848\n\n\ncomp 6\n0,0327210\n99,47457\n\n\ncomp 7\n0,0148713\n100,00000\n\n\ncomp 8\n0,0000000\n100,00000\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\nOn voit qu’il n’y a pas très grande différence entre les pourcentage de variances cumulées des deux AFM (manuellement @variance.cum.val.prop.2acp et avec R) parcontre les valeurs propres ne sont pas les mêmes.\n\nOn peut visualiser les variables\n\n\nfviz_mfa_var(model.afm, axes = c(1,2), choice= \"quanti.var\", repel = T) + theme_light()\n\n\n\n\nFigure 8 : Visualisation des variables dans le plan (1,2) avec les résultats de l’AFM\n\n\n\n\n\nOn peut visualiser leur qualité de representation\n\n\ngraph.cos.var.afm &lt;- fviz_mfa_var(model.afm, axes = c(1,2), choice= \"quanti.var\", col.var=\"cos2\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel = T, ggtheme = theme_light())\n\ngraph.cos.var.afm\n\n\n\n\nFigure 9 : Qualité de représentation des variables dans le plan (1,2) avec les résultats de l’AFM\n\n\n\n\n\nLeur contribution à la formation des axes\n\n\ngraph.contrib.var.afm &lt;- fviz_mfa_var(model.afm,col.var=\"contrib\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.contrib.var.afm\n\n\n\n\nFigure 10 : Cercle de corrélation des variables et leur contribution à la formation des axes"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "",
    "text": ". . .\nLe jeu de données mtcars est l’un des ensembles de données les plus connus en statistiques et science des données. Il contient des informations sur les spécifications techniques et les performances de 32 modèles de voitures des années 1970. Ce dataset offre une opportunité unique d’explorer des relations entre des variables mécaniques, comme la consommation en carburant, la puissance ou encore le poids des véhicules.\n\n\n\n\nComment exploiter les relations entre les caractéristiques des voitures pour identifier des groupes ou des tendances qui pourraient aider à la prise de décision dans le secteur automobile ?\n\n\n\n\n\nÉtudier les relations entre les caractéristiques techniques des voitures afin de dégager des tendances et des informations utiles pour la conception ou la sélection des véhicules.\n\n\n\n\n\n\nExplorer les relations entre la consommation en carburant (mpg) et les caractéristiques mécaniques\n\n\n\n\nIdentifier des groupes de voitures ayant des caractéristiques similaires à l’aide d’analyses descriptives et graphiques."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#contexte",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#contexte",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "",
    "text": ". . .\nLe jeu de données mtcars est l’un des ensembles de données les plus connus en statistiques et science des données. Il contient des informations sur les spécifications techniques et les performances de 32 modèles de voitures des années 1970. Ce dataset offre une opportunité unique d’explorer des relations entre des variables mécaniques, comme la consommation en carburant, la puissance ou encore le poids des véhicules."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#problématique",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#problématique",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "",
    "text": "Comment exploiter les relations entre les caractéristiques des voitures pour identifier des groupes ou des tendances qui pourraient aider à la prise de décision dans le secteur automobile ?"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectif-général",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectif-général",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "",
    "text": "Étudier les relations entre les caractéristiques techniques des voitures afin de dégager des tendances et des informations utiles pour la conception ou la sélection des véhicules."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectifs-spécifiques",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#objectifs-spécifiques",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "",
    "text": "Explorer les relations entre la consommation en carburant (mpg) et les caractéristiques mécaniques\n\n\n\n\nIdentifier des groupes de voitures ayant des caractéristiques similaires à l’aide d’analyses descriptives et graphiques."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#matériels",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#matériels",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Matériels",
    "text": "Matériels\n\nLogiciel utilisé : RStudio avec les packages nécessaires (ggplot2, dplyr, cowplot, etc.)\nSource des données : Jeu de données intégré mtcars."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\n\nNettoyage des données : Vérification des valeurs manquantes ou aberrantes.\nAnalyse descriptive : Moyennes, médianes, écart-types pour chaque variable."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-1",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nModélisation multivariée : Variables utilisées\n\nmpg : Consommation de carburant en miles par gallon (variable dépendante).\nwt : Poids du véhicule (en milliers de livres).\ncyl : Nombre de cylindres du moteur.\nam: Type de transmission (0 = automatique, 1 = manuelle).\ncarb : Nombre de carburateurs.\nhp : Puissance brute du moteur (en chevaux-vapeur)."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-2",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nModélisation multivariée :\n\\[\n\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\noù :\n\n\\(Y\\): Vecteur des valeurs observées (dépendantes ici mpg)\n\\(X\\) : Matrice des variables explicatives (indépendantes), incluant une colonne de 1 pour l’intercept.\n\\(\\beta\\) : Vecteur des coefficients estimés du modèle.\n\\(\\epsilon\\) : Vecteur des erreurs résiduelles."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-3",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-3",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nTests de significativité des coefficients\nTest t de Student\n\nHypothèse nulle  \\(H_0\\) : le coefficient est égal à zéro (c’est-à-dire, la variable n’a pas d’effet significatif).\nHypothèse alternative \\(H_a\\) : Le coefficient est différent de zéro.\n\nSi la p-valeur est inférieure à un seuil significatif \\(p &lt; 0.05\\), nous rejetons l’hypothèse nulle et concluons que la variable a un effet significatif sur la variable dépendante."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-4",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-4",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nSignificativité globale du modèle : Test F\n\nHypothèse nulle \\(H_0\\): Tous les coefficients sont égaux à zéro (pas de pouvoir explicatif).\nHypothèse alternative \\(H_a\\) : Au moins un coefficient est différent de zéro (le modèle est significatif).\n\nSi la p-valeur du test \\(F\\) est inférieure à \\(0.05\\), nous rejetons l’hypothèse nulle et concluons que le modèle est significatif."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-5",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-5",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\nR-carré : qualité d’ajustement\n\n\\(R^2\\) varie entre 0 et 1 :\n\nUn \\(R^2\\) proche de 1 signifie que le modèle explique bien les variations de la variable dépendante.\nUn \\(R^2\\) proche de 0 indique que le modèle n’explique que peu ou pas les variations de la variable dépendante."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-6",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#méthode-6",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Méthode",
    "text": "Méthode\n\nVisualisations :\n\nGraphiques de dispersion (scatterplots) pour étudier les corrélations\nHistogrammes pour analyser la distribution des variables"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#présentation-de-léchantillon",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#présentation-de-léchantillon",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Présentation de l’échantillon",
    "text": "Présentation de l’échantillon\n\n\n\n\n\nTable 1 : Description des variables du jeu de données\n\n\nColonne\nNom\nDescription\n\n\n\n\n[,1]\nmpg\nMiles par gallon (US)\n\n\n[,2]\ncyl\nNombre de cylindres\n\n\n[,3]\ndisp\nCylindrée (en pouces cubes)\n\n\n[,4]\nhp\nPuissance brute (chevaux)\n\n\n[,5]\ndrat\nRapport du pont arrière\n\n\n[,6]\nwt\nPoids (en milliers de livres)\n\n\n[,7]\nqsec\nTemps pour parcourir 1/4 de mile\n\n\n[,8]\nvs\nType de moteur (0 = V, 1 = ligne droite)\n\n\n[,9]\nam\nType de transmission (0 = automatique, 1 = manuelle)\n\n\n[,10]\ngear\nNombre de vitesses avant\n\n\n[,11]\ncarb\nNombre de carburateurs\n\n\n\na R : mtcars"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#présentation-de-léchantillon-1",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#présentation-de-léchantillon-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Présentation de l’échantillon",
    "text": "Présentation de l’échantillon\nRésumé statistiques\n\n\n\n\nTable 2 : Résumé statistique des variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nmin\n10.400000\n4.000000\n71.1000\n52.00000\n2.7600000\n1.5130000\n14.500000\n0.0000000\n0.0000000\n3.0000000\n1.0000\n\n\nQ1.25%\n15.425000\n4.000000\n120.8250\n96.50000\n3.0800000\n2.5812500\n16.892500\n0.0000000\n0.0000000\n3.0000000\n2.0000\n\n\nQ3.75%\n22.800000\n8.000000\n326.0000\n180.00000\n3.9200000\n3.6100000\n18.900000\n1.0000000\n1.0000000\n4.0000000\n4.0000\n\n\nmed.50%\n19.200000\n6.000000\n196.3000\n123.00000\n3.6950000\n3.3250000\n17.710000\n0.0000000\n0.0000000\n4.0000000\n2.0000\n\n\nmean\n20.090625\n6.187500\n230.7219\n146.68750\n3.5965625\n3.2172500\n17.848750\n0.4375000\n0.4062500\n3.6875000\n2.8125\n\n\nmax\n33.900000\n8.000000\n472.0000\n335.00000\n4.9300000\n5.4240000\n22.900000\n1.0000000\n1.0000000\n5.0000000\n8.0000\n\n\ncount\n32.000000\n32.000000\n32.0000\n32.00000\n32.0000000\n32.0000000\n32.000000\n32.0000000\n32.0000000\n32.0000000\n32.0000\n\n\nsd\n6.026948\n1.785922\n123.9387\n68.56287\n0.5346787\n0.9784574\n1.786943\n0.5040161\n0.4989909\n0.7378041\n1.6152\n\n\nNA’s\n0.000000\n0.000000\n0.0000\n0.00000\n0.0000000\n0.0000000\n0.000000\n0.0000000\n0.0000000\n0.0000000\n0.0000\n\n\n\nNote: aR : mtcars"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats principaux : Modélisation",
    "text": "Résultats principaux : Modélisation\nSélection de modèle en ajoutant ou en supprimant des variables pour minimiser l’AIC\n\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    wt\n-3.9\n-5.4, -2.5\n&lt;0.001\n    am\n2.9\n0.05, 5.8\n0.047\n    qsec\n1.2\n0.63, 1.8\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation-1",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats principaux : Modélisation",
    "text": "Résultats principaux : Modélisation\n\nPoids (wt) : L’augmentation du poids réduit la consommation de carburant, avec un coefficient négatif significatif (p-value = 0.000199)\nNombre de cylindres (cyl) : L’effet des cylindres est légèrement négatif, mais le lien reste faible. p-value = 0.098480 (juste au seuil de signification à 0.1)."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation-2",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-principaux-modélisation-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats principaux : Modélisation",
    "text": "Résultats principaux : Modélisation\n\nPuissance (hp) : Pas de relation directe significative entre la puissance et la consommation. p-value = 0.140015.\nOptimisation : Le modèle suggère que la réduction du poids des voitures pourrait améliorer leur efficacité énergétique."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats sécondaires",
    "text": "Résultats sécondaires\nRépartition des voitures par cylindres\n\n\n\n\n\nLa majorité des voitures ont 4 ou 8 cylindres."
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires-1",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats sécondaires",
    "text": "Résultats sécondaires\nRépartition des voitures par transmission"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires-2",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#résultats-sécondaires-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Résultats sécondaires",
    "text": "Résultats sécondaires"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-1",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-1",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Discussions",
    "text": "Discussions\n\nPoids (wt) : Impact significatif sur la consommation en carburant (mpg) avec une p-valeur très faible\nNombre de cylindres (cyl) : Effet marginalement significatif (p = 0,098)\nPuissance (hp) : Pas d’impact significatif sur la consommation (p = 0,14)"
  },
  {
    "objectID": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-2",
    "href": "docs/FORMATIONS/DATA_PRESENTATIONS/presentation_mtcars.html#discussions-2",
    "title": "ANALYSE EXPLORATOIRE DES DONNEES MTCARS",
    "section": "Discussions",
    "text": "Discussions\n\nR² ajusté : 82,6 %, ce qui indique un bon ajustement du modèle\nTest F : Le modèle est globalement significatif (p &lt; 0,05).\nPuissance (hp) : Pas de relation directe significative entre la puissance et la consommation. p-value = 0.140015."
  },
  {
    "objectID": "docs/FORMATIONS/presentations.html",
    "href": "docs/FORMATIONS/presentations.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "packages &lt;- c(\"ggplot2\",\"haven\", \"gtsummary\", \"corrr\", \"MASS\",\n              \"dplyr\",\"haven\", \"rstatix\", \"tidyverse\", \"ggpubr\",\n              \"glue\", \"dplyr\",\"ggspatial\", \"ggrepel\",\n              \"readxl\", \"stringr\", \"colorspace\") \n            \nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "docs/FORMATIONS/presentations.html#faire-ses-présentations-directement-avec-r-et-rstudio",
    "href": "docs/FORMATIONS/presentations.html#faire-ses-présentations-directement-avec-r-et-rstudio",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Faire ses présentations directement avec R et Rstudio",
    "text": "Faire ses présentations directement avec R et Rstudio\n\nPourquoi utiliser R et Rstudio pour ses présentations ?\n\n      R et RStudio offrent des outils puissants pour créer des présentations dynamiques, reproductibles et intégrées à vos analyses de données. Voici quelques raisons :\n\nIntégration parfaite des analyses et des présentations :\n\nNous pouvons combiner code, graphiques, tableaux et explications textuelles dans un seul document. Cela garantit une reproductibilité totale : les résultats sont automatiquement mis à jour si vos données changent.\n\nFlexibilité avec RMarkdown :\n\nCréez des présentations dans divers formats : HTML (slidy, reveal.js), PDF (Beamer), ou powerpoint ppt. Les formats sont hautement personnalisables pour répondre à vos besoins esthétiques et fonctionnels.\n\nSimplification du travail collaboratif :\n\nIl y’a une possibilité de garder un fichier .tex pour ceux qui sont à l’aise avec latex.\n\n\nMaintenant allons-y !!!\n\n\n\n\n\nCommençons par une présentation revaljs\n\n\n\n\nInstaller les packages nécessaires\n\nAssurez-vous d’avoir le package revealjs installé. Si ce n’est pas le cas, installez-le avec :\ninstall.packages(\"revealjs\")\n\nCréer un fichier RMarkdown pour une présentation\n\nCréer un nouveau fichier RMarkdown :\n\nAllez dans : File &gt; New File &gt; Quarto presentation\nDans la fenêtre qui s’ouvre : Entrez un titre et un auteur. Dans l’option Default Output Format, choisissez From Template &gt; Revealjs Presentation.\n\n\nChanger l’en-tête YAML\n\nEn image voici, un descriptif visuel des 04 petites étapes pour la création du fichier avec des images :\n\n\n\n\n\n\nEtape 1\n\n\n\n\n\n\n\nEtape 2\n\n\n\n\n\n\n\n\n\nEtape 3\n\n\n\n\n\n\n\nEtape 4\n\n\n\n\n\n\n\n\n\nExplication de l’en-tête YAML"
  },
  {
    "objectID": "docs/FORMATIONS/presentations.html#informations-générales",
    "href": "docs/FORMATIONS/presentations.html#informations-générales",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Informations générales",
    "text": "Informations générales\n\ntitle : Titre principal de la présentation\n\nIci : “ANALYSE EXPLORATOIRE DES DONNEES MTCARS”. C’est ce qui s’affiche en haut de la première diapositive.\n\nauthor : Nom(s) des présentateur(s)\n\nIci : “Presented by Djamal Toe”.\n\ninstitute : Institution ou organisation associée\n\nIci : “National School for Statistic and Data Analysis”.\n-date : Date de la présentation\nIci, elle est générée dynamiquement avec : 2025-01-17. Cela affichera automatiquement la date du jour où le fichier est tricoté."
  },
  {
    "objectID": "docs/FORMATIONS/presentations.html#format-et-personnalisation-reveal.js",
    "href": "docs/FORMATIONS/presentations.html#format-et-personnalisation-reveal.js",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Format et personnalisation (reveal.js)",
    "text": "Format et personnalisation (reveal.js)\nLa section format: revealjs: contient des options spécifiques à la bibliothèque reveal.js, permettant de personnaliser la présentation.\n\nVitesse de transition:  transition-speed: fast définit la vitesse des transitions entre les diapositives. Options possibles : slow, normal, fast.\nAspect ratio :  aspect_ratio: \"16:9\" spécifie le ratio largeur/hauteur des diapositives. Le ratio “16:9” est idéal pour les écrans modernes (écran large). Autres options possibles : “4:3”, “3:2”, etc.\nMarges : margin: 0.02 définit l’espace vide autour du contenu de chaque diapositive. Une valeur faible (comme 0.02) maximise l’espace utilisé sur chaque diapositive.\nCentrage : center: true permet de Centrer le contenu verticalement et horizontalement sur chaque diapositive.\nPied de page : footer: “English classes with Milonnet” : Ajoute un texte en bas de chaque diapositive, comme une signature ou une note de contexte.\nLogo : logo: \"logo_ensai.png\" affiche un logo en haut à droite de chaque diapositive. L’image doit être placée dans le répertoire spécifié ou un chemin relatif correct doit être utilisé.\nCSS personnalisé : css: style.css permet d’utiliser un fichier CSS externe pour personnaliser les styles. Exemple : changer les polices, couleurs, tailles, etc. Le fichier style.css doit être dans le même répertoire ou le chemin approprié doit être indiqué.\nGestion des figure : fig_caption: yes active l’affichage des légendes sous les graphiques insérés.\nTable des matières (ToC) : toc: true active l’affichage d’une table des matières, toc-expand: false exige que les sections de la table des matières ne soient pas développées par défaut, toc-depth: 1 définit la profondeur de la hiérarchie affichée dans la table des matières (seulement les titres principaux #)."
  },
  {
    "objectID": "docs/FORMATIONS/presentations.html#prévisualition",
    "href": "docs/FORMATIONS/presentations.html#prévisualition",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Prévisualition",
    "text": "Prévisualition\n      Pendant que vous faites la présentations sur Rstudio, vous pouvez la présualiser. Regardez les images ci-après :\n\n\n\n\n\n\nPrevisualisation : etape 1\n\n\n\n\n\n\n\nPrevisualisation : etape 2\n\n\n\n\n\n\n\n\n\nCompilation et Previsualisation : etape 3\n\n\n\n\n\n\n\n\n\n\n\nViewer ou Presenation ?\n\n\n\nA l’étape 2 de la prévisualisation, il se peut que la prévisualisation apparaisse dans la partie Presentation juste à droite de l’onglet Viewer encerclé en rouge sur l’image."
  },
  {
    "objectID": "docs/FORMATIONS/presentations.html#mise-en-forme-avec-le-fichier-css",
    "href": "docs/FORMATIONS/presentations.html#mise-en-forme-avec-le-fichier-css",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Mise en forme avec le fichier CSS",
    "text": "Mise en forme avec le fichier CSS\n      Pour cette section ne vous inquietez pas si vous n’avez pas de connaissance en html ou en css, nous utiliserons juste un code css pour la mise en forme du titre."
  },
  {
    "objectID": "docs/FORMATIONS/presentations.html#télécharger-le-fichier-de-la-présentation",
    "href": "docs/FORMATIONS/presentations.html#télécharger-le-fichier-de-la-présentation",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Télécharger le fichier de la présentation",
    "text": "Télécharger le fichier de la présentation\nAvant de télécharger le fichier, vous pouvez voir ce qu’il donne en cliquant sur ce lien\nVous pouvez télécharger le fichier d’analyse exploratoire des données mtcars au format .qmd ci-dessous.\nTélécharger le fichier .qmd\nSi vous avez des questions, vous pouvez me contacter !!!\nRetour à la page d’accueuil"
  },
  {
    "objectID": "docs/FORMATIONS/SIG.html",
    "href": "docs/FORMATIONS/SIG.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "packages &lt;- c(\"ggplot2\",\"haven\", \"gtsummary\", \"corrr\", \"MASS\",\n              \"dplyr\",\"haven\", \"rstatix\", \"tidyverse\", \"ggpubr\",\n              \"glue\", \"dplyr\",\"ggspatial\", \"ggrepel\",\"marmap\", \n              \"readxl\", \"stringr\", \"colorspace\", \"sf\", \"viridis\",\n              \"tools\",\"ggspatial\",\"readxl\",\"openxlsx\",\"grid\",\n              \"outliers\",\"car\",\"ftExtra\",\"tibble\",\n              \"gtsummary\", \"wesanderson\", \"viridis\",\n              \"RColorBrewer\", \"knitr\", \"kableExtra\") \n            \nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "docs/FORMATIONS/SIG.html#comment-faire-des-cartes-choroplèthes-et-des-cartes-de-proportions-avec-r",
    "href": "docs/FORMATIONS/SIG.html#comment-faire-des-cartes-choroplèthes-et-des-cartes-de-proportions-avec-r",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Comment faire des cartes Choroplèthes et des cartes de proportions avec R ?",
    "text": "Comment faire des cartes Choroplèthes et des cartes de proportions avec R ?\n      Les cartes choroplèthes et les cartes de proportions sont des outils puissants pour visualiser des données géospatiales dans R. Ces cartes permettent de représenter des valeurs quantitatives (par exemple, des taux de population, des moyennes) sur des zones géographiques, souvent des régions administratives comme des départements, des communes, ou des zones géographiques personnalisées.\n\nIntroduction aux Cartes Choroplèthes et Cartes de Proportions\n\nLes cartes choroplèthes colorient les régions géographiques en fonction de valeurs numériques ou de proportions, facilitant l’analyse spatiale et la compréhension des variations géographiques. Elles sont couramment utilisées pour des données socio-économiques, de santé publique, ou des analyses environnementales.\nLes cartes de proportions sont similaires mais mettent davantage l’accent sur les ratios ou proportions par rapport à une valeur totale, comme des pourcentages ou des fractions de populations.\n\nNotions de Base : Polygones, Shapefiles et Coordonnées Avant de créer ces cartes, il est important de comprendre quelques notions de base, comme les polygones et les shapefiles :\n\n\n\n\n\n\n\nPolygones\n\n\n\nUne zone géographique est souvent représentée par un polygone, une forme géométrique fermée qui peut avoir plusieurs côtés. Par exemple, une commune ou un département sur une carte peut être représentée comme un polygone.\n\n\n\n\n\n\n\n\nShapefiles\n\n\n\nCe sont un format de fichier standard pour stocker des informations géospatiales, y compris les coordonnées de points, de lignes et de polygones. Ils peuvent contenir les géométries des entités géographiques ainsi que leurs attributs (valeurs associées à chaque région, comme le revenu moyen ou le taux de chômage).\n\n\n\n\n\n\n\n\nCoordonnées géographiques\n\n\n\nLes coordonnées (latitude et longitude) permettent de positionner ces polygones sur une carte. En R, on utilise des systèmes de coordonnées géographiques et projetées pour gérer et visualiser ces données.\n\n\nPlusieurs pakages permettent de visualiser les données avec les cartes, ici nous interessons aux packages glue et sf.\n\nZone d’étude\n\nSupposons que nous menions une étude au Burkina-Faso. Par exemple, nous mésurer des indicateurs tels que le taux de mortalité, la couverture sanitaire etc … Le Burkina Faso est un pays qui compte 13 regions, mais notre etude s’étend seulement sur 8 regions. Il convient de montrer toutes les regions, puis de mettre en exègue celles qui nous concernent.\n\nPlace au code\n\n\n\nvoir/cacher le code\n\n\n###---- Chargement des shapefiles src = GADM\nroot &lt;- getwd() ##-- la racine du repertoire\n\n##- La carte du pays sans les polygones des regions, communes et/ou departements\npath0 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_0.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath1 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_1.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath2 &lt;- paste0(\"/DATA_SIG/BFA2/gadm41_BFA_2.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath3 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_3.shp\")\n\n\n##-- selection des regions concernées\n\nstudy.area &lt;-  c(\"Boucle du Mouhoun\", \"Centre-Est\", \"Centre-Nord\",\n             \"Centre-Ouest\", \"Nord\", \"Sud-Ouest\",\n             \"Haut-Bassins\", \"Cascades\")\n\n##-- lecture des shapefiles\npays_shp &lt;- read_sf(glue(path0), quiet = T)\nregion_shp &lt;- read_sf(glue(path1), quiet = T)\n#commune_shp &lt;- read_sf(glue(path2), quiet = T)\n#province_shp &lt;- read_sf(glue(path3), quiet = T)\n\n##-- création d'une sous base avec les polygones des regions sélectionnés\n\ndata_region &lt;- region_shp %&gt;% filter(NAME_1 %in% study.area)\n\n\n##-- Study area colors\nstudy_zone_colors &lt;- c(\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\",\n                       \"#3FE1B8\", \"#9467bd\", \"#8c564b\",\n                       \"#00008B\", \"#4B0082\")\n\nstudy_zone_map &lt;- ggplot() +\n  geom_sf(data = pays_shp, aes(linewidth = \"Burkina Faso\"),fill = \"white\", color = \"black\") +\n  geom_sf(data = region_shp, aes(fill = ifelse(\n    NAME_1 %in% study.area,\n    \"Regions d'études\",\n    \"Autres regions\"\n  ) )) +\n  geom_sf_text(data = region_shp, aes(label = ifelse(\n    NAME_1 %in% study.area,\n    study.area,\n    \"\"\n  )), size = 4)+\n  ggspatial::annotation_scale(\n    location = \"br\",\n    bar_cols = c(\"black\", \"white\")\n  )  +\n  theme_light()+\n  ggspatial::annotation_north_arrow(\n    location = \"tr\", which_north = \"true\",\n    pad_x = unit(0.05, \"in\"), pad_y = unit(0.05, \"in\"),\n    style = ggspatial::north_arrow_nautical(\n      fill = c(\"black\", \"white\"),\n      line_col = \"black\"\n    )\n  )+\n  xlab(\"\")+\n  ylab(\"\")+\n  scale_linewidth_manual(values = c(1.2), name = \"\")+\n  scale_fill_manual(values = c(\"white\",\"#1f77b4\"), name=\"Zone d'étude\")+\n  theme_light() + \n  guides(\n    linewidth = guide_legend(order = 1),\n    fill = guide_legend(order = 2),\n    color = guide_legend(order = 3)\n  )\n\n\n\nstudy_zone_map\n\n\n\n\nCartographie de la zone d’étude\n\n\n\n\n\nExpliquons le code à présent\n\n\nCharger les fichier shapefiles :\n\nglue : pour preparer la structure du format (optionnel)\nreadsf : pour lire les fichiers shapefiles\n\nDefinir la zone d’étude : les fichier shapefile devient comme un dataframe, donc est manipulable au même titre que les fichiers excel, csv etc …\nOn trace d’abord la carte du pays, ensuite on ajoute la couche des regions (c’est-à-dire le shapefile des regions). On pourrait le faire simplement avec le shapefile des regions sans celui du pays.\nEnsuite on ajoute la couleur pour la zone concernée et les noms des regions sélectionnées avec geom_sf_text\nannotation_scale permet d’ajouter une barre d’échelle (scale bar) à une carte avec la position br pour dire bottom rigth (en bas à droite)\nannotation_north_arrow est utilisée pour ajouter une flèche du nord sur une carte créée avec ggplot2\nPour le reste il s’agit des fonctions qu’on utilise couramment avec ggplot2\n\n\n\nAfficher/Masquer le tableau\n\n\n\n\n\nTableau 1 : Les 10 premières lignes du shapefile\n\n\nGID_1\nGID_0\nCOUNTRY\nNAME_1\nVARNAME_1\nNL_NAME_1\nTYPE_1\nENGTYPE_1\nCC_1\nHASC_1\nISO_1\ngeometry\n\n\n\n\nBFA.1_1\nBFA\nBurkina Faso\nBoucle du Mouhoun\nNA\nNA\nRégion\nRegion\nNA\nBF.BO\nNA\nPOLYGON ((-2,73901 11,71249...\n\n\nBFA.2_1\nBFA\nBurkina Faso\nCascades\nNA\nNA\nRégion\nRegion\nNA\nBF.CD\nNA\nPOLYGON ((-4,591742 9,70225...\n\n\nBFA.7_1\nBFA\nBurkina Faso\nCentre\nNA\nNA\nRégion\nRegion\nNA\nBF.CT\nNA\nPOLYGON ((-1,2786 12,13921,...\n\n\nBFA.3_1\nBFA\nBurkina Faso\nCentre-Est\nNA\nNA\nRégion\nRegion\nNA\nBF.CE\nNA\nPOLYGON ((0,4371 11,67655, ...\n\n\nBFA.4_1\nBFA\nBurkina Faso\nCentre-Nord\nNA\nNA\nRégion\nRegion\nNA\nBF.CN\nNA\nPOLYGON ((-0,7773 12,66989,...\n\n\nBFA.5_1\nBFA\nBurkina Faso\nCentre-Ouest\nNA\nNA\nRégion\nRegion\nNA\nBF.CO\nNA\nPOLYGON ((-2,360162 11,0081...\n\n\nBFA.6_1\nBFA\nBurkina Faso\nCentre-Sud\nNA\nNA\nRégion\nRegion\nNA\nBF.CS\nNA\nPOLYGON ((-0,8624911 10,985...\n\n\nBFA.8_1\nBFA\nBurkina Faso\nEst\nNA\nNA\nRégion\nRegion\nNA\nBF.ES\nNA\nPOLYGON ((1,384436 11,44223...\n\n\nBFA.9_1\nBFA\nBurkina Faso\nHaut-Bassins\nNA\nNA\nRégion\nRegion\nNA\nBF.HB\nNA\nPOLYGON ((-4,08994 10,79044...\n\n\nBFA.10_1\nBFA\nBurkina Faso\nNord\nNA\nNA\nRégion\nRegion\nNA\nBF.NO\nNA\nPOLYGON ((-1,96586 12,67774...\n\n\n\na Source des données : GADM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCartes choroplèthes\n\n      Les cartes choroplèthes sont des représentations graphiques qui utilisent des nuances de couleurs pour illustrer des données quantitatives ou qualitatives sur des zones géographiques. Chaque zone est remplie d’une couleur qui correspond à une valeur spécifique ou à une plage de valeurs, facilitant ainsi l’analyse des variations spatiales des données.\nLes cartes choroplèthes sont idéales pour représenter des indicateurs comme le taux de mortalité, le revenu moyen, l’accès à l’eau potable, ou encore la couverture sanitaire par région.\n\nExemple de carte choroplèthe\nDans cet exemple, nous allons créer une carte choroplèthe montrant la couverture sanitaire par région au Burkina Faso, en utilisant les données fictives créées plus haut. pour les données, vous pouvez me contacter par email.\n\nEtape 1 : Charger les shapefiles et les données\n\nIci nous nous assurons que les shapefiles des régions et les données sont correctement chargés et liés entre eux. Pour cela on fait une jointure externe.\n\n##-- Joindre les données au shapefile\nregion_data &lt;- region_shp %&gt;% \n  left_join(data, by = c(\"NAME_1\" = \"Region\"))\n\nAvant de passer à l’étape 2, affichons les données générées avant jointure et ceux aprés jointures.\n\n\nAfficher/cacher le code\n\n\ntbl.avant.jointure &lt;- kbl(head(data,10)) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\ntbl.apres.jointure &lt;- kbl(head(data,10)) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  GADM\")\n\n\n\n\nAfficher/Masquer le tableau\n\n\ntbl.avant.jointure\ntbl.apres.jointure\n\n\nLes 10 premières lignes des tables\n\n\n\n\n\nAvant jointure\n\n\nRegion\nPopulation\nTaux_Mortalite\nCouverture_Sanitaire\nAcces_Eau_Potable\n\n\n\n\nBoucle du Mouhoun\n2046446\n5,03\n79,31\n57,79\n\n\nCascades\n853269\n8,05\n72,22\n83,55\n\n\nCentre\n356206\n5,05\n94,96\n61,79\n\n\nCentre-Est\n2279767\n13,41\n60,49\n58,83\n\n\nCentre-Nord\n2119333\n9,53\n69,89\n79,70\n\n\nCentre-Ouest\n1148591\n8,46\n87,32\n84,49\n\n\nCentre-Sud\n430694\n9,88\n65,74\n87,38\n\n\nEst\n1984393\n8,62\n83,19\n62,86\n\n\nHauts-Bassins\n1956576\n5,31\n84,44\n82,11\n\n\nNord\n970511\n9,45\n83,94\n84,14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAprès jointure\n\n\nRegion\nPopulation\nTaux_Mortalite\nCouverture_Sanitaire\nAcces_Eau_Potable\n\n\n\n\nBoucle du Mouhoun\n2046446\n5,03\n79,31\n57,79\n\n\nCascades\n853269\n8,05\n72,22\n83,55\n\n\nCentre\n356206\n5,05\n94,96\n61,79\n\n\nCentre-Est\n2279767\n13,41\n60,49\n58,83\n\n\nCentre-Nord\n2119333\n9,53\n69,89\n79,70\n\n\nCentre-Ouest\n1148591\n8,46\n87,32\n84,49\n\n\nCentre-Sud\n430694\n9,88\n65,74\n87,38\n\n\nEst\n1984393\n8,62\n83,19\n62,86\n\n\nHauts-Bassins\n1956576\n5,31\n84,44\n82,11\n\n\nNord\n970511\n9,45\n83,94\n84,14\n\n\n\na Source des données : GADM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEtape 2 : Créer la carte choroplèthe\n\nUtilisez ggplot2 et geom_sf() pour afficher les régions et les colorer en fonction de la couverture sanitaire.\n\n##-  Carte choroplèthe\nchoropleth_map &lt;- ggplot(region_data) +\n  geom_sf(aes(fill = Couverture_Sanitaire), color = \"black\") +\n  scale_fill_viridis_c(\n    option = \"C\",\n    name = \"Couverture Sanitaire (%)\"\n  ) +\n  ggtitle(\"Carte choroplèthe : Couverture sanitaire par région\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    plot.title = element_text(hjust = 0.5, face = \"bold\")\n  )\n\nchoropleth_map\n\n\n\n\nCouverture sanitaire par région\n\n\n\n\n\nEtape 3 :  Ajouter des éléments décoratifs\n\nAjoutons une barre d’échelle et une flèche du nord pour rendre la carte plus informative.\n\n##- Ajout des éléments décoratifs\nchoropleth_map &lt;- choropleth_map +\n  ggspatial::annotation_scale(location = \"br\") +\n  ggspatial::annotation_north_arrow(\n    location = \"tl\", style = north_arrow_nautical()\n  ) ###-- tl pour top-left (en haut à gauche)\n\nchoropleth_map\n\n\n\n\n\nInterpréter les résultats\n\nExaminez la carte générée et répondez aux questions suivantes : - Quelles régions ont la meilleure couverture sanitaire ? - Quelles régions doivent faire l’objet d’une attention particulière pour améliorer les conditions de vie ?\n\nExtensions possibles\n\nRéalisez une carte choroplèthe pour le taux de mortalité.\nAjoutez des annotations pour les régions ayant les valeurs extrêmes.\nExpérimentez avec d’autres palettes de couleurs en utilisant scale_fill_brewer() ou scale_fill_manual() etc ….\n\n\n\n\n\n\n\nDonnées discrètes ?\n\n\n\nIl se peut qu’il n’y ait pas une variabilité importante dans les données dans ce cas, au lieu d’avoir une palette, nous aurons juste des cases de couleurs comme s’agissait d’un indicateur discrèt. Dans ce cas, recoder juste cet indicateur en un indicateur qualitatif (regrouper par classe) et ensuite utiliser scale_fill_manual() pour definir vos couleurs manuellement ou laisser R le faire tout seul. Le graphique ci-dessous en est un exemple.\n\n\n\n\n\nExemple de carte avec un indicateur recodé\n\n\n\nCartes de proportions\n\n\n\n\nA suivre\n\n\n\n\nCartes de proportions avancées\n\n\n\n\n\n\nRetour à la page d’accueuil"
  }
]