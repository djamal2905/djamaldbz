[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "Bienvenue sur mon site personnel.\nJe suis Djamal Y. TOE, statisticien passionné par les analyses avancées, la visualisation de données, et la résolution de problèmes complexes à travers des approches quantitatives. Ce site présente mes projets, mes recherches, et mes contributions dans le domaine des statistiques et de la science des données. Je suis titulaire d’une licence en statistique-informatique et actuellement élève ingénieur en Data Science à l’Ecole Nationale de la statistique et de l’Analyse de l’Information à Bruz Rennes, France."
  },
  {
    "objectID": "about.html#à-propos-de-moi",
    "href": "about.html#à-propos-de-moi",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "À propos de moi",
    "text": "À propos de moi\nJe combine mes compétences en statistiques, programmation et analyse de données pour transformer des ensembles de données en informations exploitables. Mon objectif est d’améliorer la prise de décision grâce à des modèles et des méthodes robustes. Ayant effectuer des stages en entreprises, j’ai appris beaucoup de choses notamment en bio-statistiques et sur les modélisations qui y sont utilisées. J’ai également des connaissance en cartographie (avec R)."
  },
  {
    "objectID": "about.html#expérience",
    "href": "about.html#expérience",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Expérience",
    "text": "Expérience\n\nStagiaire au Centre de Méthodologie et de Gestion de données au Centre MURAZ sis Bobo-Dioulasso, Burkina Faso\n\ndurée : 6 mois Août 2023 - Janvier 2024\nTravail effectué :\n\nAnalyse exploratoire de données\nTests statistiques et Modélisations\nSystème d’information géographique\nRedaction automatique de rapports\n\n\nStagiaire au Centre de Méthodologie et de Gestion de données au Centre MURAZ & l’Institut National de recherche en Science de la Santé sis Bobo-Dioulasso, Burkina Faso\n\ndurée : 5 mois Janvier 2024 - Mai 2024"
  },
  {
    "objectID": "about.html#projets-et-contributions",
    "href": "about.html#projets-et-contributions",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Projets et Contributions",
    "text": "Projets et Contributions\n\n1. Analyses Factorielles et Visualisations Avancées\n\nDéveloppement d’analyses factorielles (ACP, AFC, ACM, AFM, AFD) pour comprendre les structures complexes des données.\nVisualisation interactive des résultats pour une meilleure interprétation (Rshiny, Python Jupyter Dash).\n\n\n\n2. Modèles de Régression et Prévision\n\nRégression linéaire, logistique, et mixte\nPrévisions à l’aide de modèles de séries temporelles\n\n\n\n3. Applications Statistiques\n\nDéveloppement d’outils interactifs pour l’analyse de données (Shiny, Quarto)\nRapports automatisés (Rmarkdown, Bookdown)\n\n\n\n4. Applications Bureau et Web\n\nDévéloppement de logiciel bureau pour la gestion des caisses\nDévéloppement de sites web avec python&Django (pas trop avancé)\n\n\n\n5. Computer vision\nDébute dans la vision par ordinateur avec :\n\nLa SVM (Support Vector Machine)\nLe KNN (K- Nearest Neighbour)\nL’ACP (L’Analyse en Composante Principale)\nLes reseaux de neurones convolutionnels (à venir)\n\n\n\n6. Langages de programmtion et outils statistiques\n\nPython, Java, C++ & C\nR, Stata, SPSS\nHtml, Css\nOffice et Suites\nSystème de Gestion de données :\n\nMySql\nOracle SQL"
  },
  {
    "objectID": "about.html#dernières-publications",
    "href": "about.html#dernières-publications",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Dernières Publications",
    "text": "Dernières Publications\n\nExploration des Techniques d’Analyse Factorielle\nGuide Pratique pour les Modèles Mixtes\nVisualisation Dynamique avec R et Quarto\nFormation en python"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html",
    "href": "ANALYSES_FACTORIELLES/TP03.html",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "",
    "text": "packages_ &lt;- c(\"ggplot2\", \"dplyr\",\"readxl\",\"cowplot\")\n\nfor (pkg in packages_) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#quelques-définitions",
    "href": "ANALYSES_FACTORIELLES/TP03.html#quelques-définitions",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Quelques définitions",
    "text": "Quelques définitions\n      Le calcul de l’empreinte écologique et de la biocapacité nous aide à répondre à la question de recherche fondamentale : Quelle est la demande des êtres humains envers les surfaces biologiquement productives (empreinte écologique) par rapport à la quantité que la planète (ou la surface productive d’une région) peut régénérer sur ces surfaces (biocapacité) ?\n\nHectare global (gha) : C’est l’unité choisie pour exprimer toutes les quantités d’intérêt concernant la consommation/émission de carbone. Une unité de surface correspondant à la productivité moyenne d’un hectare de terres mondiales. Un hectare de terres agricoles vaudra plus d’hectares globaux qu’un hectare de désert.\nEmpreinte écologique (en gha par personne) : Le nombre de gha requis pour produire les besoins et absorber les déchets d’un pays.\nBiocapacité (en gha) : La capacité d’un pays à produire ce dont il a besoin et à absorber ses déchets (réserve écologique).\nJour de dépassement : Jour de l’année où la demande d’un pays dépasse sa biocapacité annuelle."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#chargement-des-données",
    "href": "ANALYSES_FACTORIELLES/TP03.html#chargement-des-données",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Chargement des données",
    "text": "Chargement des données\n\n##-- Installer et Charger les packages requis\n###--- vecteurs des packages\npackages &lt;- c(\"factoextra\", \"corrr\", \"FactoMineR\", \"dplyr\",\"kableExtra\",\"corrplot\",\n              \"explor\")\n\n###--- Boucle pour installer et charger les packages\nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}\n\n##-- charger la base de données via le lien web\nlink.to.data &lt;- \"https://marieetienne.github.io/datasets/overshootday_overview.csv\"\ndf &lt;- read.csv(link.to.data)"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#analyse-exploratoire-des-données",
    "href": "ANALYSES_FACTORIELLES/TP03.html#analyse-exploratoire-des-données",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Analyse exploratoire des données",
    "text": "Analyse exploratoire des données\n\nnrow(df); ncol(df) ;dim(df)\n\n[1] 182\n\n\n[1] 13\n\n\n[1] 182  13\n\n\nLes données sont composées de 182 lignes et de 13 colonnes."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#résumé-statitique-des-variables",
    "href": "ANALYSES_FACTORIELLES/TP03.html#résumé-statitique-des-variables",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Résumé statitique des variables",
    "text": "Résumé statitique des variables\nOn utilise la commande summary(df) tout simplement, mais pour une question d’exthétique on utilise ce code.\n\n##-- summary pour les variable numériques\nsummary.df.num &lt;- sapply(df[sapply(df, is.numeric)], function(x) {\n  c(\n    min = min(x, na.rm = TRUE),\n    Q1 = quantile(x, 0.25, na.rm = TRUE),\n    Q3 = quantile(x, 0.75, na.rm = TRUE),\n    med = quantile(x, 0.5, na.rm = TRUE),\n    mean = mean(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE),\n    count = sum(!is.na(x)),\n    sd = sd(x, na.rm = TRUE),\n    `NA's` = round(sum(is.na(x)),0)\n  )\n})\nsummary.df.num &lt;- as.data.frame(summary.df.num)\n\nEnsuite nous affichons ce resumé dans un tableau :\n\n\n\nTableau 1 : Résumé statistique des variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlife_expectancy\nhdi\nper_capita_gdp\npop\ntotal_prod\ntotal_cons\nbiocapacity\nnumber_of_countries_required\nnumber_of_earths_required\novershoot_day\n\n\n\n\nmin\n52,525000\n0,3850000\n732,836\n0,06200\n0,371747\n0,5540298\n0,1041268\n0,0180633\n0,3668548\n41,0000\n\n\nQ1.25%\n65,747000\n0,5945000\n4888,255\n2,64100\n1,156834\n1,2195240\n0,6633750\n0,8273357\n0,8075166\n143,0000\n\n\nQ3.75%\n76,400695\n0,8350000\n31670,000\n32,91550\n3,828778\n3,8418335\n2,6656718\n2,7330613\n2,5438978\n365,0000\n\n\nmed.50%\n71,900000\n0,7310000\n13548,200\n10,01950\n1,924223\n2,3197815\n1,3622344\n1,7280656\n1,5360601\n239,0000\n\n\nmean\n71,180320\n0,7177193\n21139,464\n43,47636\n2,879469\n2,9624675\n3,5569055\n2,9127705\n1,9616192\n239,7802\n\n\nmax\n84,445610\n0,9620000\n120505,000\n1480,63200\n13,394536\n13,1263342\n85,6461100\n55,1061868\n8,6916969\n365,0000\n\n\ncount\n175,000000\n171,0000000\n163,000\n182,00000\n182,000000\n181,0000000\n181,0000000\n181,0000000\n181,0000000\n182,0000\n\n\nsd\n7,615465\n0,1533110\n22330,819\n156,03751\n2,515235\n2,1957327\n10,0256869\n5,1916277\n1,4539202\n109,5507\n\n\nNA’s\n7,000000\n11,0000000\n19,000\n0,00000\n0,000000\n1,0000000\n1,0000000\n1,0000000\n1,0000000\n0,0000\n\n\n\nNote: aby Djamal Y. TOE\n\n\n  Nous constatons que ceraines variables ont des données manquantes, nous pouvons décider de soit les supprimer, soit les prédire avec des méthodes d’imputation en fonction de leurs importances. Mais pour le moment nous allons juste les supprimer.\n\ndf &lt;- na.omit(df)\nnrow(df)\n\n[1] 162\n\n\nAinsi nous passons de 182 à 162 lignes."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#contruction-de-lanalyse-en-composante-principale",
    "href": "ANALYSES_FACTORIELLES/TP03.html#contruction-de-lanalyse-en-composante-principale",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Contruction de l’Analyse en composante principale",
    "text": "Contruction de l’Analyse en composante principale\n\nLe poids pour les pays : Les tailles respectives des populations de chaques pays car cela garantit que l’analyse est représentative des différences globales, en tenant compte de l’impact démographique des pays.\nMétrique : Normalisation des données car les variables ne sont pas toutes sur la même échelle. Cela permet d’éviter que les variables avec de grosses valeurs (grandes échelles) dominent l’analyse.\nvariables sup :\n\nQuali sup : region, income_group\nQuanti sup : pop\n\n\n\nRéalisation de l’ACP\n\nVérifions la corrélations entre les variables quantitatives\n\n\nnumeric.vars &lt;- as.data.frame(df[sapply(df, is.numeric)])\nM &lt;- round(cor(numeric.vars),2) #- Calculer la matrice de corrélation\n\n##-- créer un objet qui contient une palette de couleur pour le gradiant dans le plot\ncol &lt;- colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\n\n##-- dessiner le graphique\ncorrplot(M, method=\"color\", col=col(200),  \n         type=\"upper\", order=\"hclust\", \n         addCoef.col = \"black\", #- ajout des coefficients correlation\n         tl.col=\"black\", tl.srt=45, tl.cex = 1\n         , #- couleur, rotation et police de texte des libellés \n         ##-- ne pas afficher les coefficients de corrélations sur la diagonale (ils valent tous 1)\n         diag=FALSE \n         ) \n\n\n\n\nFigure 1 : Matrice de corrélations\n\n\n\n\n    On voit qu’il y’ a quand même des variables qui sont &lt;&gt; (pour l’affirmer avec plus d’assurance il serait judicieux de faire un test billatéral de corrélation de Pearson avec la commande cor.test(method = “pearson”, alternative = “two.sided”)).\n\nCréation du modèle de l’ACP\n\n\ndata.pca &lt;- df[,-1] #- sélectionner toute les variables sauf la variable pays\nrownames(data.pca) &lt;- df[,1] #- renommer les lignes avec les noms des pays (individus)\npoids &lt;- df$pop\npca.model &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = 6)\n\n##- explor(pca.model) pour une interface interactive\n\n\n\nRecupération des valeurs propres et des variances\n\neigen.values &lt;- pca.model$eig\nknitr::kable(eigen.values[1:3,2:3], caption = capTab(\"Inerties expliquées par les 3 premiers axes\"))\n\n\nTableau 2 : Inerties expliquées par les 3 premiers axes\n\n\n\npercentage of variance\ncumulative percentage of variance\n\n\n\n\ncomp 1\n69,758338\n69,75834\n\n\ncomp 2\n16,485374\n86,24371\n\n\ncomp 3\n4,865912\n91,10962\n\n\n\n\n\nOn remarque que les axes 1,2 et 3 représentent respectivement 69,76, 16,49 et 4,09, donc au total 91,11\nOn pourrait aussi visualiser le graphique des valeurs propres :\n\nplt.eig &lt;- fviz_eig(pca.model, title = \"Valeurs propres avec Singapore\")\n\n\n\nQualité de representation des plans / sur les plans\n\nQualité de representation des plans\n\n  Le premier plan a un taux d’inertie supérieur à 86 %, il capte une grande partie de l’information présente dans les données ce qui signifie qu’il à une bonne qualité de representation alors que le second (1-3) en capte environ 74,63 % donc a une faible qualité de représenatation comparé au premier. En depit de ce fait, les deux plans ont quand même qualité de représentation si mous fions au critère du taux d’inertie.\n\nQualité de representation sur les plans\n\n(1-2)\n\n\nLES VARIABLES\n\ngraph.cos2.var &lt;- fviz_pca_var(pca.model,col.var=\"cos2\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.cos2.var\n\n\n\n\nFigure 3 : Qualités de representation des variables\n\n\n\n\nConcernant les variables, on constate qu’elles toutes sont bien representées avec des cosinus carrés qui ont une valeur minimale environ 0,8 à part les variables biocapacity, life_expectancy, number_of_countries_required qui ont un cosinus carrés qui vaut environ 0,7.\nLES INDIVIDUS\n\nthreshold &lt;- 0.85\ndata.ind.cos2 &lt;- pca.model$ind$cos2\n\ndim1 &lt;- data.ind.cos2[,\"Dim.1\"]\ndim1 &lt;- dim1[dim1 &gt;= threshold]\ncountries.dim1 &lt;- names(dim1)\nnames(dim1) &lt;-  NULL\n\ndim2 &lt;- data.ind.cos2[,\"Dim.2\"]\ndim2 &lt;- dim2[dim2 &gt;= 0.6]\ncountries.dim2 &lt;- names(dim2)\nnames(dim2) &lt;-  NULL\n\n##-- crétion des dataframes \ndim1.df &lt;- data.frame(\n  Country = countries.dim1,\n  `Cos carré` = dim1\n) %&gt;% arrange(desc(dim1))\n\n\ndim2.df &lt;- data.frame(\n  Country = countries.dim2,\n  `Cos carré` = dim2\n) %&gt;% arrange(desc(dim2))\n\n\n##-- création des tableaux kableExtra\ndim1.tbl &lt;- kableExtra::kbl(dim1.df, caption = capTab(\"Individus ayant un cosinus carré supérieur ou égal à 0,85 sur l'axe 1\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\ndim2.tbl &lt;- kableExtra::kbl(dim2.df, caption = capTab(\"Individus ayant un cosinus carré supérieur ou égal à 0,6 sur l'axe 2\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))  %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\n\ndim1.tbl\n\n\n\nTableau 3 : Individus ayant un cosinus carré supérieur ou égal à 0,85 sur l'axe 1\n\n\nCountry\nCos.carré\n\n\n\n\nRwanda\n0,9810454\n\n\nNepal\n0,9772128\n\n\nHaiti\n0,9763067\n\n\nPakistan\n0,9745537\n\n\nSao Tome and Principe\n0,9617076\n\n\nIndia\n0,9558559\n\n\nKenya\n0,9448689\n\n\nTogo\n0,9425662\n\n\nMalawi\n0,9425394\n\n\nTanzania, United Republic of\n0,9419010\n\n\nEthiopia\n0,9390190\n\n\nGambia\n0,9377395\n\n\nPoland\n0,9272053\n\n\nYemen\n0,9228666\n\n\nCzech Republic\n0,9218239\n\n\nAustria\n0,9047663\n\n\nGuatemala\n0,9044971\n\n\nMyanmar\n0,8964483\n\n\nBurundi\n0,8916493\n\n\nCambodia\n0,8911437\n\n\nDenmark\n0,8896874\n\n\nUnited States of America\n0,8875048\n\n\nSlovenia\n0,8840522\n\n\nMalaysia\n0,8840507\n\n\nBenin\n0,8831711\n\n\nSudan\n0,8713134\n\n\nSenegal\n0,8705626\n\n\nTimor-Leste\n0,8640862\n\n\nBelgium\n0,8604596\n\n\nAngola\n0,8591836\n\n\nGhana\n0,8579621\n\n\nSierra Leone\n0,8542504\n\n\nSlovakia\n0,8524619\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\ndim2.tbl \n\n\n\nTableau 4 : Individus ayant un cosinus carré supérieur ou égal à 0,6 sur l'axe 2\n\n\nCountry\nCos.carré\n\n\n\n\nNamibia\n0,7502317\n\n\nParaguay\n0,6807204\n\n\nBrazil\n0,6672407\n\n\nBolivia\n0,6609662\n\n\nBarbados\n0,6458843\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\nAXE 1 : On voit que les pays (individus) comme le Togo, le Yemen, les USA, le Rwanda sont tres bien representés. RMRQ : Il y en a d’autres\nAXE 2 : Il n’y a que 6 pays qui sont bien représentés sur cet axe. Il s’agit de la Namibie, le Paraguay, le Brésil, la Bolivie et Barbados.\n\nREMARQUE :  Pour le plan formé des axes 1 et 3, on peut procéder la même que celle en amont\n\n\nCaractérisation des axes\n\ngraph.contrib.var &lt;- fviz_pca_var(pca.model,col.var=\"contrib\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.contrib.var\n\n\n\n\nFigure 4 : Cercle de corrélation des variables et leur contribution à la formation des axes\n\n\n\n\n\n\nComment l’ACP est-elle modifiée si on retire Singapour de l’analyse ?\n\ndata.pca.sans.singapore &lt;- data.pca %&gt;% filter(rownames(data.pca) != \"Singapore\")\npoids &lt;- df$pop\npca.model.sans.singapore &lt;- PCA(data.pca.sans.singapore, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca.sans.singapore$pop,\n                 quanti.sup = 6)\n\n##-- explor(pca.model)\n\n\nplt.eig.sans.sing &lt;- fviz_eig(pca.model.sans.singapore, title = \"Valeurs propres sans Singapore\") \ncomp.eig &lt;-  cowplot::plot_grid(\n  plt.eig,\n  plt.eig.sans.sing,\n  ncol = 2\n)+ theme_light()\ncomp.eig\n\n\n\n\nFigure 5 : Comparaison des valeurs propres issues de l’ACP aevc et sans Singapore\n\n\n\n\n  On voit que rien ne se passe (pas de changement brusque) au niveau de la qualité des axes. Voyons de plus prêt ce qui se passe :\n\nplot.indiv.avec.sing &lt;- fviz_pca_ind(pca.model) + \n                        theme_light()\nplot.indiv.avec.sing\n\n\n\n\nFigure 6 : Comparaison des valeurs propres issues de l’ACP aevc et sans Singapore\n\n\n\n\n  On voit que Singapore est atypique. Cela pourrait signifier que Singapore participe fortement à la formation de l’axe 2 (point plus proche de l’axe 1).\n\ndata &lt;- as.data.frame(pca.model$ind$contrib)\ndata &lt;-  data %&gt;% arrange(desc(Dim.2)) %&gt;% head(10)\nkableExtra::kbl(data, caption = capTab(\"Contribution des individus à la formation des axes par contribution décroissante suivant l'axe 2\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))  %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 5 : Contribution des individus à la formation des axes par contribution décroissante suivant l'axe 2\n\n\n\nDim.1\nDim.2\nDim.3\nDim.4\nDim.5\n\n\n\n\nSingapore\n0,7259355\n15,139608\n28,5623680\n9,9266768\n5,6933884\n\n\nBrazil\n0,2363938\n11,748028\n0,2780798\n16,7474472\n0,1489935\n\n\nChina\n6,3338962\n10,346574\n0,9583694\n1,3599693\n36,9834265\n\n\nRussian Federation\n3,7284884\n10,223438\n4,1131775\n0,1010599\n3,8319553\n\n\nCanada\n3,7127169\n6,392768\n0,8335954\n3,8719645\n0,0267550\n\n\nJapan\n2,3347045\n4,109062\n0,8491595\n0,6848764\n2,2016647\n\n\nUnited States of America\n21,6581050\n3,434086\n3,0985377\n22,3391460\n5,4054986\n\n\nKorea, Republic of\n1,9711036\n2,758601\n0,8457859\n0,0962515\n0,0745840\n\n\nAustralia\n1,8672806\n2,568678\n0,0085414\n1,3778438\n0,3505079\n\n\nGuyana\n0,0605633\n2,548944\n1,0759061\n8,5175485\n0,9606747\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEt pourtant il contribue fortement à la formation de l’axe 2, il est même celui qui contribue les plus à la formation des axes. Le fait que Singapore contribue le plus à la formation des axes et que rien ne change lorsqu’il est retiré de l’analyse s’explique tout simplement par sa taille de population. En effet la taille de la population a été utilisée comme poids des individus qui sont ici les pays."
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#identifications-des-pays-en-fonction-de-leur-groupe-de-revenu",
    "href": "ANALYSES_FACTORIELLES/TP03.html#identifications-des-pays-en-fonction-de-leur-groupe-de-revenu",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "Identifications des pays en fonction de leur groupe de revenu",
    "text": "Identifications des pays en fonction de leur groupe de revenu\n\nIl s’agit juste d’une parenthèse qui n’a rien avoir avec l’objectif de l’étude\n\n\n##-- Définitions des groupes de revenus\nincome_groups_definitions &lt;- c(\n  \"UM\" = \"Upper-Middle\",\n  \"LM\" = \"Lower-Middle\",\n  \"HI\" = \"High Income\",\n  \"LI\" = \"Low Income\"\n)\n\n\n##-- Ajouter une colonne avec les définitions correspondantes\ndata.pca$income_group_def &lt;- as.factor(income_groups_definitions[data.pca$income_group])\n\n\ngraph_indiv &lt;- fviz_pca_ind(\n  pca.model,\n  select.ind = list(\n    contrib = 50\n  ),\n  invisible = c(\"quanti.sup\",\"ind.sup\"),\n  habillage = data.pca$income_group_def,\n  addEllipses = TRUE,\n  repel = TRUE,\n) + theme_light() \n\n\ngraph_indiv\n\n\n\n\nFigure 7 : Affichage des 40 individus qui contribuent le plus à la formation des axes en fonction de leur groupe de revenu\n\n\n\n#hc.pca &lt;- HCPC(pca.model, nb.clust=3)\n\n      On voit que les groupes ne sont pas bien séparés, raison pour laquelle les ellipses ont des partie qui coïncident. Cela pourrait signifier que les les groupes de revenus sont trop similaires pour etre clairement séparés sur les axes sélectionnés (dans le plan des composantes principales). Cela pourrait aussi fait cas d’hétérogénéité, c’est-à-dire que les groupes ne sont pas homogènes (grande variabilité intra-groupe).\n      A bien regarder, nous aurions pu les regrouper en trois groupes de revenu, en combinant les Low income et les Low middle income, les Upper middle income (avec certains pays du High income) et enfin le dernier groupe les high income. Il faut noter que tout ça n’est que purement visuel même si on a quand même une grande partie de l’information contenue dans les données rien qu’avec ces deux plans (plus de 80%).\n\nDeux ACP différentes\n\nPourquoi réaliser deux ACP différentes ?\n\n  Pour simplement calculer la 1-ère valeur propre de chaque groupe de variables (empreinte écologique et de developpement) afin de les utiliser ponderer les variables afin qu’elles contribuent de manière équitable à la formation des axes. Pour plus de détails aller à la sous-section et sur le site de mon professeur de Méthodes d’Analyses Factorielles en cliquanr sur ce lien https://marieetienne.github.io/MAF/01_afm.html#/title-slide.\nOn préfère utiliser la première valeur propre (\\(\\lambda_{k1}\\)) car elle capturerait l’essentiel de l’inertie d’un groupe et permet une pondération cohérente et équilibrée dans l’AFM. La seconde valeur propre reflète des structures secondaires ou résiduelles qui ne sont pas pertinentes pour normaliser les contributions des groupes dans l’analyse globale.\n\nvariables.empreinte &lt;- df[, c(\"total_prod\", \"total_cons\", \"biocapacity\", \"number_of_earths_required\", \"overshoot_day\", \"pop\")]\nrownames(variables.empreinte) &lt;- df$country\nvariables.developpement &lt;- df[, c(\"life_expectancy\", \"hdi\", \"per_capita_gdp\",\"pop\")]\nrownames(variables.developpement) &lt;- df$country\n\n\nACP sur les variables d’empruntes écologiques\n      Il s’agit ici de faire l’ACP que sur les variables d’empruntes écologiques et de mettre les autres variables (de developpement) en quantitatives supplémentaires.\n\ndata.pca &lt;- df[,-1] ## sélectionner toute les variables sauf la variable pays\nrownames(data.pca) &lt;- df[,1] ## renommer les lignes avec les noms des pays (individus)\npoids &lt;- df$pop\nacp_empreinte &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = c(6,1,2,3))\n\n##-- 1ere valeur propre\nacp_empreinte$eig[1,1]\n\n[1] 4,115324\n\n\nLa première valeur propre est : 4,12\n\n\nACP sur les variables d’empruntes écologiques\n\nacp.developpement &lt;- PCA(data.pca, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\"),\n                 graph = FALSE,\n                 row.w = data.pca$pop,\n                 quanti.sup = 6:12)\n\n##-- 1ere valeur propre\nacp.developpement$eig[1,1]\n\n[1] 2,592046\n\n\nLa première valeur propre est : 2,59\n\n\nRéalisons l’AFM manuellement\n\nvariables.empreinte.pond &lt;- variables.empreinte[,-ncol(variables.empreinte)]/sqrt(acp_empreinte$eig[1,1])\n\nvariables.developpement.pond &lt;- variables.developpement[,-ncol(variables.developpement)]/sqrt(\n  acp.developpement$eig[1,1]\n)\n\nvariables.empreinte.pond$group &lt;- \"Empreinte écologique\"\nvariables.developpement.pond$group &lt;- \"developpement\"\n\ndf.afm &lt;- cbind(variables.empreinte.pond, \n                variables.developpement.pond,\n                pop = df$pop,\n                region = df$region,\n                income_group = df$income_group)\n\nacp.afm &lt;- PCA(df.afm, scale.unit = TRUE,\n                 quali.sup = c(\"region\", \"income_group\", \"group\"),\n                 graph = FALSE,\n                 row.w = df.afm$pop,\n                 quanti.sup = 9)\n\nvariance.cum.val.prop.2acp &lt;- acp.afm$eig[, c(1,3)]\ncolnames(variance.cum.val.prop.2acp) &lt;- c(\"Valeur propres\", \"Pourcentage de variance cumulée\")\n\n\nkableExtra::kbl(variance.cum.val.prop.2acp, caption = capTab(\"Valeurs propres et variances cumulées de chaque axes issues d'une AFM manuelle\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 6 : Valeurs propres et variances cumulées de chaque axes issues d'une AFM manuelle\n\n\n\nValeur propres\nPourcentage de variance cumulée\n\n\n\n\ncomp 1\n5,4257689\n67,82211\n\n\ncomp 2\n1,3223267\n84,35120\n\n\ncomp 3\n0,6522681\n92,50455\n\n\ncomp 4\n0,3973880\n97,47190\n\n\ncomp 5\n0,1005256\n98,72847\n\n\ncomp 6\n0,0689548\n99,59040\n\n\ncomp 7\n0,0327679\n100,00000\n\n\ncomp 8\n0,0000000\n100,00000\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv"
  },
  {
    "objectID": "ANALYSES_FACTORIELLES/TP03.html#afm",
    "href": "ANALYSES_FACTORIELLES/TP03.html#afm",
    "title": "Djamaldbz - Méthodes d’Analyse factorielle TP02",
    "section": "REALISATION DE L’AFM",
    "text": "REALISATION DE L’AFM\n\nPourquoi réaliser une AFM au lieu d’une ACP tout court?\n\n      L’Analyse Factorielle Multiple (AFM) permet d’aller au-delà des limites d’une Analyse en Composantes Principales (ACP) classique, particulièrement lorsque les variables d’un jeu de données ne sont pas à la même échelle ou lorsqu’elles sont organisées en groupes. La normalisation dans l’ACP sert à ramener toutes les variables à une même échelle, évitant ainsi que certaines variables dominent artificiellement l’analyse en raison de leur variance plus élevée. Par exemple d’autres ont une contribution élevée que d’autres alors que c’est juste l’unité de mésure qui pèse plus.\n  Cependant, cette normalisation n’est pas suffisante lorsque les variables sont regroupées par thématique ou nature. Par exemple, supposons un jeu de données contenant \\(n\\) variables, parmi lesquelles \\(n - k\\) \\(\\text{avec k telque  } \\forall \\text{ j} \\neq \\text{k, }\\)\n\\(\\text{n - k} &gt; \\text{n - j où n - j est le nombre de variables dans tous les autres groupes ou dans un autre groupe j}\\) appartiennent à un groupe \\(i\\) .Dans ce cas, le groupe \\(i\\) peut influencer de manière disproportionnée les résultats de l’ACP, simplement en raison de la taille du groupe. Cela signifie que, même après normalisation, le poids collectif du groupe \\(i\\) dans la construction des composantes principales pourrait être trop important par rapport aux autres groupes.\n  L’AFM résout ce problème en intégrant un poids équilibré entre les groupes. Elle considère chaque groupe comme une entité, indépendamment du nombre de variables qu’il contient. Cela permet une contribution équitable des groupes aux axes factoriels. Par conséquent, l’AFM est particulièrement adaptée dans des contextes où les variables appartiennent à des thématiques distinctes (par exemple, des groupes liés à des disciplines différentes : santé, économie, environnement).\nIl est crucial de préserver l’équilibre des contributions entre ces thématiques pour éviter les biais d’interprétation. Ainsi, l’AFM fournit une perspective multidimensionnelle plus équilibrée et pertinente pour analyser des jeux de données complexes, tout en respectant la structure inhérente des variables\n\nRéalisons l’AFM à présent\n\n\n#-- création de la table pour l'AFM. Les vriables doivent être rangées \n#-- suivant le groupe (variables du groupe 1 ensuite celles du groupe 2 ...)\ndata.afm &lt;- data.pca %&gt;%\n  select(\n    life_expectancy, hdi, per_capita_gdp,  ##-- Variables de developpement\n    total_prod, total_cons, biocapacity, ##------ Variables\n    number_of_earths_required, overshoot_day ##-- d'empreinte écologique\n)\n\nmodel.afm &lt;- MFA(\n    data.afm, \n    group = c(5, 3), ##-- Spécifie le nombre de variables dans chaque groupe\n    type = rep(\"s\", 2), ##-- Indique que les variables doivent être normalisées pour chaque groupe\n    name.group = c(\"Developpement\", \"Empreinte ecologique\"), ##-- Nommer les groupes\n    graph = F  ##-- Générer un graphique\n)\nvariance.cum.val.prop.afm &lt;- model.afm$eig[, c(1,3)]\ncolnames(variance.cum.val.prop.afm) &lt;- c(\"Valeur propres\", \"Pourcentage de variance cumulée\")\n\n\nkableExtra::kbl(variance.cum.val.prop.afm, caption = capTab(\"Valeurs propres et variances cumulées de chaque axes issues d'une AFM avec R\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\")) %&gt;% add_footnote(label = \"Source des données :  https://marieetienne.github.io/datasets/overshootday_overview.csv\")\n\n\n\nTableau 7 : Valeurs propres et variances cumulées de chaque axes issues d'une AFM avec R\n\n\n\nValeur propres\nPourcentage de variance cumulée\n\n\n\n\ncomp 1\n1,9203865\n67,85068\n\n\ncomp 2\n0,5123847\n85,95414\n\n\ncomp 3\n0,2050340\n93,19836\n\n\ncomp 4\n0,0790131\n95,99003\n\n\ncomp 5\n0,0659024\n98,31848\n\n\ncomp 6\n0,0327210\n99,47457\n\n\ncomp 7\n0,0148713\n100,00000\n\n\ncomp 8\n0,0000000\n100,00000\n\n\n\na Source des données : https://marieetienne.github.io/datasets/overshootday_overview.csv\n\n\n\n\n\n\n\n\n\n\n\nOn voit qu’il n’y a pas très grande différence entre les pourcentage de variances cumulées des deux AFM (manuellement @variance.cum.val.prop.2acp et avec R) parcontre les valeurs propres ne sont pas les mêmes.\n\nOn peut visualiser les variables\n\n\nfviz_mfa_var(model.afm, axes = c(1,2), choice= \"quanti.var\", repel = T) + theme_light()\n\n\n\n\nFigure 8 : Visualisation des variables dans le plan (1,2) avec les résultats de l’AFM\n\n\n\n\n\nOn peut visualiser leur qualité de representation\n\n\ngraph.cos.var.afm &lt;- fviz_mfa_var(model.afm, axes = c(1,2), choice= \"quanti.var\", col.var=\"cos2\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel = T, ggtheme = theme_light())\n\ngraph.cos.var.afm\n\n\n\n\nFigure 9 : Qualité de représentation des variables dans le plan (1,2) avec les résultats de l’AFM\n\n\n\n\n\nLeur contribution à la formation des axes\n\n\ngraph.contrib.var.afm &lt;- fviz_mfa_var(model.afm,col.var=\"contrib\", gradient.cols=c(\"#F1C40F\",\"#2ECC71\",\"#8E44AD\"), repel=TRUE, ggtheme = theme_light())\n\ngraph.contrib.var.afm\n\n\n\n\nFigure 10 : Cercle de corrélation des variables et leur contribution à la formation des axes"
  },
  {
    "objectID": "FORMATIONS/SIG.html",
    "href": "FORMATIONS/SIG.html",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "",
    "text": "packages &lt;- c(\"ggplot2\",\"haven\", \"gtsummary\", \"corrr\", \"MASS\",\n              \"dplyr\",\"haven\", \"rstatix\", \"tidyverse\", \"ggpubr\",\n              \"glue\", \"dplyr\",\"ggspatial\", \"ggrepel\",\"marmap\", \n              \"readxl\", \"stringr\", \"colorspace\", \"sf\", \"viridis\",\n              \"tools\",\"ggspatial\",\"readxl\",\"openxlsx\",\"grid\",\n              \"outliers\",\"car\",\"ftExtra\",\"tibble\",\n              \"gtsummary\", \"wesanderson\", \"viridis\",\"RColorBrewer\") \n            \nfor (pkg in packages) {\n  if (!requireNamespace(pkg, quietly = TRUE)) {\n    install.packages(pkg, dependencies = T)\n  }\n  library(pkg, character.only = TRUE)\n}"
  },
  {
    "objectID": "FORMATIONS/SIG.html#comment-faire-des-cartes-choroplèthes-et-des-cartes-de-proportions-avec-r",
    "href": "FORMATIONS/SIG.html#comment-faire-des-cartes-choroplèthes-et-des-cartes-de-proportions-avec-r",
    "title": "Djamaldbz - DJAMAL TOE",
    "section": "Comment faire des cartes Choroplèthes et des cartes de proportions avec R ?",
    "text": "Comment faire des cartes Choroplèthes et des cartes de proportions avec R ?\n      Les cartes choroplèthes et les cartes de proportions sont des outils puissants pour visualiser des données géospatiales dans R. Ces cartes permettent de représenter des valeurs quantitatives (par exemple, des taux de population, des moyennes) sur des zones géographiques, souvent des régions administratives comme des départements, des communes, ou des zones géographiques personnalisées.\n\nIntroduction aux Cartes Choroplèthes et Cartes de Proportions\n\nLes cartes choroplèthes colorient les régions géographiques en fonction de valeurs numériques ou de proportions, facilitant l’analyse spatiale et la compréhension des variations géographiques. Elles sont couramment utilisées pour des données socio-économiques, de santé publique, ou des analyses environnementales.\nLes cartes de proportions sont similaires mais mettent davantage l’accent sur les ratios ou proportions par rapport à une valeur totale, comme des pourcentages ou des fractions de populations.\n\nNotions de Base : Polygones, Shapefiles et Coordonnées Avant de créer ces cartes, il est important de comprendre quelques notions de base, comme les polygones et les shapefiles :\n\n\n\n\n\n\n\nPolygones\n\n\n\nUne zone géographique est souvent représentée par un polygone, une forme géométrique fermée qui peut avoir plusieurs côtés. Par exemple, une commune ou un département sur une carte peut être représentée comme un polygone.\n\n\n\n\n\n\n\n\nShapefiles\n\n\n\nCe sont un format de fichier standard pour stocker des informations géospatiales, y compris les coordonnées de points, de lignes et de polygones. Ils peuvent contenir les géométries des entités géographiques ainsi que leurs attributs (valeurs associées à chaque région, comme le revenu moyen ou le taux de chômage).\n\n\n\n\n\n\n\n\nCoordonnées géographiques\n\n\n\nLes coordonnées (latitude et longitude) permettent de positionner ces polygones sur une carte. En R, on utilise des systèmes de coordonnées géographiques et projetées pour gérer et visualiser ces données.\n\n\nPlusieurs pakages permettent de visualiser les données avec les cartes, ici nous interessons aux packages glue et sf.\n\nZone d’étude\n\nSupposons que nous menions une étude au Burkina-Faso. Par exemple, nous mésurer des indicateurs tels que le taux de mortalité, la couverture sanitaire etc … Le Burkina Faso est un pays qui compte 13 regions, mais notre etude s’étend seulement sur 8 regions. Il convient de montrer toutes les regions, puis de mettre en exègue celles qui nous concernent.\n\nPlace au code\n\n\n###---- Chargement des shapefiles src = GADM ----###\nroot &lt;- getwd() ##-- la racine du repertoire\n\n##- La carte du pays sans les polygones des regions, communes et/ou departements\npath0 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_0.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath1 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_1.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath2 &lt;- paste0(\"/DATA_SIG/BFA2/gadm41_BFA_2.shp\")\n\n##- La carte du pays avec le polygone des regions, sans ceux des communes et/ou departements\npath3 &lt;- paste0(root,\"/DATA_SIG/BFA2/gadm41_BFA_3.shp\")\n\n\n##-- selection des regions concernées\n\nstudy.area &lt;-  c(\"Boucle du Mouhoun\", \"Centre-Est\", \"Centre-Nord\",\n             \"Centre-Ouest\", \"Nord\", \"Sud-Ouest\",\n             \"Hauts-Bassins\", \"Cascades\")\n\n##-- lecture des shapefiles\npays_shp &lt;- read_sf(glue(path0), quiet = T)\nregion_shp &lt;- read_sf(glue(path1), quiet = T)\n#commune_shp &lt;- read_sf(glue(path2), quiet = T)\n#province_shp &lt;- read_sf(glue(path3), quiet = T)\n\n##-- création d'une sous base avec les polygones des regions sélectionnés\n\ndata_region &lt;- region_shp %&gt;% filter(NAME_1 %in% study.area)\n\n\n##-- Study area colors\nstudy_zone_colors &lt;- c(\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\",\n                       \"#3FE1B8\", \"#9467bd\", \"#8c564b\",\n                       \"#00008B\", \"#4B0082\")\n\nstudy_zone_map &lt;- ggplot() +\n  geom_sf(data = pays_shp, aes(linewidth = \"Burkina Faso\"),fill = \"white\", color = \"black\") +\n  geom_sf(data = region_shp, aes(fill = ifelse(\n    NAME_1 %in% study.area,\n    \"Regions d'études\",\n    \"Autres regions\"\n  ) )) +\n  geom_sf_text(data = region_shp, aes(label = ifelse(\n    NAME_1 %in% study.area,\n    study.area,\n    \"\"\n  )), size = 4)+\n  ggspatial::annotation_scale(\n    location = \"br\",\n    bar_cols = c(\"black\", \"white\")\n  )  +\n  theme_light()+\n  ggspatial::annotation_north_arrow(\n    location = \"tr\", which_north = \"true\",\n    pad_x = unit(0.05, \"in\"), pad_y = unit(0.05, \"in\"),\n    style = ggspatial::north_arrow_nautical(\n      fill = c(\"black\", \"white\"),\n      line_col = \"black\"\n    )\n  )+\n  xlab(\"\")+\n  ylab(\"\")+\n  scale_linewidth_manual(values = c(1.2), name = \"\")+\n  scale_fill_manual(values = c(\"white\",study_zone_colors), name=\"Zone d'étude\")+\n  theme_light() + \n  guides(\n    linewidth = guide_legend(order = 1),\n    fill = guide_legend(order = 2),\n    color = guide_legend(order = 3)\n  )\n\n\nstudy_zone_map\n\n\n\n\nCartographie de la zone d’étude\n\n\n\n\n\nCartes choroplèthes\n\n\nCartes de proportions\n\n\nCartes de proportions avancées\n\nRetour à la page d’accueuil"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "",
    "text": "Bienvenue sur le site Djamaldbz, dédié à mes travaux en statistiques et informatique. Explorez mes projets, mes recherches, et mes publications."
  },
  {
    "objectID": "index.html#qui-suis-je",
    "href": "index.html#qui-suis-je",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Qui suis-je ?",
    "text": "Qui suis-je ?\nJe m’appelle Djamal Y. TOE, et je suis passionné par les statistiques et l’informatique. Mon parcours m’a amené à me concentrer sur l’analyse avancée et la résolution de problèmes à l’aide de méthodes quantitatives. Mon apprentissage est un voyage continu. Mon objectif est d’explorer de nouvelles approches et d’apporter des solutions pratiques, tout en restant ouvert à l’apprentissage et à l’amélioration constante dans le domaine des statistiques et de la science des données.\n\nEn savoir plus sur moi ici"
  },
  {
    "objectID": "index.html#mon-expertise",
    "href": "index.html#mon-expertise",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Mon expertise",
    "text": "Mon expertise\nJe combine mes compétences en statistiques, programmation et analyse de données pour résoudre des problèmes complexes et fournir des solutions pratiques.\nVoici un aperçu de mes domaines d’expertise :\n\nAnalyses Factorielles et Visualisation\nModèles de Régression et Prévisions\nApplications Statistiques Interactives\nDéveloppement d’Applications Bureau et Web\nVision par Ordinateur (Computer Vision en apprentissage)"
  },
  {
    "objectID": "index.html#mes-projets-récents",
    "href": "index.html#mes-projets-récents",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Mes projets récents",
    "text": "Mes projets récents\nVoici quelques-uns de mes projets récents dans le domaine des statistiques et de l’analyse de données :\n\nAnalyse Factorielle et Visualisation Avancée\nModélisation de Régressions Mixtes pour des données complexes\nDéveloppement d’outils interactifs pour la visualisation de données\n\n\nVoir tous mes projets [Bientôt disponible]"
  },
  {
    "objectID": "index.html#dernières-publications",
    "href": "index.html#dernières-publications",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Dernières publications",
    "text": "Dernières publications\nVoici les dernières publications sur des sujets de statistiques et d’informatique que j’ai partagées :\n\nExploration des Techniques d’Analyse Factorielle\nGuide pratique pour les modèles mixtes\nComment faire des cartes de proportions et des cartes choroplèthes avec R ?\n\n\nVoir toutes les publications [Bientôt disponible]"
  },
  {
    "objectID": "index.html#contactez-moi",
    "href": "index.html#contactez-moi",
    "title": "Djamaldbz - Expertise en Statistiques",
    "section": "Contactez-moi",
    "text": "Contactez-moi\nSi vous avez des questions ou souhaitez collaborer sur un projet, n’hésitez pas à me contacter !\n\nEnvoyer un message\n\n\n\n\nA propos de nous\nElève en Science de données à l’Ecole Nationale de la Statistique et de l’Analyse de l’Information en France, titulaire d’une licence en Statistiques-informatique.\nRéseaux sociaux\n\nFacebook\nTwitter\nLinkedIn\n\n\nCoordonnées\n\nAdresse : Rennes, 35000, France\nEmail : djamaltoe2905@gmail.com\nTéléphone : +33 ** ** ** ** **\n\nHeures de services\n\n\n\nJour\nHoraire\n\n\n\n\nLundi\n8h30pm - 9:30pm\n\n\nMardi - Vendredi\n7pm - 8pm\n\n\nSamedi\n9:30am - 10:30am\n\n\n\n\n\n\n\nInformations supplémentaires\n© 2024 DJAMAL DEV\nContact: djamaltoe2905@*.com\nLocalisation: Rennes, France\nTéléphone: +33"
  }
]